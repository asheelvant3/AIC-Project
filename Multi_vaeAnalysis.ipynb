{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0reo6C2Hwngo",
        "outputId": "760c23da-f16d-4751-cc05-3f29f0fed4ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sfv2xYnLwseu",
        "outputId": "204c8b40-4021-4c7c-892a-14b547e1ed4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Project\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1gfLSgbxBC8",
        "outputId": "ee226015-a098-4c88-eb2f-1ef7c23c4738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1905.03375.pdf  \u001b[0m\u001b[01;34mdaisyRec\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJB1KGETxCXk",
        "outputId": "100fe5da-ecb6-426c-e1c3-e175172f7227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Project/daisyRec\n"
          ]
        }
      ],
      "source": [
        "cd daisyRec/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VtQ3uMexD6x",
        "outputId": "ea300c23-3250-47a4-e4ac-66ed314a986c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdaisy\u001b[0m/  \u001b[01;34mimages\u001b[0m/  \u001b[01;34mlog\u001b[0m/       README.md         \u001b[01;34mres\u001b[0m/      test.py  \u001b[01;34mtune_res\u001b[0m/\n",
            "\u001b[01;34mdata\u001b[0m/   LICENSE  model.pkl  requirements.txt  setup.py  tune.py  Untitled.ipynb\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HkVwDyFxc55",
        "outputId": "9ca11053-9ba0-473a-8d3b-a9f273aa5bbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.1.1-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from optuna) (1.22.4)\n",
            "Collecting cmaes>=0.9.1\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.10.3-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.3/212.3 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from optuna) (6.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (2.0.9)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.10.3 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip3 install optuna "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxJVUy28xgDW",
        "outputId": "cf1a7d17-191c-4e6f-8aac-3f6139ab5ec6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n"
          ]
        }
      ],
      "source": [
        "!pip3 install colorama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl--CzNQxYGa",
        "outputId": "8a637c4e-70f7-4f97-a3fe-ce7e87eff10f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 015]: 100% 1/1 [00:00<00:00,  5.55it/s]\u001b[0m\n",
            "[Epoch 016]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0859,  0.1161,  0.0016,  ..., -0.0525,  0.0160,  0.0011],\n",
            "        [ 0.0125, -0.0088, -0.0555,  ..., -0.1308, -0.0703,  0.1385],\n",
            "        [ 0.0128,  0.0195,  0.1037,  ..., -0.0558, -0.0326,  0.0298],\n",
            "        ...,\n",
            "        [ 0.0004, -0.0004, -0.0013,  ..., -0.0004,  0.0005, -0.0004],\n",
            "        [-0.0067,  0.0415, -0.0242,  ...,  0.0128,  0.0107,  0.0124],\n",
            "        [ 0.0401, -0.0004,  0.0923,  ..., -0.0905,  0.0345, -0.0275]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 016]: 100% 1/1 [00:00<00:00,  5.94it/s]\u001b[0m\n",
            "[Epoch 017]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0838, -0.0220,  0.0369,  ...,  0.0289,  0.0403,  0.0169],\n",
            "        [-0.1028,  0.0846, -0.0240,  ..., -0.1148, -0.0957, -0.0229],\n",
            "        [ 0.0004, -0.0005, -0.0014,  ..., -0.0004,  0.0006, -0.0004],\n",
            "        ...,\n",
            "        [ 0.0089, -0.0166, -0.0694,  ...,  0.0406, -0.0428,  0.0328],\n",
            "        [ 0.0544,  0.0263,  0.0406,  ...,  0.0841, -0.0079, -0.1042],\n",
            "        [ 0.0969,  0.0794, -0.0198,  ...,  0.0892,  0.0269, -0.0082]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 017]: 100% 1/1 [00:00<00:00,  5.99it/s]\u001b[0m\n",
            "[Epoch 018]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0235, -0.1152,  0.0947,  ...,  0.0675, -0.1226, -0.0533],\n",
            "        [-0.1435,  0.0128,  0.0450,  ...,  0.0067, -0.0033,  0.0033],\n",
            "        [-0.0606, -0.0373,  0.1123,  ...,  0.0380,  0.0631, -0.0345],\n",
            "        ...,\n",
            "        [ 0.0004, -0.0005, -0.0015,  ..., -0.0004,  0.0006, -0.0005],\n",
            "        [ 0.0368, -0.0983, -0.0795,  ..., -0.0341,  0.0398,  0.1653],\n",
            "        [-0.1390,  0.1930,  0.0231,  ..., -0.0600, -0.0311, -0.0352]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 018]: 100% 1/1 [00:00<00:00,  7.16it/s]\u001b[0m\n",
            "[Epoch 019]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0331,  0.1201,  0.0111,  ...,  0.0539,  0.0186, -0.0678],\n",
            "        [-0.0520,  0.0421,  0.1590,  ..., -0.0453, -0.0236,  0.0375],\n",
            "        [-0.0579,  0.0639,  0.0959,  ...,  0.0914, -0.0909, -0.0127],\n",
            "        ...,\n",
            "        [ 0.0873,  0.0745,  0.0679,  ...,  0.0490, -0.0149,  0.1369],\n",
            "        [-0.0901,  0.0215,  0.0591,  ..., -0.0599, -0.0239, -0.0377],\n",
            "        [ 0.0754,  0.0105, -0.0172,  ...,  0.0171,  0.0826, -0.1599]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 019]: 100% 1/1 [00:00<00:00,  8.81it/s]\u001b[0m\n",
            "[Epoch 020]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1101,  0.1329, -0.0079,  ..., -0.0120,  0.0642, -0.0754],\n",
            "        [-0.0803, -0.0258, -0.0151,  ..., -0.0649, -0.0693,  0.0616],\n",
            "        [-0.0432, -0.0464, -0.0316,  ..., -0.2069,  0.0517, -0.0145],\n",
            "        ...,\n",
            "        [ 0.0107, -0.0861, -0.0484,  ..., -0.1099, -0.0741, -0.0091],\n",
            "        [-0.0162, -0.0208,  0.1026,  ..., -0.0044,  0.0194,  0.0863],\n",
            "        [ 0.1338, -0.0100, -0.0079,  ...,  0.0659,  0.1811, -0.0704]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 020]: 100% 1/1 [00:00<00:00,  6.90it/s]\u001b[0m\n",
            "[Epoch 021]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0960,  0.0782,  0.0906,  ..., -0.0529, -0.0488,  0.0786],\n",
            "        [ 0.0583, -0.1105, -0.0281,  ..., -0.0820, -0.0696, -0.0564],\n",
            "        [ 0.0110,  0.0831,  0.0492,  ..., -0.0317, -0.1640,  0.0374],\n",
            "        ...,\n",
            "        [-0.0443,  0.1431,  0.0200,  ...,  0.0447, -0.0473, -0.0630],\n",
            "        [ 0.0347, -0.1490,  0.0095,  ...,  0.0706,  0.0110, -0.0304],\n",
            "        [ 0.0005, -0.0006, -0.0018,  ..., -0.0005,  0.0007, -0.0005]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 021]: 100% 1/1 [00:00<00:00,  9.30it/s]\u001b[0m\n",
            "[Epoch 022]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-1.3669e-01, -9.6983e-02,  7.0822e-02,  ..., -2.5700e-02,\n",
            "          3.5073e-02,  1.0286e-01],\n",
            "        [ 9.6380e-03, -2.1217e-01,  2.9373e-02,  ...,  3.3810e-02,\n",
            "         -2.8383e-02, -4.1860e-02],\n",
            "        [ 5.6126e-02,  6.3124e-02, -1.7217e-02,  ..., -2.5631e-02,\n",
            "          5.7480e-02, -2.4901e-02],\n",
            "        ...,\n",
            "        [-2.9897e-02, -1.4927e-02, -3.5061e-02,  ...,  2.8050e-05,\n",
            "          3.5627e-02,  1.5271e-01],\n",
            "        [ 4.8913e-04, -6.1264e-04, -1.8425e-03,  ..., -4.9728e-04,\n",
            "          7.9020e-04, -5.8926e-04],\n",
            "        [-2.1226e-02, -7.8086e-02, -3.6090e-02,  ..., -9.1800e-02,\n",
            "          5.3812e-02, -2.6371e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 022]: 100% 1/1 [00:00<00:00,  7.57it/s]\u001b[0m\n",
            "[Epoch 023]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0178,  0.1091,  0.0005,  ...,  0.1512,  0.0301, -0.0882],\n",
            "        [ 0.0091, -0.0167, -0.0698,  ...,  0.0405, -0.0426,  0.0326],\n",
            "        [ 0.0742, -0.1007,  0.0875,  ..., -0.0277, -0.0111,  0.0378],\n",
            "        ...,\n",
            "        [ 0.0812,  0.0625, -0.0551,  ..., -0.0622, -0.0278,  0.0210],\n",
            "        [ 0.0244, -0.0335, -0.0193,  ...,  0.0960,  0.0557,  0.0028],\n",
            "        [-0.1185, -0.0504,  0.0458,  ...,  0.0493,  0.0714,  0.0347]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 023]: 100% 1/1 [00:00<00:00,  9.19it/s]\u001b[0m\n",
            "[Epoch 024]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0897, -0.0633,  0.1232,  ...,  0.0819,  0.0024,  0.1590],\n",
            "        [-0.0338,  0.1099, -0.0514,  ...,  0.0470,  0.0646, -0.0492],\n",
            "        [-0.0881,  0.0598,  0.0115,  ..., -0.0020,  0.0337,  0.0077],\n",
            "        ...,\n",
            "        [ 0.0156,  0.0403, -0.0397,  ..., -0.0616,  0.0613,  0.0479],\n",
            "        [-0.0973,  0.1125,  0.0062,  ..., -0.0377, -0.0591, -0.0376],\n",
            "        [ 0.0005, -0.0006, -0.0020,  ..., -0.0005,  0.0009, -0.0007]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 024]: 100% 1/1 [00:00<00:00,  8.41it/s]\u001b[0m\n",
            "[Epoch 025]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0653, -0.0749,  0.0594,  ..., -0.0841, -0.1654,  0.1009],\n",
            "        [-0.0595, -0.1133,  0.1591,  ..., -0.0866, -0.0064, -0.0406],\n",
            "        [ 0.0293, -0.0493,  0.1271,  ...,  0.0857,  0.0527,  0.1016],\n",
            "        ...,\n",
            "        [ 0.1497,  0.0476, -0.0334,  ..., -0.0509, -0.0385, -0.0580],\n",
            "        [ 0.0083, -0.0406, -0.0330,  ...,  0.1030,  0.0650,  0.0266],\n",
            "        [-0.0250,  0.0237,  0.0714,  ..., -0.0240, -0.1809,  0.0359]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 025]: 100% 1/1 [00:00<00:00,  7.71it/s]\u001b[0m\n",
            "[Epoch 026]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0577,  0.0719, -0.0414,  ...,  0.0211,  0.0885,  0.0149],\n",
            "        [-0.0449, -0.0177, -0.0270,  ..., -0.0338,  0.0758, -0.0408],\n",
            "        [ 0.0530, -0.0275,  0.0086,  ..., -0.0258,  0.0040,  0.0455],\n",
            "        ...,\n",
            "        [ 0.0746, -0.0227, -0.0503,  ...,  0.1703,  0.0720, -0.1366],\n",
            "        [ 0.0078, -0.0571, -0.1143,  ..., -0.0400,  0.0324, -0.1506],\n",
            "        [ 0.0170, -0.0424, -0.0335,  ...,  0.0412, -0.0104,  0.0471]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 026]: 100% 1/1 [00:00<00:00,  8.33it/s]\u001b[0m\n",
            "[Epoch 027]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0539,  0.0466,  0.0359,  ...,  0.1183, -0.0094, -0.0096],\n",
            "        [ 0.0757, -0.0010, -0.0968,  ..., -0.0065,  0.0283,  0.1212],\n",
            "        [-0.0058, -0.0195, -0.0034,  ...,  0.0555, -0.0879,  0.0011],\n",
            "        ...,\n",
            "        [-0.0350,  0.1581, -0.0364,  ...,  0.0580,  0.0649, -0.0988],\n",
            "        [ 0.0437, -0.0412,  0.0794,  ...,  0.0168,  0.0639, -0.1220],\n",
            "        [-0.0595,  0.1250,  0.0215,  ..., -0.0652, -0.0898,  0.1513]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 027]: 100% 1/1 [00:00<00:00,  7.31it/s]\u001b[0m\n",
            "[Epoch 028]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-1.7355e-01,  8.4948e-02, -4.2862e-02,  ..., -1.5506e-02,\n",
            "         -2.7808e-02,  1.3405e-02],\n",
            "        [-2.6902e-02,  8.2041e-02,  3.3026e-02,  ...,  4.3394e-02,\n",
            "         -8.6610e-03,  2.1243e-02],\n",
            "        [ 6.7949e-04, -7.6902e-04, -2.3671e-03,  ..., -7.2143e-04,\n",
            "          9.8473e-04, -7.6903e-04],\n",
            "        ...,\n",
            "        [ 1.6687e-02,  1.2813e-01,  1.5461e-02,  ...,  9.1433e-06,\n",
            "         -5.3191e-02, -1.4009e-01],\n",
            "        [ 1.7425e-02,  2.7433e-03,  6.9310e-02,  ...,  3.5575e-03,\n",
            "          3.8380e-02,  4.4826e-02],\n",
            "        [-7.3568e-02,  2.4006e-02,  3.8258e-02,  ..., -6.7515e-02,\n",
            "          7.6246e-02,  3.4984e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 028]: 100% 1/1 [00:00<00:00,  8.63it/s]\u001b[0m\n",
            "[Epoch 029]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0078, -0.0089,  0.0047,  ..., -0.1482, -0.0831, -0.0579],\n",
            "        [ 0.0007, -0.0008, -0.0025,  ..., -0.0007,  0.0010, -0.0008],\n",
            "        [ 0.0007, -0.0008, -0.0025,  ..., -0.0007,  0.0010, -0.0008],\n",
            "        ...,\n",
            "        [-0.0058, -0.0195, -0.0035,  ...,  0.0554, -0.0878,  0.0010],\n",
            "        [ 0.0681, -0.0256, -0.0253,  ...,  0.0701,  0.0586, -0.0147],\n",
            "        [ 0.0979,  0.1157, -0.0357,  ..., -0.0304,  0.0866,  0.0471]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 029]: 100% 1/1 [00:00<00:00,  7.61it/s]\u001b[0m\n",
            "[Epoch 030]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1007,  0.0738, -0.0719,  ...,  0.0208,  0.0168, -0.0824],\n",
            "        [ 0.0814,  0.0623, -0.0558,  ..., -0.0623, -0.0275,  0.0207],\n",
            "        [-0.0676,  0.3355, -0.0939,  ..., -0.0183, -0.0926, -0.1662],\n",
            "        ...,\n",
            "        [ 0.0017,  0.0230, -0.0397,  ..., -0.0633, -0.1065,  0.0051],\n",
            "        [-0.0450, -0.0035,  0.0198,  ...,  0.0885, -0.0169,  0.0572],\n",
            "        [ 0.0317, -0.0856, -0.0629,  ...,  0.0879,  0.0363, -0.0898]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 030]: 100% 1/1 [00:00<00:00,  7.39it/s]\u001b[0m\n",
            "[Epoch 031]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0007, -0.0191, -0.0107,  ...,  0.0101, -0.2054,  0.1136],\n",
            "        [-0.0731,  0.0724, -0.0767,  ..., -0.0224,  0.0920,  0.0151],\n",
            "        [-0.0702,  0.1330, -0.0234,  ..., -0.1092, -0.0310, -0.0117],\n",
            "        ...,\n",
            "        [ 0.0050, -0.0368,  0.0336,  ..., -0.0442,  0.0225, -0.0097],\n",
            "        [ 0.0640,  0.1523,  0.0874,  ..., -0.0159,  0.0429,  0.0920],\n",
            "        [ 0.0093, -0.1106, -0.0751,  ...,  0.0711,  0.0388,  0.0629]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 031]: 100% 1/1 [00:00<00:00,  8.77it/s]\u001b[0m\n",
            "[Epoch 032]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0948,  0.1038, -0.0341,  ..., -0.1361, -0.0130, -0.0315],\n",
            "        [-0.1078,  0.0119, -0.0718,  ..., -0.0477,  0.0824,  0.0470],\n",
            "        [-0.0245,  0.0842,  0.0477,  ..., -0.0624, -0.0513,  0.1129],\n",
            "        ...,\n",
            "        [-0.0219,  0.0902, -0.1297,  ...,  0.0121, -0.0905,  0.0201],\n",
            "        [-0.0891, -0.1354,  0.0249,  ..., -0.0292,  0.0019, -0.0514],\n",
            "        [-0.0579,  0.0294, -0.0788,  ...,  0.0107, -0.0257,  0.0774]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 032]: 100% 1/1 [00:00<00:00,  7.31it/s]\u001b[0m\n",
            "[Epoch 033]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0156, -0.0684,  0.0331,  ...,  0.0510, -0.0274, -0.0067],\n",
            "        [-0.0400,  0.0292, -0.0415,  ..., -0.1203, -0.0207,  0.0270],\n",
            "        [-0.1035,  0.0846,  0.0462,  ...,  0.0021,  0.0379,  0.0838],\n",
            "        ...,\n",
            "        [-0.0458,  0.0080,  0.0217,  ..., -0.0174,  0.0083,  0.0584],\n",
            "        [ 0.0165,  0.0406, -0.1084,  ..., -0.0097,  0.0867,  0.0245],\n",
            "        [-0.0516,  0.0417,  0.1575,  ..., -0.0455, -0.0232,  0.0371]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 033]: 100% 1/1 [00:00<00:00,  7.59it/s]\u001b[0m\n",
            "[Epoch 034]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1517, -0.0847, -0.0709,  ..., -0.0478, -0.0060, -0.0163],\n",
            "        [-0.0825,  0.0793, -0.0544,  ...,  0.0188,  0.0148, -0.0455],\n",
            "        [ 0.0253, -0.0431,  0.0007,  ..., -0.0261,  0.0109,  0.0363],\n",
            "        ...,\n",
            "        [-0.0436, -0.0486, -0.1400,  ..., -0.0321, -0.0326,  0.0664],\n",
            "        [ 0.0723, -0.1238,  0.0879,  ..., -0.1815, -0.0465,  0.0354],\n",
            "        [ 0.1078,  0.0127, -0.1545,  ...,  0.0810,  0.0472, -0.0744]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 034]: 100% 1/1 [00:00<00:00,  7.92it/s]\u001b[0m\n",
            "[Epoch 035]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0640,  0.1331, -0.0017,  ..., -0.0315, -0.0385,  0.1041],\n",
            "        [ 0.0288,  0.0322,  0.0535,  ..., -0.0505,  0.0464, -0.0411],\n",
            "        [-0.1184, -0.0044,  0.0183,  ...,  0.0641,  0.1594,  0.0240],\n",
            "        ...,\n",
            "        [-0.0328,  0.0380, -0.0492,  ...,  0.0264,  0.0629,  0.0847],\n",
            "        [ 0.0910,  0.0696, -0.0626,  ..., -0.0696, -0.0307,  0.0231],\n",
            "        [ 0.0537, -0.0475,  0.0643,  ...,  0.1612, -0.0416, -0.0843]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 035]: 100% 1/1 [00:00<00:00,  8.78it/s]\u001b[0m\n",
            "[Epoch 036]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0325, -0.2019, -0.1461,  ...,  0.0289,  0.0137,  0.1568],\n",
            "        [ 0.0183, -0.0738,  0.0754,  ...,  0.1413, -0.1026, -0.0724],\n",
            "        [ 0.0292, -0.0535,  0.0899,  ..., -0.1225, -0.1471,  0.0885],\n",
            "        ...,\n",
            "        [-0.0383,  0.0857,  0.0437,  ...,  0.0199, -0.0192, -0.0196],\n",
            "        [ 0.0009, -0.0009, -0.0031,  ..., -0.0008,  0.0013, -0.0010],\n",
            "        [ 0.0566, -0.0084, -0.1853,  ..., -0.0417, -0.0382, -0.0078]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 036]: 100% 1/1 [00:00<00:00,  7.65it/s]\u001b[0m\n",
            "[Epoch 037]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0233, -0.0786, -0.0639,  ..., -0.0776,  0.0487,  0.1595],\n",
            "        [-0.0421,  0.0225, -0.0260,  ...,  0.0033, -0.0217, -0.0430],\n",
            "        [ 0.0954,  0.0122, -0.0154,  ...,  0.0407,  0.0661,  0.1174],\n",
            "        ...,\n",
            "        [ 0.0009, -0.0010, -0.0032,  ..., -0.0009,  0.0013, -0.0010],\n",
            "        [-0.0536,  0.0598, -0.1097,  ..., -0.1628,  0.0177, -0.0123],\n",
            "        [ 0.0070, -0.0469,  0.0380,  ..., -0.0157, -0.0127,  0.0274]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 037]: 100% 1/1 [00:00<00:00,  8.23it/s]\u001b[0m\n",
            "[Epoch 038]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0450, -0.0961, -0.1074,  ..., -0.1159,  0.0355,  0.0986],\n",
            "        [ 0.0642, -0.0449, -0.0034,  ...,  0.0486,  0.0065,  0.0787],\n",
            "        [-0.0384, -0.0158,  0.0266,  ...,  0.0040, -0.0777, -0.0016],\n",
            "        ...,\n",
            "        [-0.1076,  0.1267, -0.0279,  ...,  0.0914,  0.0361, -0.0092],\n",
            "        [ 0.0009, -0.0010, -0.0033,  ..., -0.0009,  0.0013, -0.0011],\n",
            "        [ 0.1010,  0.0403,  0.0531,  ...,  0.0989, -0.2322,  0.0723]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 038]: 100% 1/1 [00:00<00:00,  9.42it/s]\u001b[0m\n",
            "[Epoch 039]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0236, -0.0391,  0.1046,  ...,  0.1185, -0.1397,  0.0718],\n",
            "        [ 0.0764,  0.1315, -0.0827,  ..., -0.0318,  0.0287, -0.0605],\n",
            "        [ 0.1597, -0.1052, -0.0441,  ..., -0.0470, -0.0311,  0.1087],\n",
            "        ...,\n",
            "        [-0.0178,  0.0179, -0.0771,  ...,  0.1660, -0.0439, -0.0888],\n",
            "        [-0.0404, -0.0528,  0.1321,  ..., -0.0272, -0.0973,  0.0198],\n",
            "        [ 0.0303, -0.0208, -0.2035,  ...,  0.0241, -0.0347, -0.0533]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 039]: 100% 1/1 [00:00<00:00,  7.32it/s]\u001b[0m\n",
            "[Epoch 040]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0597, -0.0323, -0.1087,  ..., -0.1459, -0.0449,  0.1198],\n",
            "        [-0.0137,  0.0872, -0.1528,  ...,  0.0575,  0.0475,  0.0381],\n",
            "        [ 0.0156,  0.0052,  0.0373,  ..., -0.0782,  0.0834, -0.1277],\n",
            "        ...,\n",
            "        [ 0.0020,  0.0228, -0.0405,  ..., -0.0635, -0.1062,  0.0049],\n",
            "        [ 0.0364, -0.0675,  0.1482,  ...,  0.2184, -0.1422,  0.0474],\n",
            "        [ 0.0010, -0.0010, -0.0035,  ..., -0.0009,  0.0014, -0.0011]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 040]: 100% 1/1 [00:00<00:00,  8.99it/s]\u001b[0m\n",
            "[Epoch 041]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0526, -0.0540, -0.0385,  ...,  0.0288,  0.0566,  0.1040],\n",
            "        [ 0.0098, -0.0171, -0.0713,  ...,  0.0400, -0.0423,  0.0323],\n",
            "        [-0.1533, -0.0484, -0.0121,  ...,  0.0596,  0.1505, -0.0385],\n",
            "        ...,\n",
            "        [ 0.0141,  0.1543,  0.0441,  ..., -0.0609,  0.0287, -0.1623],\n",
            "        [-0.0093,  0.0144,  0.0011,  ...,  0.1055,  0.0235, -0.0791],\n",
            "        [ 0.0173,  0.0353, -0.1527,  ...,  0.0719,  0.0740, -0.1495]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 041]: 100% 1/1 [00:00<00:00,  7.07it/s]\u001b[0m\n",
            "[Epoch 042]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0934, -0.0488,  0.1212,  ...,  0.0105, -0.0657,  0.1628],\n",
            "        [ 0.0068, -0.0454, -0.0473,  ...,  0.0026,  0.0869,  0.0670],\n",
            "        [-0.0770,  0.0200,  0.0249,  ..., -0.1749,  0.2009,  0.1241],\n",
            "        ...,\n",
            "        [ 0.0010, -0.0010, -0.0036,  ..., -0.0010,  0.0015, -0.0012],\n",
            "        [-0.1025,  0.0842, -0.0261,  ..., -0.1152, -0.0948, -0.0237],\n",
            "        [-0.0225, -0.0381, -0.0225,  ...,  0.0977,  0.0944,  0.0512]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 042]: 100% 1/1 [00:00<00:00,  8.00it/s]\u001b[0m\n",
            "[Epoch 043]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0153, -0.0071,  0.0733,  ..., -0.0440,  0.0295, -0.0518],\n",
            "        [-0.0601, -0.0379,  0.1100,  ...,  0.0374,  0.0640, -0.0354],\n",
            "        [ 0.0699, -0.0884, -0.0213,  ..., -0.1978, -0.0569,  0.0852],\n",
            "        ...,\n",
            "        [-0.0428, -0.0444,  0.0919,  ...,  0.0213, -0.0111,  0.1355],\n",
            "        [-0.0516, -0.0155,  0.0889,  ..., -0.0881, -0.0712, -0.0040],\n",
            "        [ 0.0712,  0.0183, -0.0892,  ..., -0.0648, -0.1386, -0.0305]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 043]: 100% 1/1 [00:00<00:00,  8.67it/s]\u001b[0m\n",
            "[Epoch 044]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0010, -0.0011, -0.0038,  ..., -0.0010,  0.0015, -0.0013],\n",
            "        [-0.0516,  0.0420,  0.0118,  ...,  0.0451, -0.0373,  0.0230],\n",
            "        [-0.0755,  0.0644,  0.0575,  ...,  0.1006, -0.0724,  0.0331],\n",
            "        ...,\n",
            "        [-0.1351, -0.0539,  0.0451,  ...,  0.0932, -0.1419, -0.0235],\n",
            "        [ 0.0755,  0.0861,  0.0789,  ...,  0.0096, -0.0349, -0.0636],\n",
            "        [ 0.0330,  0.0056,  0.0301,  ..., -0.0037,  0.0651, -0.0311]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 044]: 100% 1/1 [00:00<00:00,  7.23it/s]\u001b[0m\n",
            "[Epoch 045]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0448,  0.1153, -0.1754,  ...,  0.0763,  0.0442,  0.0935],\n",
            "        [-0.0886,  0.0475,  0.0653,  ..., -0.1154, -0.0794,  0.1522],\n",
            "        [-0.0042, -0.0040,  0.0298,  ..., -0.1434,  0.1820,  0.0410],\n",
            "        ...,\n",
            "        [ 0.0048, -0.1127,  0.0823,  ...,  0.2850, -0.0957, -0.0355],\n",
            "        [ 0.0400, -0.0365, -0.1275,  ..., -0.0355, -0.0079,  0.0068],\n",
            "        [ 0.0637,  0.1030,  0.0706,  ...,  0.1656,  0.0739,  0.0556]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 045]: 100% 1/1 [00:00<00:00,  7.40it/s]\u001b[0m\n",
            "[Epoch 046]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0113,  0.0849,  0.0485,  ...,  0.0313, -0.0550,  0.1899],\n",
            "        [-0.1242,  0.0243,  0.0139,  ...,  0.0552,  0.0386, -0.0332],\n",
            "        [ 0.0764, -0.0979,  0.0108,  ...,  0.1052,  0.0024, -0.1213],\n",
            "        ...,\n",
            "        [-0.1043,  0.0689,  0.0259,  ..., -0.0650, -0.0193,  0.0323],\n",
            "        [-0.0521, -0.0951,  0.1227,  ...,  0.1658,  0.1080, -0.0777],\n",
            "        [ 0.0730,  0.0253,  0.0470,  ...,  0.0035,  0.0617,  0.0398]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 046]: 100% 1/1 [00:00<00:00,  6.99it/s]\u001b[0m\n",
            "[Epoch 047]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0274,  0.0883, -0.1780,  ...,  0.1062,  0.0355,  0.0020],\n",
            "        [-0.0229,  0.0108,  0.0416,  ...,  0.0021, -0.0453, -0.0985],\n",
            "        [-0.0041,  0.0563, -0.1426,  ..., -0.0523,  0.0949,  0.0044],\n",
            "        ...,\n",
            "        [-0.0181, -0.0114, -0.0589,  ..., -0.0331,  0.0355, -0.0009],\n",
            "        [-0.2009,  0.1214, -0.0559,  ..., -0.0099,  0.1196, -0.0887],\n",
            "        [ 0.1255, -0.1147, -0.0111,  ..., -0.0610, -0.1093,  0.0101]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 047]: 100% 1/1 [00:00<00:00,  8.56it/s]\u001b[0m\n",
            "[Epoch 048]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0012, -0.0011, -0.0042,  ..., -0.0011,  0.0017, -0.0014],\n",
            "        [ 0.0016,  0.0673, -0.0190,  ..., -0.0080,  0.0468, -0.0398],\n",
            "        [ 0.0012, -0.0011, -0.0042,  ..., -0.0011,  0.0017, -0.0014],\n",
            "        ...,\n",
            "        [ 0.0402,  0.0790, -0.1168,  ..., -0.1336,  0.0175,  0.0352],\n",
            "        [ 0.0055, -0.0023, -0.0503,  ...,  0.0293, -0.0637,  0.2143],\n",
            "        [ 0.0027,  0.0136, -0.0270,  ...,  0.1704, -0.0060, -0.0830]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 048]: 100% 1/1 [00:00<00:00,  6.87it/s]\u001b[0m\n",
            "[Epoch 049]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1378,  0.0224, -0.0370,  ..., -0.1024,  0.0483,  0.1354],\n",
            "        [ 0.0741, -0.0968,  0.0676,  ...,  0.0483, -0.0800, -0.0533],\n",
            "        [ 0.0302, -0.0576,  0.1015,  ...,  0.0758, -0.0300,  0.0957],\n",
            "        ...,\n",
            "        [-0.1023,  0.0842, -0.0268,  ..., -0.1153, -0.0945, -0.0240],\n",
            "        [ 0.0700,  0.0582,  0.0732,  ...,  0.1792,  0.1181, -0.0188],\n",
            "        [ 0.0375,  0.0156,  0.0500,  ...,  0.0509, -0.0578, -0.0845]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 049]: 100% 1/1 [00:00<00:00,  7.94it/s]\u001b[0m\n",
            "[Epoch 050]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0436,  0.0777, -0.0110,  ...,  0.0276,  0.0841,  0.0529],\n",
            "        [-0.0345,  0.0814, -0.0528,  ..., -0.1867, -0.0409, -0.0330],\n",
            "        [-0.0175,  0.0177, -0.0780,  ...,  0.1658, -0.0436, -0.0891],\n",
            "        ...,\n",
            "        [-0.0931, -0.0489,  0.1205,  ...,  0.0103, -0.0654,  0.1625],\n",
            "        [ 0.0314,  0.0933,  0.0964,  ..., -0.0821, -0.1005,  0.1070],\n",
            "        [ 0.0961,  0.0774, -0.0697,  ...,  0.0359, -0.0446, -0.0269]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 050]: 100% 1/1 [00:00<00:00,  7.32it/s]\u001b[0m\n",
            "[Epoch 051]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0902,  0.0756,  0.0381,  ...,  0.1226,  0.0511,  0.0354],\n",
            "        [-0.0734,  0.0143,  0.0135,  ..., -0.1366, -0.0345,  0.0407],\n",
            "        [ 0.0426,  0.0078, -0.1075,  ...,  0.0863,  0.0017,  0.2305],\n",
            "        ...,\n",
            "        [ 0.0668,  0.0372, -0.0904,  ..., -0.0332,  0.0232, -0.0390],\n",
            "        [ 0.0591, -0.1109, -0.0308,  ..., -0.0827, -0.0687, -0.0574],\n",
            "        [-0.0265,  0.0438, -0.0460,  ..., -0.0331,  0.1401,  0.0047]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 051]: 100% 1/1 [00:00<00:00,  8.47it/s]\u001b[0m\n",
            "[Epoch 052]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0257,  0.1006, -0.0614,  ...,  0.0079,  0.0253,  0.0737],\n",
            "        [-0.0273,  0.0882, -0.1784,  ...,  0.1061,  0.0357,  0.0019],\n",
            "        [ 0.0101, -0.0171, -0.0722,  ...,  0.0397, -0.0420,  0.0320],\n",
            "        ...,\n",
            "        [-0.0305,  0.0927,  0.0890,  ..., -0.0125, -0.0092,  0.0730],\n",
            "        [ 0.0117, -0.0039,  0.0470,  ..., -0.0664, -0.0151,  0.0357],\n",
            "        [ 0.0586,  0.0280, -0.0207,  ..., -0.1410, -0.1146,  0.0790]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 052]: 100% 1/1 [00:00<00:00,  7.25it/s]\u001b[0m\n",
            "[Epoch 053]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0013, -0.0012, -0.0047,  ..., -0.0012,  0.0018, -0.0016],\n",
            "        [ 0.0262, -0.0714, -0.0120,  ...,  0.0822,  0.0895,  0.0218],\n",
            "        [ 0.0011, -0.0038,  0.0559,  ...,  0.0293, -0.0424,  0.0794],\n",
            "        ...,\n",
            "        [ 0.0592, -0.1110, -0.0310,  ..., -0.0827, -0.0686, -0.0575],\n",
            "        [ 0.1181,  0.0257,  0.0838,  ..., -0.0035, -0.0248,  0.0049],\n",
            "        [-0.0392,  0.0290, -0.0433,  ..., -0.1206, -0.0203,  0.0265]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 053]: 100% 1/1 [00:00<00:00,  9.36it/s]\u001b[0m\n",
            "[Epoch 054]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-7.2594e-02,  9.1293e-02,  7.7562e-02,  ...,  4.0675e-02,\n",
            "          5.0050e-02, -2.9551e-02],\n",
            "        [ 5.8049e-02, -6.3393e-02, -8.9702e-03,  ...,  7.0664e-02,\n",
            "         -7.8988e-02,  1.2410e-01],\n",
            "        [ 1.0170e-02, -9.6668e-02,  3.7374e-02,  ...,  4.4851e-02,\n",
            "          4.3720e-03, -1.1277e-01],\n",
            "        ...,\n",
            "        [-5.5371e-02, -3.9220e-02,  6.2997e-02,  ...,  6.7664e-02,\n",
            "         -1.8471e-04,  1.7886e-01],\n",
            "        [ 1.0855e-03, -1.9533e-02, -1.2529e-02,  ...,  9.6378e-03,\n",
            "         -2.0454e-01,  1.1271e-01],\n",
            "        [ 1.6054e-02,  3.8264e-02, -4.2744e-02,  ..., -6.9885e-02,\n",
            "         -2.8010e-03,  3.6350e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 054]: 100% 1/1 [00:00<00:00,  7.81it/s]\u001b[0m\n",
            "[Epoch 055]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1118,  0.0357, -0.0590,  ...,  0.0468,  0.0384, -0.0477],\n",
            "        [-0.0481,  0.0480, -0.1045,  ...,  0.0115, -0.0466, -0.0469],\n",
            "        [-0.1191, -0.1200,  0.0940,  ..., -0.0854,  0.0822,  0.1400],\n",
            "        ...,\n",
            "        [ 0.0823, -0.0043,  0.0400,  ...,  0.1176,  0.0552, -0.1607],\n",
            "        [ 0.0288, -0.1147,  0.0227,  ...,  0.1533, -0.0304,  0.0198],\n",
            "        [ 0.0099,  0.0065,  0.0310,  ...,  0.0363,  0.0708,  0.1082]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 055]: 100% 1/1 [00:00<00:00,  8.41it/s]\u001b[0m\n",
            "[Epoch 056]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0244, -0.1066, -0.0046,  ...,  0.0546, -0.0442,  0.2046],\n",
            "        [ 0.0025,  0.0227, -0.0419,  ..., -0.0638, -0.1058,  0.0044],\n",
            "        [-0.1093,  0.0257, -0.1267,  ..., -0.0314,  0.0584,  0.0151],\n",
            "        ...,\n",
            "        [-0.0322, -0.2019, -0.1481,  ...,  0.0282,  0.0144,  0.1559],\n",
            "        [-0.0246, -0.0426, -0.0754,  ..., -0.0493,  0.0334, -0.0189],\n",
            "        [-0.0504,  0.0131, -0.0181,  ...,  0.0213, -0.0327,  0.0322]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 056]: 100% 1/1 [00:00<00:00,  8.38it/s]\u001b[0m\n",
            "[Epoch 057]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0588, -0.1139,  0.1560,  ..., -0.0875, -0.0055, -0.0415],\n",
            "        [-0.0309, -0.1431,  0.1635,  ..., -0.0403, -0.0491,  0.0463],\n",
            "        [-0.1178,  0.1357, -0.1012,  ..., -0.0208,  0.1232, -0.0082],\n",
            "        ...,\n",
            "        [ 0.0495, -0.0972,  0.0791,  ...,  0.0047,  0.0268,  0.0274],\n",
            "        [-0.0970,  0.0116,  0.0224,  ...,  0.0279, -0.0034,  0.0370],\n",
            "        [ 0.0524,  0.0018,  0.0303,  ..., -0.0179,  0.0399,  0.0767]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 057]: 100% 1/1 [00:00<00:00,  6.77it/s]\u001b[0m\n",
            "[Epoch 058]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0905, -0.0486, -0.0735,  ..., -0.1251, -0.0283,  0.0502],\n",
            "        [-0.0322, -0.2019, -0.1484,  ...,  0.0281,  0.0145,  0.1557],\n",
            "        [ 0.0014, -0.0012, -0.0051,  ..., -0.0013,  0.0020, -0.0018],\n",
            "        ...,\n",
            "        [-0.0081, -0.0243, -0.0389,  ...,  0.0657, -0.0478,  0.1662],\n",
            "        [ 0.0014, -0.0012, -0.0051,  ..., -0.0013,  0.0020, -0.0018],\n",
            "        [ 0.0745, -0.0110, -0.0079,  ...,  0.1031,  0.0128, -0.2992]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 058]: 100% 1/1 [00:00<00:00,  8.30it/s]\u001b[0m\n",
            "[Epoch 059]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1912, -0.0231, -0.1049,  ..., -0.0620,  0.0166,  0.1026],\n",
            "        [ 0.1023, -0.0092,  0.1166,  ..., -0.1396, -0.1826,  0.0911],\n",
            "        [ 0.0754,  0.0487, -0.0989,  ..., -0.0999, -0.0676,  0.1495],\n",
            "        ...,\n",
            "        [ 0.0592, -0.0376, -0.0040,  ..., -0.0009, -0.0537, -0.1929],\n",
            "        [ 0.0516, -0.1190,  0.0291,  ...,  0.0134, -0.0171,  0.0016],\n",
            "        [-0.1008,  0.1666,  0.0460,  ...,  0.0271, -0.0542, -0.0616]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 059]: 100% 1/1 [00:00<00:00,  7.24it/s]\u001b[0m\n",
            "[Epoch 060]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0747,  0.0532, -0.0347,  ...,  0.2211,  0.0174, -0.1610],\n",
            "        [ 0.0781, -0.0519, -0.0705,  ...,  0.0558,  0.0061,  0.1003],\n",
            "        [ 0.1175, -0.0163,  0.0153,  ..., -0.0971, -0.1134,  0.0125],\n",
            "        ...,\n",
            "        [-0.1060,  0.0557,  0.0171,  ..., -0.1814,  0.2171,  0.0507],\n",
            "        [-0.0271,  0.0881, -0.1792,  ...,  0.1059,  0.0360,  0.0016],\n",
            "        [ 0.0384,  0.1607,  0.0855,  ...,  0.0324, -0.1035,  0.1280]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 060]: 100% 1/1 [00:00<00:00,  8.83it/s]\u001b[0m\n",
            "[Epoch 061]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0375, -0.0973, -0.1095,  ..., -0.0779,  0.0996,  0.0902],\n",
            "        [ 0.1190,  0.0762,  0.0158,  ...,  0.0012, -0.1179,  0.0327],\n",
            "        [ 0.0031,  0.0558,  0.0802,  ...,  0.0344,  0.1161,  0.0522],\n",
            "        ...,\n",
            "        [ 0.0692, -0.0824, -0.0836,  ..., -0.0413, -0.0201,  0.0604],\n",
            "        [ 0.1018,  0.0618,  0.0536,  ...,  0.1926,  0.0636, -0.0535],\n",
            "        [ 0.0166, -0.0091, -0.0121,  ...,  0.0728,  0.0621, -0.0140]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 061]: 100% 1/1 [00:00<00:00,  8.75it/s]\u001b[0m\n",
            "[Epoch 062]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-3.7461e-02, -8.8405e-03, -1.2198e-01,  ...,  3.3298e-02,\n",
            "          4.9745e-02,  1.7668e-02],\n",
            "        [-1.5419e-02, -6.8381e-02,  1.6148e-02,  ..., -2.6112e-02,\n",
            "         -6.6269e-02, -1.4031e-01],\n",
            "        [ 1.1595e-01, -1.2530e-01,  5.0164e-02,  ...,  1.6186e-01,\n",
            "         -1.1987e-01, -9.5321e-05],\n",
            "        ...,\n",
            "        [ 8.5005e-02,  8.5722e-02, -1.2525e-01,  ..., -7.4743e-03,\n",
            "          5.8692e-02,  4.8888e-02],\n",
            "        [ 7.6705e-02, -1.2098e-03,  5.1651e-02,  ...,  1.6915e-03,\n",
            "         -6.8007e-03,  1.2448e-01],\n",
            "        [ 4.8494e-02,  4.2405e-02, -7.5119e-02,  ...,  2.7276e-02,\n",
            "         -2.0140e-03, -3.2063e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 062]: 100% 1/1 [00:00<00:00,  7.21it/s]\u001b[0m\n",
            "[Epoch 063]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0907,  0.0726,  0.0468,  ...,  0.1338,  0.0275, -0.1372],\n",
            "        [ 0.0740, -0.0600, -0.0898,  ..., -0.0490,  0.1466, -0.0884],\n",
            "        [-0.0009, -0.0302, -0.0574,  ...,  0.0767, -0.0011,  0.0338],\n",
            "        ...,\n",
            "        [-0.0434,  0.0839,  0.0196,  ...,  0.0361,  0.0183, -0.1052],\n",
            "        [-0.0326,  0.0527, -0.0546,  ...,  0.0463,  0.0081, -0.0726],\n",
            "        [-0.0484,  0.0607,  0.0128,  ..., -0.0587,  0.0062,  0.0446]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 063]: 100% 1/1 [00:00<00:00,  7.79it/s]\u001b[0m\n",
            "[Epoch 064]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0244, -0.0428, -0.0762,  ..., -0.0495,  0.0337, -0.0192],\n",
            "        [ 0.1260, -0.1151, -0.0127,  ..., -0.0615, -0.1086,  0.0094],\n",
            "        [-0.0206, -0.0219,  0.0270,  ...,  0.1105,  0.0598,  0.0027],\n",
            "        ...,\n",
            "        [ 0.0195,  0.1296, -0.1005,  ...,  0.1239, -0.0849, -0.0353],\n",
            "        [-0.0633,  0.0780, -0.0369,  ...,  0.0367,  0.0834, -0.0205],\n",
            "        [ 0.0849, -0.0797,  0.1435,  ..., -0.0571,  0.0405, -0.0231]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 064]: 100% 1/1 [00:00<00:00,  8.61it/s]\u001b[0m\n",
            "[Epoch 065]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1134,  0.0742,  0.0514,  ..., -0.0389, -0.0763,  0.1192],\n",
            "        [ 0.0327, -0.1292, -0.0768,  ..., -0.0040,  0.0814,  0.0440],\n",
            "        [ 0.0519,  0.0402, -0.1196,  ..., -0.0213,  0.0366,  0.1116],\n",
            "        ...,\n",
            "        [ 0.0016, -0.0014, -0.0057,  ..., -0.0014,  0.0023, -0.0020],\n",
            "        [ 0.0516, -0.0165,  0.0307,  ...,  0.1024, -0.0092, -0.1187],\n",
            "        [-0.0044,  0.0405, -0.0248,  ..., -0.1141, -0.0781, -0.0240]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 065]: 100% 1/1 [00:00<00:00,  7.69it/s]\u001b[0m\n",
            "[Epoch 066]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0586,  0.0421, -0.0119,  ...,  0.0798, -0.1301,  0.0844],\n",
            "        [ 0.0878,  0.1015, -0.0748,  ..., -0.0888, -0.0359, -0.0618],\n",
            "        [-0.0594,  0.0795, -0.0474,  ...,  0.0197,  0.0638, -0.1276],\n",
            "        ...,\n",
            "        [-0.0744, -0.0344,  0.0412,  ..., -0.0780,  0.0592,  0.0175],\n",
            "        [ 0.0198,  0.0510,  0.0232,  ...,  0.0355,  0.0431, -0.0070],\n",
            "        [-0.0205,  0.0254, -0.0501,  ..., -0.0014, -0.0546,  0.0107]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 066]: 100% 1/1 [00:00<00:00,  6.83it/s]\u001b[0m\n",
            "[Epoch 067]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0852,  0.0358,  0.0241,  ...,  0.0038, -0.0282,  0.0556],\n",
            "        [ 0.0617,  0.0357,  0.0077,  ...,  0.1793,  0.0353, -0.2130],\n",
            "        [ 0.0509,  0.0310, -0.1054,  ...,  0.0744,  0.1364, -0.0146],\n",
            "        ...,\n",
            "        [-0.1019,  0.0839, -0.0283,  ..., -0.1156, -0.0938, -0.0245],\n",
            "        [ 0.0557, -0.0852,  0.0105,  ..., -0.0468, -0.0343, -0.1108],\n",
            "        [-0.0271, -0.0467, -0.0536,  ...,  0.0373, -0.0033, -0.0886]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 067]: 100% 1/1 [00:00<00:00,  8.69it/s]\u001b[0m\n",
            "[Epoch 068]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0536, -0.0574,  0.0242,  ..., -0.0646, -0.0931, -0.0755],\n",
            "        [-0.0956,  0.1206,  0.0566,  ...,  0.0031,  0.0622,  0.0141],\n",
            "        [ 0.0191,  0.0419, -0.0688,  ...,  0.1709, -0.1237,  0.0519],\n",
            "        ...,\n",
            "        [-0.0308,  0.1203, -0.0020,  ...,  0.1048,  0.1030, -0.0021],\n",
            "        [-0.0170,  0.0172, -0.0794,  ...,  0.1654, -0.0430, -0.0896],\n",
            "        [-0.0007,  0.0204, -0.1995,  ..., -0.0582, -0.0015,  0.1733]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 068]: 100% 1/1 [00:00<00:00,  7.11it/s]\u001b[0m\n",
            "[Epoch 069]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0630, -0.0702,  0.0103,  ...,  0.0120, -0.0099,  0.1030],\n",
            "        [-0.0384,  0.0287, -0.0446,  ..., -0.1209, -0.0198,  0.0263],\n",
            "        [-0.0398,  0.0617, -0.1040,  ...,  0.0418, -0.0386,  0.0812],\n",
            "        ...,\n",
            "        [ 0.1735,  0.1065,  0.0593,  ...,  0.0430,  0.1043,  0.1058],\n",
            "        [-0.0045,  0.0673, -0.0934,  ..., -0.0024, -0.0838,  0.0547],\n",
            "        [ 0.0897,  0.0495,  0.0762,  ..., -0.0574, -0.0578,  0.0137]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 069]: 100% 1/1 [00:00<00:00,  8.29it/s]\u001b[0m\n",
            "[Epoch 070]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0048, -0.0202, -0.0071,  ...,  0.0545, -0.0863, -0.0004],\n",
            "        [ 0.0160, -0.0120, -0.1105,  ...,  0.0014,  0.0199,  0.1117],\n",
            "        [ 0.0018, -0.0015, -0.0061,  ..., -0.0016,  0.0025, -0.0021],\n",
            "        ...,\n",
            "        [ 0.0432,  0.0073, -0.1092,  ...,  0.0859,  0.0025,  0.2299],\n",
            "        [ 0.1347, -0.0728, -0.1246,  ...,  0.0480, -0.0686, -0.0086],\n",
            "        [-0.0232,  0.0239,  0.0894,  ...,  0.1277,  0.0633,  0.0240]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 070]: 100% 1/1 [00:00<00:00,  7.26it/s]\u001b[0m\n",
            "[Epoch 071]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1169,  0.0068, -0.1158,  ..., -0.0076,  0.0663,  0.1946],\n",
            "        [-0.0145,  0.0459, -0.0278,  ...,  0.0872, -0.0396, -0.1254],\n",
            "        [ 0.1604, -0.0862,  0.0222,  ..., -0.0338,  0.0596,  0.0126],\n",
            "        ...,\n",
            "        [ 0.0446,  0.0700,  0.0799,  ...,  0.0604, -0.0310,  0.0374],\n",
            "        [ 0.0015,  0.1240,  0.0022,  ..., -0.0582, -0.0347, -0.0967],\n",
            "        [ 0.0018, -0.0015, -0.0062,  ..., -0.0016,  0.0025, -0.0022]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 071]: 100% 1/1 [00:00<00:00,  8.32it/s]\u001b[0m\n",
            "[Epoch 072]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0151, -0.1316,  0.1316,  ...,  0.0423, -0.0543, -0.0912],\n",
            "        [ 0.0018, -0.0015, -0.0063,  ..., -0.0016,  0.0026, -0.0022],\n",
            "        [ 0.1107, -0.0537, -0.0288,  ..., -0.0223, -0.1369, -0.0775],\n",
            "        ...,\n",
            "        [-0.0227,  0.1931, -0.0917,  ...,  0.0971,  0.0760, -0.0720],\n",
            "        [ 0.0263,  0.0133,  0.0264,  ...,  0.1197,  0.0752, -0.1704],\n",
            "        [ 0.0361, -0.0261, -0.0646,  ..., -0.0508,  0.0657, -0.0338]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 072]: 100% 1/1 [00:00<00:00,  8.99it/s]\u001b[0m\n",
            "[Epoch 073]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0378,  0.0224, -0.0644,  ...,  0.0551,  0.0090,  0.1223],\n",
            "        [ 0.0018, -0.0015, -0.0064,  ..., -0.0016,  0.0026, -0.0022],\n",
            "        [ 0.0402,  0.1173, -0.0427,  ...,  0.1376, -0.0028, -0.0915],\n",
            "        ...,\n",
            "        [ 0.0407, -0.0929, -0.0613,  ..., -0.0770,  0.0053,  0.0270],\n",
            "        [ 0.1813, -0.0538, -0.0997,  ..., -0.0073,  0.1003,  0.0612],\n",
            "        [-0.0995,  0.0730, -0.0757,  ...,  0.0200,  0.0182, -0.0837]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 073]: 100% 1/1 [00:00<00:00,  7.49it/s]\u001b[0m\n",
            "[Epoch 074]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0208, -0.0276,  0.0042,  ...,  0.1131,  0.0502, -0.0909],\n",
            "        [-0.0559,  0.0648,  0.0327,  ..., -0.0864, -0.0483,  0.0730],\n",
            "        [ 0.0096,  0.0489, -0.0508,  ...,  0.0712,  0.1184, -0.0197],\n",
            "        ...,\n",
            "        [-0.1327, -0.0783,  0.0738,  ..., -0.0062,  0.0464,  0.0303],\n",
            "        [ 0.0773, -0.0988,  0.0082,  ...,  0.1047,  0.0039, -0.1219],\n",
            "        [-0.0317, -0.2022, -0.1498,  ...,  0.0277,  0.0151,  0.1552]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 074]: 100% 1/1 [00:00<00:00,  9.19it/s]\u001b[0m\n",
            "[Epoch 075]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0307,  0.0686,  0.0695,  ...,  0.1487, -0.0275, -0.0189],\n",
            "        [-0.0194,  0.0439, -0.0903,  ..., -0.0799, -0.0017, -0.0473],\n",
            "        [ 0.1198, -0.0819, -0.0442,  ...,  0.0462,  0.0083, -0.2744],\n",
            "        ...,\n",
            "        [ 0.0020, -0.1395,  0.1048,  ...,  0.1186,  0.1480, -0.1034],\n",
            "        [-0.0411, -0.0637, -0.0738,  ..., -0.0065, -0.0212,  0.0726],\n",
            "        [ 0.0834,  0.1068, -0.1209,  ...,  0.0469,  0.1093, -0.0791]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 075]: 100% 1/1 [00:00<00:00,  7.03it/s]\u001b[0m\n",
            "[Epoch 076]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0152,  0.1417, -0.0356,  ...,  0.0150, -0.0665, -0.0566],\n",
            "        [-0.0407, -0.0504, -0.0234,  ...,  0.2254, -0.0107,  0.0527],\n",
            "        [-0.0700,  0.0958,  0.0411,  ..., -0.0742,  0.0311, -0.0814],\n",
            "        ...,\n",
            "        [-0.0552,  0.0056,  0.0446,  ..., -0.0031,  0.1093,  0.1764],\n",
            "        [ 0.0985,  0.0041, -0.0464,  ..., -0.0306,  0.1819,  0.0230],\n",
            "        [-0.0238, -0.0068, -0.1755,  ...,  0.0782, -0.0465,  0.0903]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 076]: 100% 1/1 [00:00<00:00,  8.00it/s]\u001b[0m\n",
            "[Epoch 077]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0020, -0.0016, -0.0067,  ..., -0.0017,  0.0028, -0.0023],\n",
            "        [ 0.0893,  0.0609, -0.0521,  ..., -0.0796,  0.0071, -0.0079],\n",
            "        [-0.0167,  0.0169, -0.0801,  ...,  0.1652, -0.0427, -0.0898],\n",
            "        ...,\n",
            "        [-0.1556, -0.0066,  0.0130,  ...,  0.0190,  0.1287,  0.0230],\n",
            "        [ 0.0684,  0.0279, -0.0216,  ...,  0.0579,  0.0340,  0.0310],\n",
            "        [ 0.1264, -0.1155, -0.0137,  ..., -0.0620, -0.1081,  0.0090]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 077]: 100% 1/1 [00:00<00:00,  7.32it/s]\u001b[0m\n",
            "[Epoch 078]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0044, -0.0142, -0.0477,  ..., -0.0391, -0.0381,  0.1278],\n",
            "        [-0.0641,  0.0061, -0.0169,  ...,  0.0757,  0.0393,  0.1266],\n",
            "        [-0.0107,  0.0215, -0.0270,  ..., -0.0585, -0.1662, -0.0228],\n",
            "        ...,\n",
            "        [ 0.1776,  0.0844, -0.0293,  ...,  0.0630, -0.0969, -0.0727],\n",
            "        [-0.0224,  0.0228, -0.0488,  ..., -0.0146, -0.0224,  0.0837],\n",
            "        [-0.0315, -0.1705,  0.0547,  ...,  0.0604,  0.1275,  0.0216]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 078]: 100% 1/1 [00:00<00:00,  8.82it/s]\u001b[0m\n",
            "[Epoch 079]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1310,  0.0399, -0.0309,  ...,  0.0607,  0.2034, -0.0976],\n",
            "        [-0.1183,  0.0973, -0.0670,  ..., -0.1453,  0.2057,  0.0277],\n",
            "        [ 0.0760,  0.0484, -0.1013,  ..., -0.1000, -0.0666,  0.1483],\n",
            "        ...,\n",
            "        [ 0.0427, -0.0016,  0.0865,  ..., -0.0912,  0.0372, -0.0293],\n",
            "        [-0.0486, -0.0105,  0.0133,  ..., -0.0301,  0.0019,  0.0500],\n",
            "        [-0.0590, -0.0828,  0.0072,  ...,  0.0401, -0.0260,  0.1759]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 079]: 100% 1/1 [00:00<00:00,  8.52it/s]\u001b[0m\n",
            "[Epoch 080]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0277, -0.1806,  0.1013,  ..., -0.3196,  0.0264, -0.0688],\n",
            "        [ 0.0343, -0.0917, -0.0230,  ..., -0.0625,  0.0403, -0.0502],\n",
            "        [ 0.0812, -0.0359,  0.0318,  ..., -0.0213, -0.0095, -0.1257],\n",
            "        ...,\n",
            "        [ 0.0163,  0.0267,  0.0867,  ...,  0.1366,  0.0164, -0.1164],\n",
            "        [ 0.0637, -0.0364, -0.0107,  ..., -0.1577, -0.2078,  0.1805],\n",
            "        [-0.1153,  0.1008, -0.0558,  ..., -0.0377,  0.0811, -0.0621]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 080]: 100% 1/1 [00:00<00:00,  7.10it/s]\u001b[0m\n",
            "[Epoch 081]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1600,  0.1309, -0.0435,  ...,  0.0408,  0.2254, -0.1383],\n",
            "        [ 0.0712, -0.1349,  0.1324,  ..., -0.1142, -0.0251, -0.0558],\n",
            "        [ 0.0007,  0.0040, -0.1177,  ..., -0.0616,  0.0678,  0.0252],\n",
            "        ...,\n",
            "        [ 0.0922,  0.0688, -0.0672,  ..., -0.0701, -0.0291,  0.0208],\n",
            "        [ 0.0510,  0.0106,  0.0095,  ...,  0.0155, -0.0152, -0.0265],\n",
            "        [-0.0510, -0.0955,  0.1197,  ...,  0.1651,  0.1091, -0.0790]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 081]: 100% 1/1 [00:00<00:00,  8.27it/s]\u001b[0m\n",
            "[Epoch 082]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0849, -0.1082,  0.0737,  ..., -0.0322,  0.0939,  0.1773],\n",
            "        [-0.1391,  0.0424,  0.0198,  ...,  0.0012,  0.1112,  0.0076],\n",
            "        [-0.0461,  0.0720, -0.0738,  ...,  0.1109, -0.0156,  0.0154],\n",
            "        ...,\n",
            "        [-0.0273,  0.0004, -0.0224,  ..., -0.1175, -0.0465,  0.0081],\n",
            "        [ 0.1137, -0.0130, -0.0657,  ...,  0.0354,  0.1088,  0.0266],\n",
            "        [-0.0320,  0.0506,  0.1619,  ...,  0.0916,  0.0956,  0.1114]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 082]: 100% 1/1 [00:00<00:00,  7.22it/s]\u001b[0m\n",
            "[Epoch 083]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0458,  0.0798, -0.0021,  ..., -0.0459,  0.0179,  0.0678],\n",
            "        [ 0.1498,  0.0795,  0.0278,  ...,  0.0733, -0.0181,  0.1085],\n",
            "        [-0.0160, -0.1050, -0.0410,  ..., -0.0503, -0.0243,  0.0807],\n",
            "        ...,\n",
            "        [-0.0662,  0.3340, -0.0982,  ..., -0.0192, -0.0904, -0.1679],\n",
            "        [ 0.0607, -0.0328, -0.1143,  ..., -0.1460, -0.0425,  0.1167],\n",
            "        [-0.0904,  0.0383, -0.0782,  ..., -0.0262, -0.0009,  0.0597]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 083]: 100% 1/1 [00:00<00:00,  9.22it/s]\u001b[0m\n",
            "[Epoch 084]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0601, -0.0262, -0.0105,  ...,  0.0100, -0.0941,  0.1025],\n",
            "        [ 0.0986,  0.1049,  0.0198,  ..., -0.0698,  0.0127,  0.0362],\n",
            "        [ 0.0021, -0.0018, -0.0073,  ..., -0.0018,  0.0030, -0.0026],\n",
            "        ...,\n",
            "        [-0.0154, -0.0475, -0.1429,  ..., -0.0378,  0.0073, -0.1393],\n",
            "        [ 0.0244, -0.0532,  0.0690,  ..., -0.0435, -0.0529,  0.0620],\n",
            "        [-0.0378,  0.0284, -0.0459,  ..., -0.1212, -0.0195,  0.0259]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 084]: 100% 1/1 [00:00<00:00,  8.19it/s]\u001b[0m\n",
            "[Epoch 085]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 1.3609e-02,  1.7622e-01,  5.0837e-02,  ..., -5.5896e-02,\n",
            "         -1.4757e-01, -1.1033e-01],\n",
            "        [ 6.0102e-02, -1.1157e-01, -3.3724e-02,  ..., -8.3455e-02,\n",
            "         -6.7509e-02, -5.8587e-02],\n",
            "        [-5.7297e-02,  4.8549e-02, -1.2554e-01,  ..., -6.6167e-02,\n",
            "          5.0921e-02,  3.0606e-02],\n",
            "        ...,\n",
            "        [-3.1251e-02,  1.3780e-02,  7.7313e-02,  ...,  1.6045e-01,\n",
            "         -4.6940e-03,  1.1583e-01],\n",
            "        [ 2.7691e-02, -6.9940e-02,  5.6553e-02,  ...,  8.6347e-02,\n",
            "          8.0802e-02, -7.9400e-03],\n",
            "        [ 3.1060e-05, -3.8468e-02, -2.2865e-02,  ...,  1.9401e-02,\n",
            "          1.2517e-02,  3.5989e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 085]: 100% 1/1 [00:00<00:00,  8.30it/s]\u001b[0m\n",
            "[Epoch 086]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1110,  0.0283,  0.1117,  ...,  0.0557,  0.0121,  0.0571],\n",
            "        [ 0.0140, -0.0098, -0.0645,  ..., -0.1311, -0.0666,  0.1338],\n",
            "        [ 0.0691,  0.0749, -0.0358,  ..., -0.0782, -0.0053, -0.1261],\n",
            "        ...,\n",
            "        [ 0.0312, -0.0384,  0.0347,  ..., -0.0287,  0.0351, -0.0859],\n",
            "        [ 0.0580, -0.1373,  0.0459,  ...,  0.1077,  0.0908,  0.0544],\n",
            "        [-0.1015,  0.0835, -0.0300,  ..., -0.1159, -0.0931, -0.0252]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 086]: 100% 1/1 [00:00<00:00,  8.94it/s]\u001b[0m\n",
            "[Epoch 087]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1582, -0.0476, -0.0501,  ..., -0.0167,  0.0624,  0.0579],\n",
            "        [-0.0207, -0.0369, -0.0729,  ...,  0.0921, -0.0160,  0.0911],\n",
            "        [ 0.1850,  0.0262, -0.0012,  ..., -0.0364,  0.1041,  0.0533],\n",
            "        ...,\n",
            "        [-0.0373, -0.0368,  0.0098,  ..., -0.0308,  0.0753, -0.0832],\n",
            "        [ 0.0244,  0.1286, -0.0639,  ..., -0.0677,  0.0092, -0.0313],\n",
            "        [ 0.0425, -0.1111,  0.1058,  ...,  0.0551, -0.0501, -0.0290]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 087]: 100% 1/1 [00:00<00:00,  6.87it/s]\u001b[0m\n",
            "[Epoch 088]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 1.3596e-02, -5.6777e-02,  1.3932e-01,  ...,  5.1613e-02,\n",
            "          2.6285e-02,  1.1711e-01],\n",
            "        [-8.0354e-02,  1.7495e-01, -4.8864e-03,  ...,  7.9226e-02,\n",
            "          2.8313e-03, -1.4271e-01],\n",
            "        [ 2.1978e-03, -1.8397e-03, -7.6872e-03,  ..., -1.8528e-03,\n",
            "          3.1640e-03, -2.7405e-03],\n",
            "        ...,\n",
            "        [ 1.4247e-02, -1.6994e-02, -1.1185e-01,  ..., -3.4963e-02,\n",
            "          6.7372e-02,  6.4536e-02],\n",
            "        [-1.0780e-02,  1.4471e-01,  2.5665e-03,  ..., -1.3415e-01,\n",
            "         -6.9105e-02,  3.2950e-02],\n",
            "        [ 6.3209e-02,  7.7529e-05,  1.8280e-01,  ..., -5.3879e-03,\n",
            "          1.4363e-01,  3.6708e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 088]: 100% 1/1 [00:00<00:00,  8.39it/s]\u001b[0m\n",
            "[Epoch 089]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1306,  0.0931,  0.0147,  ...,  0.0562,  0.2111,  0.0010],\n",
            "        [ 0.0296,  0.0711, -0.0520,  ..., -0.0851, -0.0903,  0.1652],\n",
            "        [ 0.0413, -0.0343, -0.0736,  ..., -0.0475,  0.0423, -0.1229],\n",
            "        ...,\n",
            "        [ 0.0832, -0.0049,  0.0375,  ...,  0.1169,  0.0564, -0.1612],\n",
            "        [-0.0304,  0.0445, -0.0124,  ..., -0.0404,  0.0832, -0.0338],\n",
            "        [ 0.0318, -0.0215, -0.2080,  ...,  0.0229, -0.0329, -0.0552]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 089]: 100% 1/1 [00:00<00:00,  6.50it/s]\u001b[0m\n",
            "[Epoch 090]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0601, -0.1128,  0.0082,  ...,  0.0453, -0.0164,  0.0596],\n",
            "        [ 0.0517,  0.0053, -0.0241,  ..., -0.2257, -0.1701,  0.0460],\n",
            "        [ 0.0324, -0.0201,  0.0517,  ...,  0.1292, -0.1293,  0.0268],\n",
            "        ...,\n",
            "        [-0.0893,  0.0534,  0.0624,  ...,  0.0840,  0.0694, -0.0603],\n",
            "        [-0.0660,  0.1345,  0.0483,  ...,  0.0112, -0.1052, -0.0585],\n",
            "        [ 0.0065, -0.0378,  0.0283,  ..., -0.0455,  0.0245, -0.0117]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 090]: 100% 1/1 [00:00<00:00,  8.49it/s]\u001b[0m\n",
            "[Epoch 091]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 1.5532e-01, -1.2295e-02, -1.2086e-04,  ...,  7.9374e-02,\n",
            "         -1.2639e-02, -1.7731e-01],\n",
            "        [-6.2748e-02, -2.0728e-02, -6.5751e-02,  ...,  1.4482e-02,\n",
            "         -1.7001e-02, -1.0893e-01],\n",
            "        [-5.3959e-02, -5.4033e-02,  3.6948e-03,  ...,  1.1045e-01,\n",
            "         -1.0289e-01,  1.5034e-02],\n",
            "        ...,\n",
            "        [ 2.7019e-02,  1.2794e-02,  2.4689e-02,  ...,  1.1927e-01,\n",
            "          7.5828e-02, -1.7088e-01],\n",
            "        [ 1.4732e-01, -3.2007e-02, -9.7607e-02,  ..., -9.1841e-02,\n",
            "         -5.5294e-02,  2.1252e-02],\n",
            "        [-8.1609e-02,  1.4310e-01,  4.8189e-02,  ...,  3.3534e-02,\n",
            "          1.2609e-01, -6.7465e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 091]: 100% 1/1 [00:00<00:00,  7.37it/s]\u001b[0m\n",
            "[Epoch 092]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0693, -0.0672,  0.0324,  ...,  0.0336,  0.0220, -0.1212],\n",
            "        [ 0.0732, -0.0284, -0.0181,  ...,  0.1171, -0.0858, -0.0110],\n",
            "        [ 0.0192, -0.0244,  0.0196,  ..., -0.0615,  0.0503,  0.0352],\n",
            "        ...,\n",
            "        [-0.0666, -0.0729, -0.0117,  ..., -0.0704, -0.0377,  0.1129],\n",
            "        [ 0.0686, -0.0786, -0.0588,  ..., -0.0312, -0.0400, -0.2057],\n",
            "        [ 0.0211, -0.0656,  0.0758,  ...,  0.0415, -0.0365, -0.0583]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 092]: 100% 1/1 [00:00<00:00,  8.78it/s]\u001b[0m\n",
            "[Epoch 093]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0267,  0.0419, -0.1223,  ...,  0.1942,  0.0191, -0.0957],\n",
            "        [ 0.1268, -0.1159, -0.0151,  ..., -0.0623, -0.1074,  0.0082],\n",
            "        [-0.1136,  0.1327, -0.0081,  ...,  0.0105, -0.1157, -0.1041],\n",
            "        ...,\n",
            "        [ 0.0164,  0.0027, -0.0625,  ..., -0.0294, -0.0238,  0.0962],\n",
            "        [ 0.0297,  0.0710, -0.0525,  ..., -0.0852, -0.0901,  0.1649],\n",
            "        [ 0.0154, -0.0557,  0.0294,  ...,  0.1079, -0.0489,  0.1656]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 093]: 100% 1/1 [00:00<00:00,  7.22it/s]\u001b[0m\n",
            "[Epoch 094]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0473, -0.0783,  0.0165,  ...,  0.0281, -0.0574, -0.0685],\n",
            "        [ 0.1555,  0.0994, -0.0073,  ...,  0.0428, -0.1243, -0.1402],\n",
            "        [-0.0658,  0.3336, -0.0991,  ..., -0.0193, -0.0899, -0.1683],\n",
            "        ...,\n",
            "        [-0.0876,  0.0646, -0.0051,  ..., -0.0670,  0.1215, -0.0376],\n",
            "        [-0.0826, -0.0530, -0.0281,  ...,  0.1787, -0.0491,  0.0491],\n",
            "        [ 0.0904,  0.0489,  0.0735,  ..., -0.0575, -0.0569,  0.0125]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 094]: 100% 1/1 [00:00<00:00,  7.93it/s]\u001b[0m\n",
            "[Epoch 095]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1086,  0.1417,  0.0124,  ...,  0.0019, -0.0787, -0.0314],\n",
            "        [-0.0235, -0.0434, -0.0789,  ..., -0.0502,  0.0347, -0.0202],\n",
            "        [ 0.0295,  0.0931, -0.1705,  ...,  0.1176,  0.0916, -0.0896],\n",
            "        ...,\n",
            "        [ 0.0295, -0.0097,  0.0515,  ...,  0.1661,  0.1096,  0.0186],\n",
            "        [ 0.0016,  0.0503, -0.0351,  ...,  0.0550,  0.0404, -0.1704],\n",
            "        [-0.0255, -0.1232,  0.0383,  ..., -0.0068,  0.1182,  0.1037]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 095]: 100% 1/1 [00:00<00:00,  7.16it/s]\u001b[0m\n",
            "[Epoch 096]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0843,  0.0469,  0.0167,  ..., -0.0153,  0.0192, -0.0117],\n",
            "        [ 0.0076, -0.0274,  0.0497,  ..., -0.1371, -0.0528,  0.0157],\n",
            "        [ 0.0332,  0.0008, -0.1232,  ..., -0.0242, -0.0996, -0.1108],\n",
            "        ...,\n",
            "        [ 0.0674,  0.0003, -0.0813,  ...,  0.0829, -0.0202, -0.0686],\n",
            "        [ 0.0262, -0.0392,  0.0132,  ...,  0.0097,  0.0258, -0.0366],\n",
            "        [ 0.1858, -0.0862, -0.0685,  ...,  0.0444, -0.0086, -0.0151]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 096]: 100% 1/1 [00:00<00:00,  4.05it/s]\u001b[0m\n",
            "[Epoch 097]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0742,  0.1205,  0.0342,  ..., -0.1446, -0.0807,  0.2034],\n",
            "        [-0.0450, -0.0920,  0.0715,  ...,  0.1418,  0.1287, -0.0940],\n",
            "        [ 0.1203, -0.2003, -0.0520,  ..., -0.0274, -0.0369,  0.0627],\n",
            "        ...,\n",
            "        [-0.0007, -0.0243,  0.0760,  ..., -0.0377,  0.0344,  0.0470],\n",
            "        [-0.0381,  0.1105, -0.0418,  ...,  0.0067,  0.0171, -0.0097],\n",
            "        [-0.0368, -0.0607, -0.1508,  ..., -0.1187,  0.0903,  0.0432]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 097]: 100% 1/1 [00:00<00:00,  5.12it/s]\u001b[0m\n",
            "[Epoch 098]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0004, -0.1121, -0.0520,  ...,  0.0679, -0.0294,  0.0004],\n",
            "        [-0.0388,  0.0528,  0.0007,  ..., -0.0214,  0.0052,  0.0590],\n",
            "        [-0.0312, -0.2024, -0.1521,  ...,  0.0271,  0.0159,  0.1543],\n",
            "        ...,\n",
            "        [-0.0424, -0.0465,  0.0139,  ...,  0.0669,  0.0377,  0.0754],\n",
            "        [ 0.0765, -0.0479, -0.0224,  ...,  0.0994, -0.1126, -0.0041],\n",
            "        [ 0.0966,  0.0417, -0.0542,  ...,  0.0201,  0.0215, -0.0099]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 098]: 100% 1/1 [00:00<00:00,  5.74it/s]\u001b[0m\n",
            "[Epoch 099]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1175,  0.0062, -0.1190,  ..., -0.0078,  0.0674,  0.1933],\n",
            "        [ 0.0520,  0.0051, -0.0248,  ..., -0.2258, -0.1697,  0.0457],\n",
            "        [-0.1149,  0.1191, -0.0990,  ...,  0.1081, -0.0230, -0.2073],\n",
            "        ...,\n",
            "        [ 0.0189, -0.0657, -0.0735,  ...,  0.0266,  0.0532, -0.1116],\n",
            "        [ 0.0026, -0.0021, -0.0087,  ..., -0.0020,  0.0036, -0.0031],\n",
            "        [ 0.0453,  0.0955,  0.0079,  ...,  0.0913, -0.0811, -0.0302]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 099]: 100% 1/1 [00:00<00:00,  5.21it/s]\u001b[0m\n",
            "[Epoch 100]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1164,  0.1345, -0.1044,  ..., -0.0217,  0.1245, -0.0095],\n",
            "        [ 0.0837,  0.1644, -0.0830,  ..., -0.0255,  0.1178,  0.0817],\n",
            "        [ 0.0211,  0.0211,  0.0692,  ..., -0.0303, -0.1409,  0.1095],\n",
            "        ...,\n",
            "        [ 0.0106, -0.0680, -0.0549,  ...,  0.0532,  0.0094,  0.1065],\n",
            "        [-0.1235, -0.0061,  0.0046,  ..., -0.0918,  0.0463,  0.0058],\n",
            "        [ 0.0026, -0.0021, -0.0087,  ..., -0.0021,  0.0036, -0.0031]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 100]: 100% 1/1 [00:00<00:00,  4.51it/s]\u001b[0m\n",
            "\u001b[0m14 Apr 00:13 INFO - Finish 1 train-validation experiment(s)...\u001b[0m\n",
            "\u001b[0m14 Apr 00:13 INFO - Start Calculating Metrics...\u001b[0m\n",
            "\u001b[0m14 Apr 00:13 INFO - ==========================\u001b[0m\n",
            "\u001b[0m14 Apr 00:13 INFO - Generate recommend list...\u001b[0m\n",
            "\u001b[0m14 Apr 00:13 INFO - ==========================\u001b[0m\n",
            "\u001b[0m\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0140, -0.1028, -0.0811,  ...,  0.0124,  0.0093,  0.0765],\n",
            "        [ 0.0634, -0.0707, -0.0624,  ..., -0.0490, -0.0785,  0.0179],\n",
            "        [-0.0177,  0.0135, -0.0283,  ..., -0.0623, -0.0079,  0.0116],\n",
            "        ...,\n",
            "        [ 0.0027, -0.0021, -0.0088,  ..., -0.0021,  0.0036, -0.0031],\n",
            "        [-0.0390,  0.1019,  0.0142,  ..., -0.0043, -0.0421,  0.0303],\n",
            "        [-0.0259,  0.0492,  0.0395,  ..., -0.0197,  0.0096,  0.0210]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "\u001b[0mPREDS\u001b[0m \u001b[0m[[ 25.  25. 412. ... 115. 319. 319.]\n",
            " [418. 418. 418. ... 340.  93.  93.]\n",
            " [182. 182. 138. ... 325. 325.  77.]\n",
            " ...\n",
            " [184. 184. 291. ... 185. 113. 113.]\n",
            " [360. 286. 348. ... 263. 263. 263.]\n",
            " [184. 184. 252. ... 403. 291. 291.]]\u001b[0m\n",
            "14 Apr 00:13 INFO - Finish 37 trial...\u001b[0m\n",
            "\u001b[0m\u001b[32m[I 2023-04-14 00:13:58,089]\u001b[0m Trial 36 finished with value: 0.048831094169637754 and parameters: {}. Best is trial 10 with value: 0.1209022497797705.\u001b[0m\n",
            "\u001b[0mLine1\u001b[0m\n",
            "\u001b[0mApplying weights\u001b[0m\n",
            "\u001b[0mAfter applying wieghts\u001b[0m\n",
            "\u001b[0mLine2\u001b[0m\n",
            "\u001b[0mModel fitting\u001b[0m\n",
            "[Epoch 001]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0711,  0.0534, -0.0588,  ...,  0.0459, -0.0064, -0.0023],\n",
            "        [ 0.1748, -0.1787, -0.1004,  ..., -0.0013,  0.0011,  0.0265],\n",
            "        [ 0.0260,  0.1544, -0.0425,  ..., -0.0287, -0.0110,  0.0612],\n",
            "        ...,\n",
            "        [ 0.0766,  0.0731,  0.0061,  ...,  0.0435,  0.0354, -0.0264],\n",
            "        [-0.0087,  0.0879, -0.0670,  ...,  0.1251,  0.0314,  0.1239],\n",
            "        [-0.1184, -0.0247,  0.0263,  ...,  0.2526,  0.0408,  0.0750]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 001]: 100% 1/1 [00:00<00:00,  4.16it/s]\u001b[0m\n",
            "[Epoch 002]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0253, -0.0021, -0.0127,  ...,  0.0871,  0.0446, -0.0106],\n",
            "        [-0.0315,  0.0849, -0.0008,  ...,  0.1037,  0.0062, -0.0486],\n",
            "        [ 0.0788,  0.1274,  0.1399,  ...,  0.0822, -0.0419, -0.0812],\n",
            "        ...,\n",
            "        [ 0.0503, -0.1456, -0.0477,  ..., -0.0098,  0.0122,  0.0554],\n",
            "        [-0.0613, -0.0819,  0.0463,  ..., -0.1046,  0.0111, -0.1065],\n",
            "        [ 0.1909,  0.1383, -0.0311,  ..., -0.0423, -0.0269,  0.0373]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 002]: 100% 1/1 [00:00<00:00,  4.85it/s]\u001b[0m\n",
            "[Epoch 003]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 3.8462e-02,  6.2447e-02, -1.8328e-01,  ..., -4.7902e-02,\n",
            "          1.4445e-01,  2.5894e-02],\n",
            "        [ 4.6498e-02,  6.4597e-02, -1.6135e-02,  ...,  6.1952e-02,\n",
            "         -8.8425e-02,  1.1844e-02],\n",
            "        [ 3.2226e-02, -1.1601e-01, -3.7147e-02,  ...,  2.0275e-02,\n",
            "         -3.0318e-01,  2.1203e-02],\n",
            "        ...,\n",
            "        [-8.0977e-02,  9.0166e-02,  1.1775e-01,  ..., -1.8603e-02,\n",
            "         -1.0829e-02,  1.1603e-01],\n",
            "        [-1.9081e-04, -2.0308e-05, -1.0637e-04,  ...,  1.5119e-04,\n",
            "          1.5226e-05,  2.0101e-04],\n",
            "        [ 3.8002e-02,  6.0008e-02,  5.4845e-02,  ...,  1.8321e-01,\n",
            "          7.6337e-02,  4.0607e-03]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 003]: 100% 1/1 [00:00<00:00,  4.63it/s]\u001b[0m\n",
            "[Epoch 004]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 1.7007e-03,  1.8483e-02, -1.7580e-01,  ..., -8.3091e-04,\n",
            "         -9.3851e-02,  1.8837e-02],\n",
            "        [ 9.8594e-02, -1.4981e-01, -1.2050e-02,  ...,  4.0991e-02,\n",
            "          5.1495e-02, -3.0704e-02],\n",
            "        [ 2.0957e-02,  8.2186e-02,  1.0943e-05,  ...,  6.7434e-02,\n",
            "         -1.0464e-01, -1.9800e-02],\n",
            "        ...,\n",
            "        [ 7.4816e-03,  1.1508e-01, -3.9087e-02,  ..., -1.6606e-01,\n",
            "         -6.3496e-02,  1.7136e-02],\n",
            "        [-1.6050e-02,  1.6108e-02,  5.0753e-02,  ...,  7.2118e-02,\n",
            "          1.1613e-01, -1.1173e-02],\n",
            "        [ 6.2822e-02,  1.7511e-02,  4.1091e-02,  ...,  5.8077e-02,\n",
            "          1.9485e-02, -4.3170e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 004]: 100% 1/1 [00:00<00:00,  5.28it/s]\u001b[0m\n",
            "[Epoch 005]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0489,  0.0289, -0.0528,  ...,  0.0615, -0.0716, -0.0600],\n",
            "        [ 0.0532, -0.0913, -0.0895,  ...,  0.0232, -0.1371,  0.0506],\n",
            "        [-0.0013,  0.0565,  0.0383,  ..., -0.0144, -0.1766,  0.0473],\n",
            "        ...,\n",
            "        [ 0.0843, -0.0995, -0.0148,  ..., -0.0121, -0.1159, -0.0429],\n",
            "        [ 0.0268,  0.0422,  0.0628,  ...,  0.0420, -0.0638, -0.0316],\n",
            "        [ 0.0918,  0.0699, -0.0598,  ...,  0.0828, -0.1452, -0.0337]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 005]: 100% 1/1 [00:00<00:00,  4.53it/s]\u001b[0m\n",
            "[Epoch 006]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1328,  0.0688,  0.1002,  ..., -0.0181,  0.0158,  0.1774],\n",
            "        [-0.0377,  0.0283, -0.0644,  ...,  0.1318, -0.0196, -0.0032],\n",
            "        [-0.0474, -0.0110, -0.0676,  ...,  0.0322,  0.0309, -0.0027],\n",
            "        ...,\n",
            "        [-0.1838,  0.0848, -0.1087,  ...,  0.0288,  0.0220, -0.0109],\n",
            "        [ 0.1045, -0.0057, -0.2195,  ..., -0.1102,  0.0352, -0.0655],\n",
            "        [ 0.0042,  0.0878,  0.1441,  ...,  0.0572, -0.0453, -0.1162]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 006]: 100% 1/1 [00:00<00:00,  4.98it/s]\u001b[0m\n",
            "[Epoch 007]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 5.1895e-02,  5.6344e-02, -2.9058e-01,  ...,  3.3626e-02,\n",
            "         -7.6549e-02,  1.7784e-03],\n",
            "        [ 6.0259e-02, -4.0646e-02, -2.4922e-02,  ...,  7.7121e-02,\n",
            "         -8.9169e-02,  2.6863e-02],\n",
            "        [ 5.3155e-02,  2.1162e-02, -3.9397e-02,  ...,  1.5181e-01,\n",
            "          1.0891e-01, -2.3741e-04],\n",
            "        ...,\n",
            "        [-2.1706e-02, -1.8087e-02,  1.9267e-02,  ..., -1.3289e-02,\n",
            "         -1.8808e-02, -3.2445e-02],\n",
            "        [ 1.6711e-02,  4.0113e-02,  7.3163e-04,  ...,  1.4693e-02,\n",
            "         -6.4341e-02, -1.6019e-01],\n",
            "        [ 1.1643e-01,  6.9154e-02, -1.4362e-01,  ..., -7.6180e-03,\n",
            "          7.1106e-04,  5.3330e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 007]: 100% 1/1 [00:00<00:00,  5.40it/s]\u001b[0m\n",
            "[Epoch 008]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0486,  0.1200,  0.0161,  ..., -0.1156,  0.0100,  0.1536],\n",
            "        [-0.0281,  0.0940, -0.0079,  ...,  0.0314, -0.0811,  0.1016],\n",
            "        [ 0.0257,  0.0316,  0.0325,  ..., -0.0021, -0.0427, -0.0868],\n",
            "        ...,\n",
            "        [ 0.0172,  0.0382, -0.0202,  ...,  0.0822, -0.0874,  0.0039],\n",
            "        [-0.0101,  0.0377,  0.0106,  ...,  0.0351, -0.0241, -0.0147],\n",
            "        [-0.0329,  0.1091, -0.0701,  ..., -0.0814, -0.0968, -0.0288]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 008]: 100% 1/1 [00:00<00:00,  5.04it/s]\u001b[0m\n",
            "[Epoch 009]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1172,  0.0469, -0.0943,  ..., -0.0836,  0.0267, -0.0091],\n",
            "        [-0.0698, -0.0487,  0.0940,  ..., -0.0032,  0.2109,  0.0315],\n",
            "        [-0.0960, -0.0186, -0.0209,  ..., -0.0037,  0.0118, -0.0183],\n",
            "        ...,\n",
            "        [-0.0239,  0.0674,  0.0306,  ..., -0.0288, -0.1487,  0.0093],\n",
            "        [ 0.0211, -0.1265,  0.0291,  ...,  0.1034,  0.0241, -0.0106],\n",
            "        [-0.1089,  0.0198,  0.0947,  ...,  0.1041,  0.0583,  0.0363]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 009]: 100% 1/1 [00:00<00:00,  4.92it/s]\u001b[0m\n",
            "[Epoch 010]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0249,  0.0361, -0.0461,  ..., -0.0237, -0.0204,  0.1224],\n",
            "        [-0.1256, -0.0046, -0.0537,  ...,  0.3106, -0.0535,  0.1384],\n",
            "        [-0.0502, -0.1035,  0.1254,  ..., -0.0240,  0.0710, -0.0337],\n",
            "        ...,\n",
            "        [ 0.1756,  0.0448,  0.0258,  ...,  0.1040,  0.0172,  0.0184],\n",
            "        [ 0.0055,  0.0017, -0.0128,  ...,  0.0949, -0.0088, -0.0608],\n",
            "        [-0.0053, -0.1284, -0.0532,  ...,  0.0100, -0.0507,  0.0228]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 010]: 100% 1/1 [00:00<00:00,  6.04it/s]\u001b[0m\n",
            "[Epoch 011]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-4.1030e-02,  1.1236e-01,  3.2986e-02,  ...,  4.9977e-02,\n",
            "          1.2754e-01, -1.1571e-01],\n",
            "        [ 2.8407e-02,  8.2480e-02, -3.3364e-02,  ..., -9.4540e-02,\n",
            "          9.1694e-03,  4.1201e-02],\n",
            "        [-2.4369e-02, -3.4953e-02, -1.2045e-01,  ...,  2.5985e-01,\n",
            "         -9.4698e-02, -4.4444e-02],\n",
            "        ...,\n",
            "        [ 7.9468e-03,  4.7556e-02,  4.1940e-02,  ...,  2.8326e-02,\n",
            "         -7.4586e-02, -1.1120e-01],\n",
            "        [-1.5894e-01, -6.8347e-02, -1.1627e-01,  ...,  1.7078e-01,\n",
            "         -6.0603e-02,  8.0891e-02],\n",
            "        [-8.5662e-04, -9.7650e-05, -5.8220e-04,  ...,  8.0656e-04,\n",
            "          7.6102e-05,  9.4221e-04]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 011]: 100% 1/1 [00:00<00:00,  4.78it/s]\u001b[0m\n",
            "[Epoch 012]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-4.7302e-03,  5.8620e-02, -3.2412e-02,  ...,  1.0877e-01,\n",
            "         -9.6824e-02,  4.0029e-02],\n",
            "        [ 1.4898e-01,  5.3176e-02, -1.4626e-01,  ..., -9.5630e-02,\n",
            "          1.6979e-02, -6.0801e-02],\n",
            "        [ 1.4051e-01, -8.9162e-02,  1.1233e-01,  ...,  7.6805e-02,\n",
            "         -1.6833e-02, -3.2023e-02],\n",
            "        ...,\n",
            "        [-9.4559e-04, -1.0077e-04, -6.5337e-04,  ...,  8.8284e-04,\n",
            "          6.4477e-05,  1.0321e-03],\n",
            "        [ 1.1213e-01,  5.6741e-02, -1.2251e-01,  ..., -5.2659e-03,\n",
            "          7.2032e-02, -5.5940e-02],\n",
            "        [-4.0288e-02,  1.1153e-02, -1.3077e-01,  ...,  3.1576e-02,\n",
            "         -7.5384e-02,  9.8809e-03]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 012]: 100% 1/1 [00:00<00:00,  4.78it/s]\u001b[0m\n",
            "[Epoch 013]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-2.4191e-02,  7.0284e-02,  3.2643e-02,  ...,  3.5136e-03,\n",
            "         -1.4750e-02,  1.3667e-02],\n",
            "        [ 3.0250e-02,  6.8298e-02, -1.0328e-01,  ..., -6.4680e-02,\n",
            "         -5.4730e-02, -5.8306e-02],\n",
            "        [-8.4895e-02, -6.1122e-02, -6.2545e-02,  ..., -1.4058e-02,\n",
            "          4.7348e-03, -1.3152e-01],\n",
            "        ...,\n",
            "        [-1.3935e-02,  1.8025e-01, -4.0032e-05,  ...,  1.9420e-01,\n",
            "         -1.4684e-02,  6.7185e-02],\n",
            "        [-5.9706e-02,  3.3239e-02, -4.3779e-02,  ...,  4.9285e-02,\n",
            "          6.8858e-02, -2.3149e-02],\n",
            "        [ 5.8634e-02, -1.1981e-02,  1.8560e-01,  ..., -3.1501e-03,\n",
            "         -6.5865e-02,  3.0491e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 013]: 100% 1/1 [00:00<00:00,  4.96it/s]\u001b[0m\n",
            "[Epoch 014]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-2.1692e-02,  1.8068e-02, -1.4158e-01,  ...,  3.0730e-02,\n",
            "         -9.0350e-02,  1.2331e-01],\n",
            "        [-1.1438e-01, -1.0904e-01,  9.3829e-02,  ...,  8.1284e-02,\n",
            "          1.0340e-01,  3.9300e-02],\n",
            "        [-1.1155e-03, -1.4853e-04, -7.6188e-04,  ...,  1.0372e-03,\n",
            "          7.3747e-05,  1.1786e-03],\n",
            "        ...,\n",
            "        [-9.8168e-02,  2.3648e-02,  7.0437e-02,  ..., -2.2234e-02,\n",
            "          1.0865e-01, -1.3144e-01],\n",
            "        [ 2.7729e-02,  3.1058e-02,  3.5003e-02,  ..., -8.9434e-02,\n",
            "          2.9889e-02,  1.5790e-02],\n",
            "        [-2.9235e-02, -6.4378e-02,  6.7486e-03,  ..., -3.8024e-02,\n",
            "          2.7869e-02, -8.0074e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 014]: 100% 1/1 [00:00<00:00,  4.10it/s]\u001b[0m\n",
            "[Epoch 015]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0425, -0.0628,  0.0423,  ...,  0.0311, -0.0052,  0.0350],\n",
            "        [ 0.0075,  0.0060, -0.0761,  ...,  0.1657,  0.0516, -0.0295],\n",
            "        [-0.0251,  0.0881, -0.0441,  ..., -0.0144, -0.0787, -0.1553],\n",
            "        ...,\n",
            "        [ 0.0085,  0.0809, -0.0048,  ...,  0.0084, -0.0162,  0.0050],\n",
            "        [ 0.1389, -0.1611, -0.1028,  ...,  0.0126, -0.0606, -0.0420],\n",
            "        [-0.0965, -0.0393, -0.0668,  ..., -0.0295, -0.0023, -0.0822]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 015]: 100% 1/1 [00:00<00:00,  4.57it/s]\u001b[0m\n",
            "[Epoch 016]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0729,  0.0311, -0.0503,  ..., -0.0229,  0.0152, -0.0223],\n",
            "        [-0.0895,  0.0671, -0.0943,  ..., -0.0745,  0.0188,  0.1325],\n",
            "        [-0.0464, -0.0958,  0.0069,  ...,  0.0046, -0.0470,  0.0592],\n",
            "        ...,\n",
            "        [-0.0876,  0.0169, -0.0223,  ..., -0.1138, -0.0798, -0.1190],\n",
            "        [-0.0312,  0.0594, -0.1106,  ..., -0.0092, -0.0247, -0.0197],\n",
            "        [ 0.0115,  0.0185, -0.1372,  ..., -0.0647, -0.0125,  0.0939]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 016]: 100% 1/1 [00:00<00:00,  5.44it/s]\u001b[0m\n",
            "[Epoch 017]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0586,  0.0525, -0.1603,  ..., -0.0729,  0.0223, -0.0374],\n",
            "        [ 0.0146, -0.0185,  0.0245,  ...,  0.1155, -0.0443, -0.0473],\n",
            "        [-0.0554,  0.0748,  0.0606,  ...,  0.1496,  0.0767, -0.0910],\n",
            "        ...,\n",
            "        [ 0.0130,  0.0217, -0.0135,  ..., -0.0778,  0.0007, -0.0070],\n",
            "        [-0.1846,  0.0845, -0.1095,  ...,  0.0297,  0.0222, -0.0099],\n",
            "        [-0.1448,  0.1998, -0.0485,  ..., -0.0443, -0.0813,  0.0956]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 017]: 100% 1/1 [00:00<00:00,  4.64it/s]\u001b[0m\n",
            "[Epoch 018]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0216,  0.0537, -0.0217,  ...,  0.0034, -0.0009,  0.0164],\n",
            "        [-0.0701, -0.0413, -0.0904,  ...,  0.0846, -0.0499, -0.0070],\n",
            "        [ 0.0209,  0.0268,  0.0591,  ...,  0.0111, -0.1127, -0.0296],\n",
            "        ...,\n",
            "        [ 0.0529,  0.1415,  0.0033,  ...,  0.0500, -0.0032,  0.0254],\n",
            "        [ 0.0356,  0.0886, -0.0151,  ...,  0.0048, -0.0286, -0.0323],\n",
            "        [ 0.1984, -0.1623, -0.0535,  ...,  0.0070,  0.1241,  0.0207]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 018]: 100% 1/1 [00:00<00:00,  4.88it/s]\u001b[0m\n",
            "[Epoch 019]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0259, -0.0485, -0.0941,  ...,  0.0632, -0.0538,  0.0566],\n",
            "        [ 0.0191, -0.0097, -0.0474,  ..., -0.0376, -0.0268,  0.1104],\n",
            "        [-0.0315, -0.0290, -0.0288,  ..., -0.0731, -0.0095, -0.0167],\n",
            "        ...,\n",
            "        [ 0.0129,  0.0845, -0.0525,  ..., -0.0961, -0.0587,  0.0597],\n",
            "        [ 0.0907,  0.0169, -0.0387,  ..., -0.0081,  0.0232,  0.0167],\n",
            "        [-0.0480, -0.1147, -0.0517,  ...,  0.1646,  0.0494,  0.0246]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 019]: 100% 1/1 [00:00<00:00,  5.51it/s]\u001b[0m\n",
            "[Epoch 020]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0250,  0.0488, -0.0526,  ..., -0.0515, -0.0052,  0.0122],\n",
            "        [ 0.0119, -0.1483, -0.1487,  ...,  0.0985,  0.0002,  0.0566],\n",
            "        [ 0.0161,  0.0518, -0.0198,  ...,  0.0262,  0.0042, -0.0388],\n",
            "        ...,\n",
            "        [ 0.0631, -0.0398, -0.0561,  ...,  0.0323, -0.0314, -0.0277],\n",
            "        [-0.0949,  0.1639, -0.0092,  ..., -0.0991, -0.0495,  0.0519],\n",
            "        [ 0.0363,  0.0213, -0.0124,  ..., -0.0280,  0.0076, -0.0231]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 020]: 100% 1/1 [00:00<00:00,  5.48it/s]\u001b[0m\n",
            "[Epoch 021]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0191, -0.0623,  0.0124,  ..., -0.0041, -0.1283, -0.0527],\n",
            "        [-0.0734,  0.0310, -0.0507,  ..., -0.0225,  0.0152, -0.0219],\n",
            "        [-0.1120, -0.0778,  0.0648,  ..., -0.1016,  0.0133, -0.0366],\n",
            "        ...,\n",
            "        [ 0.0329,  0.0574,  0.1104,  ...,  0.0283, -0.0106,  0.1200],\n",
            "        [ 0.1187,  0.1471, -0.1477,  ..., -0.0384,  0.0657,  0.0548],\n",
            "        [-0.1667,  0.0724, -0.0502,  ...,  0.2341, -0.0121,  0.1247]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 021]: 100% 1/1 [00:00<00:00,  7.06it/s]\u001b[0m\n",
            "[Epoch 022]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-1.3297e-03, -3.9474e-02,  1.6763e-02,  ...,  1.8644e-02,\n",
            "          1.5909e-01,  4.0428e-02],\n",
            "        [-1.8456e-03, -2.3841e-04, -1.2935e-03,  ...,  1.6364e-03,\n",
            "          8.9486e-05,  1.8733e-03],\n",
            "        [ 4.7483e-02,  7.4363e-02, -7.0005e-03,  ..., -1.8880e-02,\n",
            "         -3.7411e-02, -8.3158e-02],\n",
            "        ...,\n",
            "        [ 5.2628e-02, -3.1113e-02, -8.1746e-02,  ...,  2.8451e-02,\n",
            "          6.8089e-02,  3.0401e-02],\n",
            "        [-8.0563e-02, -8.8748e-03,  4.6154e-02,  ...,  1.0056e-01,\n",
            "         -4.3852e-02,  7.4752e-02],\n",
            "        [ 3.1907e-02,  5.8593e-02,  1.1522e-02,  ..., -7.1128e-02,\n",
            "         -1.5860e-02, -3.0316e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 022]: 100% 1/1 [00:00<00:00,  7.83it/s]\u001b[0m\n",
            "[Epoch 023]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 2.4114e-02,  1.6144e-02,  4.6089e-02,  ...,  8.7910e-03,\n",
            "          1.2395e-01, -5.5157e-03],\n",
            "        [-1.9337e-03, -2.6520e-04, -1.3749e-03,  ...,  1.7127e-03,\n",
            "          1.1232e-04,  1.9467e-03],\n",
            "        [ 7.1253e-02,  8.5191e-02, -1.2398e-01,  ..., -2.3962e-02,\n",
            "          5.3501e-03,  4.1728e-02],\n",
            "        ...,\n",
            "        [-8.6706e-02, -1.7453e-02,  1.8364e-02,  ...,  7.2417e-02,\n",
            "         -1.1059e-01,  8.1859e-02],\n",
            "        [ 1.6661e-02,  1.4707e-02, -4.3252e-03,  ..., -7.4315e-02,\n",
            "         -5.2357e-02, -4.1624e-02],\n",
            "        [ 5.9956e-02, -1.2498e-01,  5.7295e-02,  ...,  5.6528e-02,\n",
            "         -5.3868e-03,  2.0863e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 023]: 100% 1/1 [00:00<00:00,  7.45it/s]\u001b[0m\n",
            "[Epoch 024]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0902,  0.0201, -0.0252,  ...,  0.0617,  0.0530, -0.0080],\n",
            "        [-0.0323, -0.0389, -0.0061,  ..., -0.0128, -0.0288, -0.0998],\n",
            "        [-0.0734, -0.0318,  0.0077,  ..., -0.0999,  0.0134, -0.0069],\n",
            "        ...,\n",
            "        [ 0.0344,  0.1312, -0.1293,  ...,  0.0127,  0.0478, -0.0401],\n",
            "        [-0.0189, -0.0201, -0.0944,  ...,  0.0455,  0.0041, -0.0390],\n",
            "        [ 0.0570, -0.0977,  0.0104,  ...,  0.1691,  0.0736,  0.0253]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 024]: 100% 1/1 [00:00<00:00,  8.31it/s]\u001b[0m\n",
            "[Epoch 025]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-6.8902e-02,  1.4922e-02,  8.8971e-02,  ...,  9.8135e-02,\n",
            "         -1.5702e-02, -7.1638e-02],\n",
            "        [-9.4727e-02, -5.5503e-03, -1.1350e-01,  ...,  1.1159e-01,\n",
            "         -1.2248e-01,  9.0858e-03],\n",
            "        [-2.1210e-03, -2.7356e-04, -1.4776e-03,  ...,  1.8447e-03,\n",
            "          9.7176e-05,  2.1518e-03],\n",
            "        ...,\n",
            "        [ 2.4090e-02,  1.5394e-01, -4.4517e-02,  ..., -2.6765e-02,\n",
            "         -1.1161e-02,  6.3566e-02],\n",
            "        [-4.5336e-02, -5.9840e-02, -1.4900e-01,  ...,  9.3128e-02,\n",
            "         -2.6627e-02, -8.5371e-02],\n",
            "        [-2.1210e-03, -2.7356e-04, -1.4776e-03,  ...,  1.8447e-03,\n",
            "          9.7176e-05,  2.1518e-03]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 025]: 100% 1/1 [00:00<00:00,  8.67it/s]\u001b[0m\n",
            "[Epoch 026]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0193, -0.0137, -0.0896,  ..., -0.0159, -0.1134,  0.0186],\n",
            "        [-0.0012,  0.0050, -0.0895,  ...,  0.0100, -0.0113, -0.0278],\n",
            "        [ 0.1891,  0.1383, -0.0328,  ..., -0.0409, -0.0270,  0.0396],\n",
            "        ...,\n",
            "        [-0.1358, -0.0602,  0.0067,  ...,  0.0221, -0.0660,  0.0027],\n",
            "        [-0.0730,  0.0472,  0.0123,  ...,  0.0542, -0.2154, -0.0181],\n",
            "        [-0.0306, -0.0693,  0.0007,  ...,  0.0254, -0.0607, -0.0015]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 026]: 100% 1/1 [00:00<00:00,  6.04it/s]\u001b[0m\n",
            "[Epoch 027]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0647, -0.0364, -0.0520,  ...,  0.0429, -0.0014,  0.0711],\n",
            "        [-0.0417, -0.0182,  0.0628,  ..., -0.0337, -0.0175,  0.0785],\n",
            "        [ 0.0647,  0.1850,  0.0878,  ...,  0.0212,  0.0765,  0.1444],\n",
            "        ...,\n",
            "        [-0.0042,  0.0450, -0.0404,  ..., -0.0695, -0.0364, -0.0527],\n",
            "        [-0.0156, -0.0165, -0.1369,  ...,  0.0164,  0.0178, -0.0321],\n",
            "        [ 0.1159,  0.0686, -0.1667,  ..., -0.1202,  0.0331, -0.0400]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 027]: 100% 1/1 [00:00<00:00,  8.77it/s]\u001b[0m\n",
            "[Epoch 028]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0461, -0.0812, -0.0144,  ...,  0.0556,  0.0052, -0.0193],\n",
            "        [ 0.0401,  0.0264,  0.0289,  ...,  0.1608, -0.0220, -0.0355],\n",
            "        [ 0.0330,  0.0466, -0.0012,  ...,  0.0025, -0.0755,  0.0662],\n",
            "        ...,\n",
            "        [ 0.2069, -0.0220,  0.0305,  ...,  0.1761,  0.0969,  0.0601],\n",
            "        [ 0.0214,  0.0075, -0.1604,  ...,  0.0321,  0.0101,  0.0324],\n",
            "        [-0.1108, -0.0163,  0.0343,  ..., -0.0409, -0.1053, -0.0481]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 028]: 100% 1/1 [00:00<00:00,  7.59it/s]\u001b[0m\n",
            "[Epoch 029]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1017, -0.0284,  0.0654,  ..., -0.0617,  0.0374, -0.0375],\n",
            "        [ 0.0436, -0.0319,  0.0599,  ...,  0.0644, -0.0466, -0.0918],\n",
            "        [-0.0476, -0.0959,  0.0059,  ...,  0.0056, -0.0471,  0.0604],\n",
            "        ...,\n",
            "        [-0.0508,  0.0276, -0.0108,  ...,  0.0039,  0.0236, -0.0106],\n",
            "        [-0.0063, -0.0481, -0.0013,  ...,  0.0833, -0.0578, -0.0309],\n",
            "        [-0.0372,  0.0789, -0.0029,  ...,  0.0563, -0.0621,  0.0123]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 029]: 100% 1/1 [00:00<00:00,  8.18it/s]\u001b[0m\n",
            "[Epoch 030]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0943,  0.0041, -0.0430,  ..., -0.0968, -0.1519, -0.0715],\n",
            "        [-0.0500,  0.0867, -0.0080,  ..., -0.0134, -0.0816,  0.0179],\n",
            "        [-0.0323, -0.0286, -0.0932,  ...,  0.1468,  0.1524,  0.0054],\n",
            "        ...,\n",
            "        [-0.0342, -0.0206,  0.1263,  ..., -0.0573,  0.0342,  0.0757],\n",
            "        [ 0.1568, -0.0736,  0.0146,  ...,  0.0082, -0.0772,  0.0063],\n",
            "        [ 0.0756, -0.1279, -0.0748,  ...,  0.0442,  0.0812, -0.0621]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 030]: 100% 1/1 [00:00<00:00,  6.60it/s]\u001b[0m\n",
            "[Epoch 031]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0101,  0.0184, -0.1380,  ..., -0.0636, -0.0124,  0.0954],\n",
            "        [-0.0027, -0.0004, -0.0018,  ...,  0.0023,  0.0001,  0.0028],\n",
            "        [ 0.0811,  0.0822, -0.1179,  ..., -0.0775,  0.0685, -0.0322],\n",
            "        ...,\n",
            "        [-0.0027, -0.0004, -0.0018,  ...,  0.0023,  0.0001,  0.0028],\n",
            "        [ 0.0131,  0.1275, -0.0485,  ..., -0.0306, -0.0285,  0.0064],\n",
            "        [-0.0381, -0.0343, -0.0877,  ..., -0.0804, -0.0915, -0.0403]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 031]: 100% 1/1 [00:00<00:00,  8.91it/s]\u001b[0m\n",
            "[Epoch 032]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0624,  0.1488,  0.1257,  ...,  0.0633,  0.0545,  0.1904],\n",
            "        [ 0.0961,  0.0228, -0.0345,  ...,  0.0867,  0.0271,  0.0842],\n",
            "        [-0.0240, -0.0350, -0.0456,  ...,  0.0723, -0.0738,  0.0123],\n",
            "        ...,\n",
            "        [-0.0080, -0.0540, -0.0556,  ...,  0.0520, -0.1296,  0.0746],\n",
            "        [ 0.1746, -0.0978, -0.0710,  ..., -0.0628,  0.0574,  0.0045],\n",
            "        [-0.0515,  0.0800, -0.0770,  ...,  0.0319, -0.0322,  0.0693]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 032]: 100% 1/1 [00:00<00:00,  6.82it/s]\u001b[0m\n",
            "[Epoch 033]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1201, -0.0734,  0.0136,  ...,  0.0565,  0.1032,  0.0612],\n",
            "        [-0.0322, -0.0298,  0.1189,  ...,  0.0279,  0.2133,  0.0621],\n",
            "        [-0.0480,  0.0021,  0.0270,  ...,  0.0862,  0.0440, -0.0179],\n",
            "        ...,\n",
            "        [ 0.0658,  0.0430, -0.0476,  ..., -0.0787,  0.0236,  0.0660],\n",
            "        [-0.1948,  0.0103, -0.0053,  ..., -0.0533, -0.0165,  0.0414],\n",
            "        [-0.0815, -0.0493, -0.0249,  ...,  0.1060, -0.0036,  0.0431]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 033]: 100% 1/1 [00:00<00:00,  8.25it/s]\u001b[0m\n",
            "[Epoch 034]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-8.7104e-02,  4.5088e-02, -6.3621e-02,  ...,  1.6601e-01,\n",
            "          4.4265e-02, -5.6731e-02],\n",
            "        [-2.6985e-02,  5.3198e-02,  4.7211e-02,  ...,  5.4929e-02,\n",
            "          1.0030e-01, -7.2347e-02],\n",
            "        [ 7.3509e-02,  1.2348e-01, -8.4329e-02,  ..., -3.8133e-02,\n",
            "         -4.1379e-02,  1.6587e-01],\n",
            "        ...,\n",
            "        [ 2.0522e-02, -6.2230e-02,  5.5408e-03,  ..., -8.9731e-03,\n",
            "          3.6732e-02, -3.2979e-02],\n",
            "        [-1.4905e-01, -8.1753e-02,  5.3753e-02,  ..., -5.3027e-02,\n",
            "         -4.0342e-03,  2.4592e-02],\n",
            "        [ 6.3346e-02, -1.9510e-02,  5.1282e-02,  ...,  6.3982e-06,\n",
            "         -4.9111e-02, -1.6821e-01]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 034]: 100% 1/1 [00:00<00:00,  7.03it/s]\u001b[0m\n",
            "[Epoch 035]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0110,  0.0425, -0.0345,  ..., -0.0916,  0.0253, -0.0295],\n",
            "        [-0.0536,  0.0565, -0.0346,  ...,  0.0608,  0.1135,  0.0248],\n",
            "        [-0.0005,  0.0054, -0.1005,  ..., -0.0389, -0.0297, -0.0306],\n",
            "        ...,\n",
            "        [-0.0030, -0.0004, -0.0021,  ...,  0.0026,  0.0002,  0.0031],\n",
            "        [ 0.0033,  0.0009, -0.0146,  ...,  0.0970, -0.0085, -0.0583],\n",
            "        [ 0.0470,  0.1477, -0.0078,  ...,  0.0486,  0.0498,  0.0617]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 035]: 100% 1/1 [00:00<00:00,  8.73it/s]\u001b[0m\n",
            "[Epoch 036]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0031, -0.0005, -0.0022,  ...,  0.0027,  0.0002,  0.0032],\n",
            "        [ 0.0096,  0.0183, -0.1383,  ..., -0.0632, -0.0123,  0.0958],\n",
            "        [-0.0180, -0.0326,  0.0633,  ..., -0.0661,  0.0080,  0.1421],\n",
            "        ...,\n",
            "        [-0.0351,  0.0058, -0.0643,  ...,  0.0649, -0.1462,  0.0047],\n",
            "        [-0.0660,  0.0548, -0.1213,  ...,  0.1748,  0.1119,  0.0082],\n",
            "        [ 0.0500,  0.0204, -0.1596,  ...,  0.0350, -0.0153, -0.0853]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 036]: 100% 1/1 [00:00<00:00,  6.91it/s]\u001b[0m\n",
            "[Epoch 037]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0017,  0.0975,  0.0082,  ...,  0.0694, -0.0328, -0.0479],\n",
            "        [ 0.0530,  0.0232,  0.0265,  ...,  0.0381, -0.0893, -0.1161],\n",
            "        [ 0.1230, -0.0262, -0.1235,  ...,  0.0226, -0.1516, -0.0271],\n",
            "        ...,\n",
            "        [ 0.0763, -0.0944, -0.1148,  ...,  0.0344,  0.0346,  0.0456],\n",
            "        [-0.0796, -0.1104, -0.1480,  ...,  0.0331,  0.0168, -0.0175],\n",
            "        [-0.1040, -0.0345, -0.1171,  ...,  0.0135, -0.0651,  0.0395]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 037]: 100% 1/1 [00:00<00:00,  8.37it/s]\u001b[0m\n",
            "[Epoch 038]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1966,  0.1077, -0.1390,  ..., -0.0138, -0.0007,  0.1701],\n",
            "        [ 0.0002,  0.1457, -0.0180,  ...,  0.0747,  0.0519,  0.1057],\n",
            "        [-0.0203,  0.1798, -0.0533,  ...,  0.0811,  0.0878,  0.0972],\n",
            "        ...,\n",
            "        [-0.0822,  0.0121, -0.0545,  ...,  0.0907, -0.0224,  0.0557],\n",
            "        [-0.0318,  0.0955,  0.0776,  ...,  0.0906, -0.0262, -0.0834],\n",
            "        [-0.0809, -0.0112,  0.0486,  ...,  0.0247, -0.0053, -0.0218]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 038]: 100% 1/1 [00:00<00:00,  7.42it/s]\u001b[0m\n",
            "[Epoch 039]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0727,  0.0008, -0.0921,  ...,  0.0085,  0.0084, -0.0229],\n",
            "        [-0.0853,  0.0580, -0.1618,  ..., -0.0454, -0.0412, -0.0119],\n",
            "        [-0.0038, -0.0457, -0.0356,  ..., -0.0273,  0.0863,  0.0735],\n",
            "        ...,\n",
            "        [-0.1284, -0.0661, -0.0226,  ..., -0.1538,  0.0388, -0.0825],\n",
            "        [ 0.0736, -0.0170,  0.0313,  ..., -0.0541, -0.0557,  0.0551],\n",
            "        [-0.0034, -0.0005, -0.0023,  ...,  0.0029,  0.0003,  0.0034]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 039]: 100% 1/1 [00:00<00:00,  7.75it/s]\u001b[0m\n",
            "[Epoch 040]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0884,  0.1157, -0.1849,  ...,  0.0528,  0.0357,  0.0417],\n",
            "        [ 0.0282,  0.1304,  0.0284,  ...,  0.0193, -0.0010,  0.1128],\n",
            "        [-0.0187, -0.1100, -0.0834,  ...,  0.0647,  0.0632,  0.1056],\n",
            "        ...,\n",
            "        [-0.0035, -0.0005, -0.0024,  ...,  0.0030,  0.0003,  0.0035],\n",
            "        [ 0.0180, -0.0139, -0.0904,  ..., -0.0147, -0.1133,  0.0200],\n",
            "        [-0.0360, -0.0988,  0.0062,  ..., -0.0064,  0.0123, -0.0597]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 040]: 100% 1/1 [00:00<00:00,  7.70it/s]\u001b[0m\n",
            "[Epoch 041]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-5.4960e-02,  3.8191e-02,  2.3298e-02,  ...,  7.7710e-02,\n",
            "         -1.0846e-01, -1.3511e-02],\n",
            "        [-6.9032e-02,  4.2652e-02,  7.8343e-02,  ..., -4.0249e-02,\n",
            "         -6.2155e-02, -5.4589e-03],\n",
            "        [ 8.7090e-02,  1.5888e-01,  6.1088e-02,  ..., -8.4255e-02,\n",
            "          3.2701e-03,  8.5360e-02],\n",
            "        ...,\n",
            "        [-3.5619e-03, -5.0061e-04, -2.4520e-03,  ...,  3.0564e-03,\n",
            "          3.3436e-04,  3.6334e-03],\n",
            "        [-6.2947e-02,  2.4138e-02, -1.0229e-01,  ...,  2.5548e-01,\n",
            "         -3.8214e-02,  3.1424e-02],\n",
            "        [-4.3902e-05,  1.4564e-01, -1.8161e-02,  ...,  7.4971e-02,\n",
            "          5.2006e-02,  1.0603e-01]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 041]: 100% 1/1 [00:00<00:00,  6.90it/s]\u001b[0m\n",
            "[Epoch 042]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0073,  0.0571,  0.0085,  ..., -0.0521, -0.0568, -0.0163],\n",
            "        [-0.0643, -0.0862, -0.0675,  ...,  0.0567, -0.0365,  0.0138],\n",
            "        [-0.0680,  0.0339, -0.0585,  ...,  0.1253, -0.0014,  0.1049],\n",
            "        ...,\n",
            "        [ 0.1814, -0.0392, -0.0232,  ...,  0.1660,  0.1725,  0.0393],\n",
            "        [-0.0473, -0.0436,  0.0478,  ..., -0.0043,  0.1142,  0.0063],\n",
            "        [-0.0338,  0.1016, -0.1701,  ..., -0.0362, -0.1126, -0.0364]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 042]: 100% 1/1 [00:00<00:00,  8.97it/s]\u001b[0m\n",
            "[Epoch 043]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0305, -0.0264, -0.0759,  ...,  0.0712,  0.0382, -0.0099],\n",
            "        [-0.1637, -0.0546, -0.0162,  ...,  0.2883, -0.0618,  0.0735],\n",
            "        [ 0.0884,  0.0694, -0.0622,  ...,  0.0857, -0.1449, -0.0302],\n",
            "        ...,\n",
            "        [-0.0375,  0.0413, -0.1148,  ..., -0.0665, -0.1251, -0.0291],\n",
            "        [-0.0915,  0.0719, -0.0665,  ...,  0.0072, -0.0934, -0.0285],\n",
            "        [ 0.0420, -0.0033, -0.0549,  ...,  0.1187, -0.1104, -0.0780]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 043]: 100% 1/1 [00:00<00:00,  7.66it/s]\u001b[0m\n",
            "[Epoch 044]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1216,  0.0126, -0.0140,  ...,  0.3058,  0.0054,  0.1099],\n",
            "        [-0.0011, -0.0022,  0.0362,  ..., -0.0618, -0.0612, -0.0623],\n",
            "        [-0.0598, -0.0023, -0.0893,  ...,  0.1122, -0.0981,  0.0617],\n",
            "        ...,\n",
            "        [-0.0965,  0.0488,  0.0792,  ...,  0.0649,  0.0560,  0.0585],\n",
            "        [ 0.0869,  0.0676, -0.0551,  ...,  0.1151, -0.0123,  0.1262],\n",
            "        [ 0.1877,  0.1383, -0.0340,  ..., -0.0398, -0.0268,  0.0414]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 044]: 100% 1/1 [00:00<00:00,  8.21it/s]\u001b[0m\n",
            "[Epoch 045]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0561,  0.0213, -0.0077,  ...,  0.0463, -0.0216,  0.0782],\n",
            "        [ 0.0453,  0.0464,  0.0140,  ...,  0.0842,  0.0056,  0.1530],\n",
            "        [-0.0170,  0.0390,  0.0054,  ...,  0.0787,  0.0279,  0.0003],\n",
            "        ...,\n",
            "        [ 0.0020, -0.1167, -0.1292,  ...,  0.0410,  0.0016,  0.0004],\n",
            "        [-0.0236, -0.0395,  0.0465,  ...,  0.0658,  0.0014, -0.0057],\n",
            "        [-0.1037,  0.0151,  0.0364,  ..., -0.0016,  0.1095,  0.1089]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 045]: 100% 1/1 [00:00<00:00,  7.38it/s]\u001b[0m\n",
            "[Epoch 046]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0614, -0.1203, -0.0413,  ...,  0.1281, -0.0151,  0.0468],\n",
            "        [-0.1502, -0.0820,  0.0531,  ..., -0.0521, -0.0038,  0.0257],\n",
            "        [-0.1256, -0.0772,  0.1369,  ..., -0.0757,  0.1158, -0.1585],\n",
            "        ...,\n",
            "        [ 0.0158,  0.1053, -0.1961,  ..., -0.0401, -0.0267, -0.0253],\n",
            "        [-0.0352,  0.0542, -0.0161,  ...,  0.0226,  0.0746,  0.0888],\n",
            "        [ 0.0316, -0.0256, -0.0811,  ...,  0.0498, -0.0597,  0.0089]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 046]: 100% 1/1 [00:00<00:00,  7.40it/s]\u001b[0m\n",
            "[Epoch 047]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0161,  0.0245, -0.0016,  ..., -0.0282, -0.0379, -0.0055],\n",
            "        [ 0.0053,  0.0441, -0.0867,  ..., -0.0302, -0.0887, -0.0300],\n",
            "        [ 0.0891,  0.0012, -0.0185,  ...,  0.0617, -0.0794, -0.0470],\n",
            "        ...,\n",
            "        [-0.0038,  0.0663,  0.0200,  ...,  0.0869,  0.0822,  0.0809],\n",
            "        [ 0.0169,  0.0792, -0.1525,  ...,  0.0021, -0.0556, -0.0416],\n",
            "        [-0.0661,  0.0172, -0.0498,  ...,  0.1779,  0.0052,  0.0694]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 047]: 100% 1/1 [00:00<00:00,  9.19it/s]\u001b[0m\n",
            "[Epoch 048]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0474,  0.2015,  0.0431,  ...,  0.0492,  0.0599,  0.0944],\n",
            "        [ 0.0348, -0.0596, -0.0291,  ..., -0.1093, -0.0646, -0.0872],\n",
            "        [-0.0132,  0.0324, -0.0948,  ...,  0.1351, -0.0058, -0.0014],\n",
            "        ...,\n",
            "        [-0.0935,  0.1350,  0.1237,  ..., -0.0183, -0.1858, -0.0456],\n",
            "        [-0.0081, -0.0483, -0.0023,  ...,  0.0848, -0.0577, -0.0292],\n",
            "        [ 0.0450,  0.0734, -0.0087,  ..., -0.0167, -0.0371, -0.0804]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 048]: 100% 1/1 [00:00<00:00,  7.29it/s]\u001b[0m\n",
            "[Epoch 049]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1362, -0.0108, -0.0565,  ...,  0.0657, -0.0516, -0.0267],\n",
            "        [-0.0205, -0.0414, -0.0620,  ..., -0.0849, -0.0037, -0.0247],\n",
            "        [-0.0555,  0.0118, -0.0569,  ..., -0.1744, -0.0074,  0.0185],\n",
            "        ...,\n",
            "        [ 0.0156,  0.1064, -0.1007,  ..., -0.0261, -0.0134, -0.0065],\n",
            "        [-0.0763,  0.0304,  0.0940,  ..., -0.0870,  0.0100, -0.0031],\n",
            "        [-0.0078,  0.0025,  0.1232,  ...,  0.0254,  0.0375, -0.0014]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 049]: 100% 1/1 [00:00<00:00,  8.27it/s]\u001b[0m\n",
            "[Epoch 050]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0644,  0.0615,  0.0015,  ...,  0.0175, -0.0638,  0.0363],\n",
            "        [-0.0020,  0.0052, -0.1014,  ..., -0.0377, -0.0297, -0.0291],\n",
            "        [-0.0537,  0.0887, -0.0229,  ..., -0.0356,  0.0425,  0.1168],\n",
            "        ...,\n",
            "        [ 0.0198,  0.1018, -0.1483,  ..., -0.0860, -0.0901, -0.0792],\n",
            "        [-0.0307,  0.0813,  0.0068,  ..., -0.0065,  0.0770, -0.0575],\n",
            "        [-0.0198,  0.0560, -0.0552,  ...,  0.0501, -0.0715,  0.1190]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 050]: 100% 1/1 [00:00<00:00,  7.58it/s]\u001b[0m\n",
            "[Epoch 051]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1178, -0.0850, -0.0558,  ...,  0.0068, -0.0550, -0.0299],\n",
            "        [-0.0198, -0.0507, -0.1249,  ...,  0.0228, -0.0384, -0.0231],\n",
            "        [ 0.0237, -0.0306, -0.0091,  ...,  0.0993, -0.0942, -0.0084],\n",
            "        ...,\n",
            "        [-0.0093, -0.0502,  0.0552,  ...,  0.1640, -0.0485, -0.0963],\n",
            "        [-0.0373,  0.0033, -0.0381,  ...,  0.0383, -0.0177,  0.0269],\n",
            "        [ 0.0140, -0.0202,  0.0076,  ...,  0.0269, -0.0840,  0.0546]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 051]: 100% 1/1 [00:00<00:00,  7.76it/s]\u001b[0m\n",
            "[Epoch 052]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0622,  0.0345, -0.1302,  ...,  0.0301, -0.0735,  0.0299],\n",
            "        [-0.0946, -0.0006,  0.0640,  ...,  0.0579,  0.0048,  0.0886],\n",
            "        [-0.1472, -0.0086, -0.0677,  ...,  0.0577, -0.0614,  0.0359],\n",
            "        ...,\n",
            "        [-0.0812,  0.0964, -0.1492,  ..., -0.0604, -0.1151, -0.0571],\n",
            "        [-0.0166, -0.0045, -0.0466,  ...,  0.0176, -0.0148,  0.0058],\n",
            "        [-0.0111,  0.1867, -0.0221,  ..., -0.0847,  0.0112,  0.0082]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 052]: 100% 1/1 [00:00<00:00,  8.43it/s]\u001b[0m\n",
            "[Epoch 053]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0315,  0.0349, -0.0991,  ...,  0.0111,  0.1112, -0.0967],\n",
            "        [ 0.0235,  0.0567, -0.0028,  ..., -0.0083, -0.0330, -0.0228],\n",
            "        [-0.0275, -0.0275,  0.0051,  ...,  0.0106, -0.0896,  0.0612],\n",
            "        ...,\n",
            "        [ 0.0104, -0.0103,  0.0128,  ...,  0.1892, -0.0009, -0.0328],\n",
            "        [-0.0794,  0.0483,  0.0310,  ...,  0.0499, -0.0813,  0.0522],\n",
            "        [ 0.0016,  0.0003, -0.0158,  ...,  0.0985, -0.0083, -0.0564]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 053]: 100% 1/1 [00:00<00:00,  7.09it/s]\u001b[0m\n",
            "[Epoch 054]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0500, -0.0810,  0.0305,  ..., -0.0100, -0.0361,  0.0100],\n",
            "        [ 0.0293,  0.0337, -0.0208,  ...,  0.0504, -0.0639,  0.0900],\n",
            "        [-0.1678, -0.0226, -0.0340,  ..., -0.0615, -0.0415,  0.0716],\n",
            "        ...,\n",
            "        [-0.0733,  0.0542,  0.0671,  ..., -0.0622, -0.0562,  0.0485],\n",
            "        [ 0.0138, -0.0202,  0.0074,  ...,  0.0272, -0.0839,  0.0549],\n",
            "        [-0.0481,  0.0026, -0.0847,  ...,  0.1485, -0.0337,  0.1229]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 054]: 100% 1/1 [00:00<00:00,  7.83it/s]\u001b[0m\n",
            "[Epoch 055]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-5.2695e-03,  4.7337e-02, -1.5570e-01,  ...,  1.0921e-02,\n",
            "          2.9016e-02, -5.7958e-02],\n",
            "        [ 6.7174e-02, -1.2327e-01, -6.1489e-02,  ...,  1.8995e-02,\n",
            "          5.4377e-02,  9.5982e-03],\n",
            "        [-5.1958e-02, -6.4101e-02,  1.5339e-01,  ...,  2.4272e-03,\n",
            "          4.0017e-02, -2.5069e-02],\n",
            "        ...,\n",
            "        [-2.5389e-02,  2.8147e-02,  6.3851e-02,  ...,  4.6434e-02,\n",
            "          2.2560e-02,  4.4362e-02],\n",
            "        [-4.7708e-02, -7.8628e-03, -5.2554e-02,  ..., -8.4376e-02,\n",
            "         -1.5108e-02,  7.2618e-05],\n",
            "        [ 7.0300e-02,  1.2663e-01, -4.5420e-02,  ...,  1.1237e-01,\n",
            "          3.9873e-02,  9.6899e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 055]: 100% 1/1 [00:00<00:00,  7.19it/s]\u001b[0m\n",
            "[Epoch 056]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0303, -0.0467,  0.0228,  ..., -0.0388,  0.0900, -0.0094],\n",
            "        [-0.0413,  0.0378, -0.1087,  ..., -0.2484, -0.1433, -0.0353],\n",
            "        [-0.0013,  0.0022, -0.0548,  ...,  0.1638,  0.0534,  0.0103],\n",
            "        ...,\n",
            "        [ 0.0321, -0.0330, -0.1392,  ...,  0.0392, -0.0625, -0.0658],\n",
            "        [ 0.0616,  0.0261, -0.0363,  ...,  0.0038,  0.0672,  0.0435],\n",
            "        [-0.0450, -0.0094, -0.1214,  ..., -0.0092,  0.0084, -0.0697]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 056]: 100% 1/1 [00:00<00:00,  8.60it/s]\u001b[0m\n",
            "[Epoch 057]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0221,  0.0343,  0.0573,  ...,  0.1274, -0.0287,  0.0146],\n",
            "        [-0.1120,  0.0101, -0.0753,  ...,  0.0574, -0.0025,  0.0994],\n",
            "        [-0.0875,  0.0050, -0.0227,  ..., -0.0028,  0.0162, -0.0120],\n",
            "        ...,\n",
            "        [-0.0364,  0.0794,  0.0059,  ..., -0.0042, -0.0069,  0.0560],\n",
            "        [ 0.1387, -0.0006, -0.0631,  ..., -0.0007, -0.0649,  0.0496],\n",
            "        [-0.0045, -0.0400,  0.0146,  ...,  0.0213,  0.1592,  0.0437]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 057]: 100% 1/1 [00:00<00:00,  7.43it/s]\u001b[0m\n",
            "[Epoch 058]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0068,  0.0874, -0.1191,  ..., -0.0718, -0.0969,  0.0457],\n",
            "        [-0.0650,  0.0300, -0.0291,  ...,  0.0402, -0.0837, -0.0150],\n",
            "        [-0.0052, -0.0007, -0.0034,  ...,  0.0043,  0.0003,  0.0052],\n",
            "        ...,\n",
            "        [ 0.1229, -0.0454, -0.0848,  ..., -0.0960, -0.0235, -0.0028],\n",
            "        [ 0.0495,  0.0742,  0.0436,  ...,  0.0207, -0.0546, -0.0382],\n",
            "        [-0.0648, -0.0333, -0.0039,  ...,  0.0085, -0.0318,  0.0314]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 058]: 100% 1/1 [00:00<00:00,  8.12it/s]\u001b[0m\n",
            "[Epoch 059]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1175, -0.0163, -0.1343,  ..., -0.0006, -0.0063,  0.0108],\n",
            "        [-0.0765, -0.0324,  0.0056,  ..., -0.0973,  0.0137, -0.0035],\n",
            "        [-0.0035,  0.0291,  0.0927,  ..., -0.0028, -0.0186,  0.0081],\n",
            "        ...,\n",
            "        [ 0.0142, -0.1101,  0.0046,  ...,  0.0737, -0.0208, -0.0641],\n",
            "        [ 0.0061,  0.1054, -0.0552,  ...,  0.1031,  0.0205,  0.0540],\n",
            "        [-0.0053, -0.0007, -0.0035,  ...,  0.0044,  0.0003,  0.0053]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 059]: 100% 1/1 [00:00<00:00,  7.74it/s]\u001b[0m\n",
            "[Epoch 060]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0054, -0.0007, -0.0036,  ...,  0.0045,  0.0003,  0.0055],\n",
            "        [ 0.1263,  0.1169, -0.0302,  ..., -0.0812, -0.0046, -0.0314],\n",
            "        [-0.0370, -0.0217, -0.0102,  ..., -0.0256, -0.0235,  0.0537],\n",
            "        ...,\n",
            "        [ 0.0238,  0.0115,  0.1087,  ...,  0.1026,  0.0669, -0.0644],\n",
            "        [-0.0367, -0.0052, -0.0794,  ...,  0.0584, -0.0681, -0.0459],\n",
            "        [ 0.0908, -0.0761,  0.0677,  ...,  0.0317, -0.0437,  0.0904]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 060]: 100% 1/1 [00:00<00:00,  7.61it/s]\u001b[0m\n",
            "[Epoch 061]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0637, -0.0192,  0.1485,  ...,  0.0196,  0.0549, -0.0338],\n",
            "        [-0.0127,  0.0740, -0.0445,  ...,  0.1320,  0.1408,  0.0581],\n",
            "        [ 0.0309,  0.0202, -0.1040,  ..., -0.0272, -0.0247, -0.0655],\n",
            "        ...,\n",
            "        [ 0.0094,  0.0736,  0.1579,  ...,  0.0721, -0.0004, -0.1236],\n",
            "        [ 0.0463,  0.0207,  0.0261,  ..., -0.0005, -0.1317,  0.0363],\n",
            "        [ 0.0067, -0.0053, -0.1112,  ...,  0.0365, -0.0510, -0.1133]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 061]: 100% 1/1 [00:00<00:00,  8.51it/s]\u001b[0m\n",
            "[Epoch 062]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1041, -0.0515, -0.0404,  ...,  0.0783, -0.0093, -0.0049],\n",
            "        [ 0.0481, -0.0224, -0.0016,  ..., -0.0115, -0.0833,  0.0290],\n",
            "        [-0.0158,  0.0501,  0.0514,  ...,  0.0443,  0.0050,  0.0021],\n",
            "        ...,\n",
            "        [ 0.1077,  0.0563, -0.1249,  ..., -0.0015,  0.0726, -0.0512],\n",
            "        [-0.0732,  0.0153, -0.0161,  ...,  0.0204, -0.0173, -0.0402],\n",
            "        [-0.0747, -0.0425, -0.1480,  ..., -0.0015, -0.0928, -0.1018]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 062]: 100% 1/1 [00:00<00:00,  6.67it/s]\u001b[0m\n",
            "[Epoch 063]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0057,  0.1053, -0.0555,  ...,  0.1034,  0.0205,  0.0543],\n",
            "        [-0.0218,  0.0813, -0.0838,  ...,  0.0142,  0.0084, -0.0289],\n",
            "        [ 0.0071,  0.0181, -0.1397,  ..., -0.0612, -0.0121,  0.0985],\n",
            "        ...,\n",
            "        [ 0.0338,  0.1814, -0.1228,  ..., -0.0824, -0.0064,  0.1242],\n",
            "        [-0.0676,  0.0200,  0.0401,  ..., -0.0447,  0.0132,  0.0329],\n",
            "        [-0.0643, -0.0843, -0.1410,  ...,  0.1185,  0.0141, -0.0528]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 063]: 100% 1/1 [00:00<00:00,  8.73it/s]\u001b[0m\n",
            "[Epoch 064]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0717,  0.0433, -0.1263,  ...,  0.0084, -0.0906, -0.0693],\n",
            "        [-0.0271,  0.0704, -0.0362,  ...,  0.0658,  0.0407,  0.1246],\n",
            "        [ 0.0965,  0.0236, -0.2400,  ..., -0.0125,  0.1132,  0.0024],\n",
            "        ...,\n",
            "        [-0.0437, -0.0210, -0.0525,  ..., -0.0818, -0.1140, -0.0812],\n",
            "        [-0.0433, -0.0385,  0.0267,  ..., -0.0290, -0.0224, -0.1294],\n",
            "        [-0.0248,  0.0204,  0.0192,  ...,  0.0050,  0.0030,  0.0044]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 064]: 100% 1/1 [00:00<00:00,  7.52it/s]\u001b[0m\n",
            "[Epoch 065]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0539, -0.0746,  0.0048,  ..., -0.0044, -0.0067, -0.0066],\n",
            "        [-0.0016,  0.0187, -0.0897,  ...,  0.0241, -0.0294,  0.1072],\n",
            "        [-0.0019,  0.0089,  0.0527,  ...,  0.0461, -0.0231, -0.0197],\n",
            "        ...,\n",
            "        [ 0.0304, -0.1304,  0.1122,  ...,  0.0134,  0.0963, -0.0062],\n",
            "        [ 0.2115, -0.1090, -0.0071,  ...,  0.0014,  0.0912, -0.0377],\n",
            "        [ 0.0853, -0.0096, -0.0539,  ...,  0.2212, -0.1409, -0.0264]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 065]: 100% 1/1 [00:00<00:00,  8.43it/s]\u001b[0m\n",
            "[Epoch 066]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0628,  0.1291, -0.0624,  ..., -0.0518, -0.0067, -0.0122],\n",
            "        [-0.0506,  0.0601,  0.0055,  ..., -0.0618,  0.1030,  0.0288],\n",
            "        [-0.0215,  0.0650, -0.1425,  ..., -0.2239, -0.2316, -0.0458],\n",
            "        ...,\n",
            "        [-0.0180,  0.0684,  0.0778,  ...,  0.0202, -0.0312, -0.0415],\n",
            "        [ 0.0380,  0.0484,  0.0446,  ...,  0.0667,  0.0021,  0.0082],\n",
            "        [ 0.0461,  0.0300, -0.0230,  ..., -0.0078, -0.0591,  0.1100]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 066]: 100% 1/1 [00:00<00:00,  8.74it/s]\u001b[0m\n",
            "[Epoch 067]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0795, -0.0739, -0.0926,  ...,  0.0052, -0.0905,  0.0155],\n",
            "        [ 0.0432,  0.1621, -0.1203,  ..., -0.0435,  0.0600, -0.0497],\n",
            "        [-0.0575, -0.0179, -0.0260,  ...,  0.0371, -0.1880,  0.0697],\n",
            "        ...,\n",
            "        [-0.0060, -0.0008, -0.0040,  ...,  0.0050,  0.0003,  0.0061],\n",
            "        [-0.0513,  0.0008,  0.0247,  ...,  0.0890,  0.0441, -0.0143],\n",
            "        [ 0.1152, -0.0013, -0.0033,  ..., -0.0633,  0.0566,  0.0612]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 067]: 100% 1/1 [00:00<00:00,  7.71it/s]\u001b[0m\n",
            "[Epoch 068]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0871,  0.0295, -0.0453,  ...,  0.1044,  0.0138,  0.0098],\n",
            "        [-0.0635,  0.0454,  0.0128,  ..., -0.0274,  0.1164,  0.0051],\n",
            "        [-0.0758,  0.0171, -0.1317,  ...,  0.2571,  0.0293,  0.0279],\n",
            "        ...,\n",
            "        [-0.0061, -0.0008, -0.0041,  ...,  0.0051,  0.0003,  0.0062],\n",
            "        [-0.0641,  0.0967, -0.0046,  ...,  0.0500, -0.0251,  0.0274],\n",
            "        [-0.0905,  0.0895,  0.0453,  ..., -0.0243, -0.0926, -0.0026]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 068]: 100% 1/1 [00:00<00:00,  8.42it/s]\u001b[0m\n",
            "[Epoch 069]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-1.0339e-01, -3.0318e-02, -5.8212e-03,  ...,  3.2005e-01,\n",
            "          4.4747e-02,  1.2044e-01],\n",
            "        [ 5.3341e-02, -8.4228e-02,  2.2312e-02,  ..., -5.3937e-02,\n",
            "          2.7563e-04,  1.9721e-02],\n",
            "        [-1.0581e-01, -1.0695e-02,  1.0988e-01,  ..., -7.7154e-02,\n",
            "          5.8322e-02,  2.7189e-02],\n",
            "        ...,\n",
            "        [-1.0740e-02,  1.2516e-01, -2.8719e-02,  ...,  2.0068e-02,\n",
            "         -1.2186e-01,  8.1445e-02],\n",
            "        [ 2.5903e-03,  9.7602e-02, -1.4515e-01,  ...,  1.3387e-03,\n",
            "         -9.2827e-03, -2.0508e-02],\n",
            "        [ 1.7843e-02,  5.9791e-02, -5.5732e-02,  ...,  7.1585e-02,\n",
            "         -2.6052e-02, -4.2030e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 069]: 100% 1/1 [00:00<00:00,  6.84it/s]\u001b[0m\n",
            "[Epoch 070]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0063, -0.0008, -0.0043,  ...,  0.0052,  0.0003,  0.0064],\n",
            "        [-0.0279, -0.0062,  0.0447,  ...,  0.0977, -0.0006, -0.0638],\n",
            "        [-0.0006, -0.0758,  0.1098,  ...,  0.0288, -0.0966,  0.1130],\n",
            "        ...,\n",
            "        [ 0.0414,  0.0105, -0.0246,  ..., -0.1181, -0.0229,  0.0089],\n",
            "        [ 0.0406,  0.1544,  0.0132,  ...,  0.0763,  0.0600,  0.0626],\n",
            "        [-0.0359, -0.0578, -0.0822,  ...,  0.0095, -0.0878,  0.0323]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 070]: 100% 1/1 [00:00<00:00,  8.03it/s]\u001b[0m\n",
            "[Epoch 071]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0260, -0.0979, -0.1259,  ...,  0.1053, -0.0959, -0.0552],\n",
            "        [-0.0580, -0.0439, -0.0973,  ...,  0.1510, -0.0070,  0.0193],\n",
            "        [ 0.1253,  0.1169, -0.0310,  ..., -0.0805, -0.0046, -0.0304],\n",
            "        ...,\n",
            "        [-0.0049,  0.1018, -0.0627,  ..., -0.0071, -0.0665, -0.0133],\n",
            "        [ 0.0231, -0.0063, -0.0098,  ..., -0.0067, -0.0723,  0.0271],\n",
            "        [-0.0819,  0.0138, -0.1025,  ...,  0.2357,  0.0249,  0.0636]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 071]: 100% 1/1 [00:00<00:00,  7.68it/s]\u001b[0m\n",
            "[Epoch 072]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0116, -0.1146, -0.0278,  ...,  0.0886,  0.0731,  0.0559],\n",
            "        [ 0.0728,  0.1269,  0.1358,  ...,  0.0878, -0.0410, -0.0745],\n",
            "        [-0.0343, -0.1056,  0.0712,  ..., -0.1039,  0.0154, -0.0196],\n",
            "        ...,\n",
            "        [ 0.0049,  0.1052, -0.0561,  ...,  0.1040,  0.0206,  0.0550],\n",
            "        [-0.0391, -0.0823, -0.0128,  ..., -0.0006,  0.0025, -0.0799],\n",
            "        [ 0.0821, -0.0277, -0.0154,  ...,  0.0148,  0.0235, -0.0783]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 072]: 100% 1/1 [00:00<00:00,  7.52it/s]\u001b[0m\n",
            "[Epoch 073]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0544,  0.0771, -0.0864,  ...,  0.0189,  0.0988,  0.0951],\n",
            "        [-0.0502, -0.0367, -0.1341,  ...,  0.1173, -0.1331, -0.0185],\n",
            "        [ 0.0362,  0.0726,  0.0022,  ..., -0.1090, -0.0284, -0.0165],\n",
            "        ...,\n",
            "        [ 0.0217,  0.0565, -0.0041,  ..., -0.0069, -0.0329, -0.0209],\n",
            "        [ 0.0722,  0.0351, -0.0048,  ...,  0.0244, -0.0327,  0.0013],\n",
            "        [ 0.0272,  0.1374, -0.0349,  ...,  0.0478,  0.1459,  0.1552]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 073]: 100% 1/1 [00:00<00:00,  8.74it/s]\u001b[0m\n",
            "[Epoch 074]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0179,  0.0273,  0.0039,  ..., -0.0271, -0.0637, -0.1605],\n",
            "        [ 0.0579,  0.0185,  0.0005,  ...,  0.0917, -0.1161,  0.0088],\n",
            "        [ 0.0229,  0.0920,  0.0126,  ..., -0.0070,  0.0803,  0.1317],\n",
            "        ...,\n",
            "        [ 0.0896,  0.0062,  0.0039,  ..., -0.0036, -0.0301,  0.0198],\n",
            "        [-0.0067, -0.0009, -0.0045,  ...,  0.0054,  0.0004,  0.0067],\n",
            "        [ 0.0321,  0.0618, -0.1868,  ..., -0.0426,  0.1453,  0.0327]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 074]: 100% 1/1 [00:00<00:00,  7.14it/s]\u001b[0m\n",
            "[Epoch 075]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0095, -0.0425,  0.0764,  ...,  0.0994, -0.0625, -0.0393],\n",
            "        [ 0.0529,  0.1468, -0.0392,  ...,  0.0727,  0.0650,  0.0506],\n",
            "        [-0.0277, -0.0354, -0.0485,  ...,  0.0758, -0.0737,  0.0164],\n",
            "        ...,\n",
            "        [ 0.0610, -0.0249,  0.0368,  ...,  0.0589, -0.0376, -0.0261],\n",
            "        [-0.0028, -0.0021, -0.0203,  ...,  0.1899, -0.0755, -0.0695],\n",
            "        [ 0.0172,  0.1192, -0.0094,  ...,  0.1423,  0.0149,  0.0241]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 075]: 100% 1/1 [00:00<00:00,  6.95it/s]\u001b[0m\n",
            "[Epoch 076]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0901, -0.1083, -0.0579,  ...,  0.0293,  0.0211, -0.0090],\n",
            "        [-0.0428,  0.0039,  0.0180,  ...,  0.0579,  0.0173, -0.0309],\n",
            "        [-0.0197,  0.1607,  0.0308,  ...,  0.1493,  0.1675,  0.0981],\n",
            "        ...,\n",
            "        [ 0.0382, -0.0038, -0.0571,  ...,  0.1215, -0.1111, -0.0746],\n",
            "        [-0.0618, -0.0504,  0.0903,  ...,  0.1096,  0.0077, -0.0130],\n",
            "        [-0.0348,  0.0008,  0.0609,  ..., -0.0686, -0.0369,  0.1057]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 076]: 100% 1/1 [00:00<00:00,  7.92it/s]\u001b[0m\n",
            "[Epoch 077]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0442, -0.0051,  0.0137,  ..., -0.0169, -0.0547, -0.0706],\n",
            "        [-0.0195, -0.0109,  0.0174,  ...,  0.0613, -0.0568, -0.0532],\n",
            "        [ 0.0467,  0.0248, -0.0800,  ..., -0.0095, -0.1672, -0.0204],\n",
            "        ...,\n",
            "        [-0.0721,  0.0090, -0.0040,  ...,  0.0312, -0.0380,  0.0071],\n",
            "        [-0.0522, -0.0208, -0.0721,  ...,  0.0371,  0.0770,  0.0680],\n",
            "        [-0.1023, -0.0726,  0.0227,  ...,  0.0539,  0.0104, -0.0864]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 077]: 100% 1/1 [00:00<00:00,  9.18it/s]\u001b[0m\n",
            "[Epoch 078]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0831, -0.1108, -0.1507,  ...,  0.0366,  0.0169, -0.0135],\n",
            "        [-0.0322,  0.1104, -0.0265,  ...,  0.1777,  0.2422,  0.1076],\n",
            "        [-0.0077, -0.1165,  0.0004,  ...,  0.0635, -0.2253,  0.0446],\n",
            "        ...,\n",
            "        [-0.1340,  0.0126, -0.0690,  ..., -0.0655, -0.0958, -0.1562],\n",
            "        [-0.0379, -0.0003, -0.0757,  ...,  0.0660, -0.0824,  0.1295],\n",
            "        [ 0.1273, -0.0319, -0.2284,  ..., -0.0312,  0.0397, -0.0810]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 078]: 100% 1/1 [00:00<00:00,  6.95it/s]\u001b[0m\n",
            "[Epoch 079]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0324, -0.0111, -0.0629,  ...,  0.0863,  0.0558,  0.0188],\n",
            "        [-0.1832, -0.0454, -0.3061,  ..., -0.0125, -0.1335, -0.1515],\n",
            "        [-0.0071, -0.0009, -0.0047,  ...,  0.0058,  0.0004,  0.0072],\n",
            "        ...,\n",
            "        [ 0.1246,  0.1169, -0.0315,  ..., -0.0801, -0.0045, -0.0296],\n",
            "        [-0.1621, -0.0426, -0.0470,  ...,  0.0646, -0.1372,  0.0186],\n",
            "        [-0.0071, -0.0009, -0.0047,  ...,  0.0058,  0.0004,  0.0072]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 079]: 100% 1/1 [00:00<00:00,  8.87it/s]\u001b[0m\n",
            "[Epoch 080]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0303,  0.0246,  0.0496,  ...,  0.0701, -0.1260,  0.0480],\n",
            "        [-0.0341, -0.0152, -0.0414,  ...,  0.1303,  0.0141,  0.0106],\n",
            "        [ 0.0112,  0.0168, -0.0853,  ...,  0.0674, -0.0820, -0.0171],\n",
            "        ...,\n",
            "        [ 0.1321,  0.0270, -0.0631,  ...,  0.1110, -0.0537,  0.0468],\n",
            "        [-0.1327, -0.0088, -0.1359,  ...,  0.0906,  0.0028,  0.1576],\n",
            "        [ 0.0919,  0.0373, -0.0148,  ...,  0.0504, -0.0632, -0.0114]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 080]: 100% 1/1 [00:00<00:00,  7.14it/s]\u001b[0m\n",
            "[Epoch 081]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0209,  0.0851, -0.0411,  ...,  0.1086, -0.1241,  0.0104],\n",
            "        [-0.0868, -0.0500, -0.0630,  ..., -0.0514, -0.0263, -0.0154],\n",
            "        [ 0.0054,  0.0180, -0.1407,  ..., -0.0600, -0.0120,  0.1001],\n",
            "        ...,\n",
            "        [-0.0073, -0.0009, -0.0049,  ...,  0.0060,  0.0004,  0.0074],\n",
            "        [ 0.0337, -0.0269, -0.0557,  ..., -0.0367, -0.0036,  0.0117],\n",
            "        [-0.0288,  0.0702, -0.0371,  ...,  0.0671,  0.0407,  0.1261]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 081]: 100% 1/1 [00:00<00:00,  9.16it/s]\u001b[0m\n",
            "[Epoch 082]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0131,  0.0614, -0.0977,  ..., -0.0431, -0.0844,  0.0487],\n",
            "        [ 0.0276, -0.0689,  0.0067,  ...,  0.1685,  0.0058,  0.0630],\n",
            "        [-0.0074, -0.0010, -0.0049,  ...,  0.0061,  0.0004,  0.0075],\n",
            "        ...,\n",
            "        [ 0.0188, -0.0395,  0.1137,  ...,  0.0038, -0.0096,  0.0895],\n",
            "        [-0.0129,  0.0209,  0.0055,  ...,  0.1460, -0.0044,  0.0571],\n",
            "        [-0.0112, -0.0038, -0.1494,  ...,  0.0119, -0.0683, -0.0227]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 082]: 100% 1/1 [00:00<00:00,  7.95it/s]\u001b[0m\n",
            "[Epoch 083]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1409,  0.0855,  0.0495,  ...,  0.0847, -0.0252,  0.0079],\n",
            "        [-0.0390,  0.1113,  0.0240,  ..., -0.0412,  0.0606,  0.0887],\n",
            "        [ 0.0656,  0.1699, -0.0486,  ..., -0.0644, -0.0914, -0.0015],\n",
            "        ...,\n",
            "        [-0.0484,  0.0196, -0.0603,  ...,  0.0871,  0.0431,  0.0992],\n",
            "        [-0.0260,  0.0335,  0.0275,  ...,  0.0363,  0.0086, -0.1156],\n",
            "        [-0.0075, -0.0009, -0.0050,  ...,  0.0061,  0.0004,  0.0076]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 083]: 100% 1/1 [00:00<00:00,  7.56it/s]\u001b[0m\n",
            "[Epoch 084]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1245, -0.0779,  0.0420,  ..., -0.0246,  0.0392,  0.0421],\n",
            "        [ 0.0148, -0.0127, -0.0890,  ..., -0.0107, -0.0747,  0.0282],\n",
            "        [ 0.0368,  0.0720,  0.0313,  ...,  0.0778,  0.0022, -0.0549],\n",
            "        ...,\n",
            "        [ 0.0352,  0.0724,  0.0015,  ..., -0.1081, -0.0285, -0.0154],\n",
            "        [ 0.0527,  0.0211, -0.0101,  ...,  0.0490, -0.0217,  0.0821],\n",
            "        [ 0.0935,  0.0464, -0.0813,  ...,  0.0359,  0.0111, -0.0075]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 084]: 100% 1/1 [00:00<00:00,  9.15it/s]\u001b[0m\n",
            "[Epoch 085]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1208,  0.0122,  0.0082,  ..., -0.0610, -0.0820, -0.0321],\n",
            "        [ 0.0029,  0.1133, -0.0998,  ...,  0.0030, -0.0082,  0.0578],\n",
            "        [ 0.0414,  0.1388, -0.0720,  ..., -0.0794, -0.0706,  0.0262],\n",
            "        ...,\n",
            "        [ 0.0051,  0.0180, -0.1409,  ..., -0.0597, -0.0120,  0.1005],\n",
            "        [-0.0767, -0.0246,  0.1130,  ..., -0.0278,  0.0178, -0.0448],\n",
            "        [-0.0728,  0.0544, -0.0283,  ...,  0.1241, -0.0244,  0.1191]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 085]: 100% 1/1 [00:00<00:00,  7.27it/s]\u001b[0m\n",
            "[Epoch 086]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0077, -0.0010, -0.0052,  ...,  0.0063,  0.0003,  0.0078],\n",
            "        [ 0.0788, -0.0558, -0.0512,  ...,  0.1757,  0.0642,  0.0218],\n",
            "        [-0.0728, -0.1747, -0.1003,  ...,  0.0579, -0.1533,  0.0992],\n",
            "        ...,\n",
            "        [-0.0403, -0.0824, -0.0137,  ...,  0.0004,  0.0024, -0.0786],\n",
            "        [-0.0485, -0.0720, -0.0031,  ...,  0.1240, -0.0110,  0.0964],\n",
            "        [-0.0077, -0.0010, -0.0052,  ...,  0.0063,  0.0003,  0.0078]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 086]: 100% 1/1 [00:00<00:00,  7.80it/s]\u001b[0m\n",
            "[Epoch 087]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0276, -0.0679,  0.0057,  ...,  0.0273,  0.0941,  0.0317],\n",
            "        [-0.0516, -0.0367, -0.1349,  ...,  0.1183, -0.1333, -0.0173],\n",
            "        [-0.0539,  0.0409,  0.1010,  ..., -0.0479,  0.0375,  0.0295],\n",
            "        ...,\n",
            "        [-0.0524,  0.0304, -0.0727,  ..., -0.0348,  0.0819,  0.0358],\n",
            "        [ 0.0767, -0.1002, -0.0199,  ..., -0.0062, -0.1155, -0.0350],\n",
            "        [-0.0566, -0.0024,  0.0752,  ..., -0.0689, -0.0088, -0.0179]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 087]: 100% 1/1 [00:00<00:00,  7.09it/s]\u001b[0m\n",
            "[Epoch 088]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-4.2055e-02, -6.7171e-02, -7.6148e-02,  ...,  1.2473e-01,\n",
            "          6.5864e-03,  2.7904e-02],\n",
            "        [-1.0180e-01, -2.1951e-03,  6.0085e-02,  ...,  9.7986e-02,\n",
            "          1.9197e-02,  3.2053e-02],\n",
            "        [-3.3806e-02,  2.8526e-02, -1.6421e-02,  ..., -1.1552e-01,\n",
            "          1.2134e-01, -2.5258e-03],\n",
            "        ...,\n",
            "        [-1.7263e-01, -7.1415e-02,  9.9930e-03,  ...,  5.6665e-02,\n",
            "         -1.0209e-01, -5.6811e-02],\n",
            "        [-2.0502e-02,  4.3368e-02, -1.6454e-04,  ...,  1.9635e-02,\n",
            "         -8.1084e-02, -2.1187e-02],\n",
            "        [ 1.2390e-01,  1.1694e-01, -3.2095e-02,  ..., -7.9493e-02,\n",
            "         -4.5641e-03, -2.8806e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 088]: 100% 1/1 [00:00<00:00,  8.52it/s]\u001b[0m\n",
            "[Epoch 089]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1007, -0.0520, -0.1525,  ...,  0.1697,  0.0050,  0.0104],\n",
            "        [-0.0457,  0.1224, -0.0205,  ..., -0.0810,  0.0111,  0.0870],\n",
            "        [-0.0596, -0.0179, -0.0273,  ...,  0.0385, -0.1877,  0.0719],\n",
            "        ...,\n",
            "        [ 0.0011,  0.0030, -0.0516,  ..., -0.1213,  0.0082,  0.0637],\n",
            "        [-0.0556,  0.0452,  0.1108,  ...,  0.0936,  0.0596,  0.0798],\n",
            "        [ 0.0514, -0.0259, -0.2907,  ..., -0.0723,  0.1122,  0.0035]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 089]: 100% 1/1 [00:00<00:00,  6.65it/s]\u001b[0m\n",
            "[Epoch 090]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0122, -0.0485, -0.0049,  ...,  0.0881, -0.0580, -0.0254],\n",
            "        [-0.0214,  0.0398, -0.0019,  ...,  0.1341, -0.0119,  0.0070],\n",
            "        [-0.1039, -0.0579, -0.0534,  ...,  0.3208,  0.0393,  0.0800],\n",
            "        ...,\n",
            "        [-0.0081, -0.0009, -0.0054,  ...,  0.0066,  0.0004,  0.0082],\n",
            "        [ 0.1483,  0.0198, -0.0636,  ...,  0.0886, -0.0465,  0.0708],\n",
            "        [-0.0866, -0.0228,  0.0473,  ...,  0.0472, -0.0860,  0.1184]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 090]: 100% 1/1 [00:00<00:00,  8.38it/s]\u001b[0m\n",
            "[Epoch 091]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1410,  0.1880,  0.0566,  ...,  0.0102, -0.1801, -0.0238],\n",
            "        [-0.0851, -0.0082, -0.1054,  ...,  0.1335, -0.0837, -0.0849],\n",
            "        [-0.0335, -0.0410, -0.0416,  ...,  0.0964, -0.0557,  0.1959],\n",
            "        ...,\n",
            "        [ 0.0031,  0.1050, -0.0573,  ...,  0.1054,  0.0205,  0.0567],\n",
            "        [-0.1201,  0.1006, -0.0377,  ...,  0.0786,  0.0672,  0.0550],\n",
            "        [-0.0026, -0.0093, -0.1037,  ...,  0.0602,  0.0015,  0.0297]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 091]: 100% 1/1 [00:00<00:00,  7.04it/s]\u001b[0m\n",
            "[Epoch 092]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0083, -0.0009, -0.0056,  ...,  0.0067,  0.0004,  0.0084],\n",
            "        [ 0.0180, -0.0323, -0.1036,  ...,  0.0436, -0.1534, -0.0114],\n",
            "        [-0.0488,  0.1345, -0.0370,  ..., -0.0031, -0.0819,  0.0088],\n",
            "        ...,\n",
            "        [-0.0176,  0.0195, -0.0775,  ..., -0.0241,  0.0800,  0.0053],\n",
            "        [-0.0447,  0.0377, -0.1109,  ..., -0.2459, -0.1432, -0.0315],\n",
            "        [-0.0617,  0.0846,  0.0091,  ...,  0.1319, -0.0464, -0.0256]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 092]: 100% 1/1 [00:00<00:00,  8.13it/s]\u001b[0m\n",
            "[Epoch 093]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0029,  0.0714, -0.0397,  ..., -0.0128, -0.0397, -0.0143],\n",
            "        [-0.0521, -0.0366, -0.1353,  ...,  0.1187, -0.1334, -0.0167],\n",
            "        [ 0.0132,  0.1777, -0.1826,  ..., -0.1354, -0.1499, -0.0490],\n",
            "        ...,\n",
            "        [-0.0084, -0.0009, -0.0057,  ...,  0.0068,  0.0004,  0.0085],\n",
            "        [ 0.0551,  0.1550, -0.0707,  ..., -0.0510,  0.0565, -0.0130],\n",
            "        [-0.1280, -0.0900,  0.0845,  ..., -0.0767,  0.1357, -0.1760]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 093]: 100% 1/1 [00:00<00:00,  7.19it/s]\u001b[0m\n",
            "[Epoch 094]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0279,  0.0612, -0.0727,  ...,  0.0806, -0.1467,  0.1632],\n",
            "        [-0.0085, -0.0010, -0.0058,  ...,  0.0069,  0.0004,  0.0086],\n",
            "        [ 0.0819,  0.0379,  0.0503,  ...,  0.0573, -0.0090, -0.1333],\n",
            "        ...,\n",
            "        [-0.0181,  0.0560,  0.1189,  ...,  0.0508, -0.0803,  0.0153],\n",
            "        [-0.0265,  0.0359,  0.0134,  ...,  0.0517,  0.1028,  0.0566],\n",
            "        [-0.0085, -0.0010, -0.0058,  ...,  0.0069,  0.0004,  0.0086]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 094]: 100% 1/1 [00:00<00:00,  7.91it/s]\u001b[0m\n",
            "[Epoch 095]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1722,  0.1445,  0.0982,  ...,  0.0458, -0.1870, -0.0237],\n",
            "        [-0.0343,  0.0042,  0.0611,  ...,  0.0563,  0.0187, -0.0877],\n",
            "        [-0.1108, -0.0490, -0.1402,  ...,  0.0834, -0.1560,  0.0129],\n",
            "        ...,\n",
            "        [ 0.0803, -0.0738, -0.1331,  ...,  0.1439, -0.0486,  0.0175],\n",
            "        [-0.0466,  0.0517,  0.0991,  ..., -0.0569,  0.0171,  0.0533],\n",
            "        [-0.1554, -0.0070, -0.1284,  ..., -0.0840, -0.1247,  0.0216]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 095]: 100% 1/1 [00:00<00:00,  8.96it/s]\u001b[0m\n",
            "[Epoch 096]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0060,  0.0672, -0.1348,  ..., -0.1869, -0.0248,  0.1029],\n",
            "        [ 0.0847,  0.0293, -0.0472,  ...,  0.1064,  0.0138,  0.0124],\n",
            "        [-0.0600,  0.0200, -0.0790,  ...,  0.0869,  0.2134,  0.0577],\n",
            "        ...,\n",
            "        [-0.0290, -0.0609, -0.0438,  ...,  0.2299, -0.0357,  0.0676],\n",
            "        [ 0.0747,  0.1336,  0.0195,  ..., -0.0423, -0.0190, -0.0409],\n",
            "        [ 0.0328, -0.0197, -0.0203,  ..., -0.0173,  0.0269,  0.0437]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 096]: 100% 1/1 [00:00<00:00,  6.97it/s]\u001b[0m\n",
            "[Epoch 097]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0916, -0.0350,  0.0690,  ...,  0.1152, -0.1123, -0.0668],\n",
            "        [-0.0845,  0.0219, -0.1447,  ...,  0.0282,  0.0080, -0.1048],\n",
            "        [ 0.0110,  0.0133, -0.0743,  ...,  0.0518, -0.0497, -0.0163],\n",
            "        ...,\n",
            "        [ 0.0300,  0.0618, -0.1881,  ..., -0.0409,  0.1455,  0.0349],\n",
            "        [-0.0100,  0.1021, -0.1605,  ..., -0.0838, -0.1558, -0.0765],\n",
            "        [ 0.0099, -0.0207,  0.0047,  ...,  0.0304, -0.0839,  0.0591]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 097]: 100% 1/1 [00:00<00:00,  8.71it/s]\u001b[0m\n",
            "[Epoch 098]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0803,  0.0914, -0.0047,  ..., -0.0166, -0.0868,  0.0595],\n",
            "        [-0.0207,  0.0212, -0.0098,  ..., -0.0092, -0.0062,  0.0578],\n",
            "        [-0.0089, -0.0010, -0.0060,  ...,  0.0072,  0.0004,  0.0089],\n",
            "        ...,\n",
            "        [ 0.0024,  0.1048, -0.0578,  ...,  0.1059,  0.0206,  0.0572],\n",
            "        [ 0.0179,  0.0011, -0.0162,  ..., -0.0131, -0.0400, -0.1367],\n",
            "        [-0.0778, -0.0640,  0.0061,  ..., -0.0335, -0.0490,  0.0901]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 098]: 100% 1/1 [00:00<00:00,  5.62it/s]\u001b[0m\n",
            "[Epoch 099]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0781, -0.0298, -0.0216,  ..., -0.0873,  0.1046, -0.1262],\n",
            "        [-0.0914, -0.0294,  0.0171,  ..., -0.0925, -0.0661,  0.0547],\n",
            "        [-0.0183,  0.0608, -0.0925,  ..., -0.0071, -0.0666, -0.0022],\n",
            "        ...,\n",
            "        [-0.0393,  0.0042, -0.1063,  ..., -0.0586,  0.0114, -0.0114],\n",
            "        [ 0.0347,  0.1117, -0.0149,  ...,  0.1100, -0.0149,  0.0471],\n",
            "        [ 0.0514,  0.0211, -0.0111,  ...,  0.0499, -0.0217,  0.0837]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 099]: 100% 1/1 [00:00<00:00,  4.69it/s]\u001b[0m\n",
            "[Epoch 100]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0488,  0.1226,  0.0394,  ...,  0.0270, -0.0909, -0.0044],\n",
            "        [-0.0767, -0.0420, -0.0702,  ..., -0.0915,  0.1236, -0.1481],\n",
            "        [-0.0888,  0.0988, -0.0467,  ..., -0.0196, -0.0339,  0.0385],\n",
            "        ...,\n",
            "        [ 0.0957,  0.0446, -0.0153,  ...,  0.0398, -0.0065, -0.0212],\n",
            "        [ 0.0037,  0.0181, -0.1417,  ..., -0.0586, -0.0119,  0.1020],\n",
            "        [-0.0310, -0.1135, -0.0433,  ...,  0.0181,  0.0287, -0.0160]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 100]: 100% 1/1 [00:00<00:00,  4.73it/s]\u001b[0m\n",
            "\u001b[0m14 Apr 00:14 INFO - Finish 1 train-validation experiment(s)...\u001b[0m\n",
            "\u001b[0m14 Apr 00:14 INFO - Start Calculating Metrics...\u001b[0m\n",
            "\u001b[0m14 Apr 00:14 INFO - ==========================\u001b[0m\n",
            "\u001b[0m14 Apr 00:14 INFO - Generate recommend list...\u001b[0m\n",
            "\u001b[0m14 Apr 00:14 INFO - ==========================\u001b[0m\n",
            "\u001b[0m\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0033,  0.0525, -0.0325,  ...,  0.0572,  0.0100,  0.0330],\n",
            "        [ 0.0041, -0.0180, -0.0490,  ...,  0.0960, -0.0212,  0.0548],\n",
            "        [ 0.0072, -0.0596, -0.0246,  ...,  0.0172, -0.1521,  0.0201],\n",
            "        ...,\n",
            "        [-0.0091, -0.0010, -0.0062,  ...,  0.0074,  0.0004,  0.0092],\n",
            "        [-0.0153,  0.0431,  0.0149,  ...,  0.0375, -0.0075, -0.0206],\n",
            "        [-0.0775, -0.0335,  0.0206,  ..., -0.0589,  0.0712, -0.0960]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "\u001b[0mPREDS\u001b[0m \u001b[0m[[203. 203. 324. ... 406. 406.  59.]\n",
            " [354. 403. 240. ... 104. 104. 288.]\n",
            " [ 82.  70.  70. ... 152. 152. 434.]\n",
            " ...\n",
            " [151. 151. 291. ... 141. 141.  78.]\n",
            " [194. 194. 194. ... 120. 282. 282.]\n",
            " [177. 177. 177. ... 220.  79. 258.]]\u001b[0m\n",
            "14 Apr 00:14 INFO - Finish 38 trial...\u001b[0m\n",
            "\u001b[0m\u001b[32m[I 2023-04-14 00:14:12,954]\u001b[0m Trial 37 finished with value: 0.07173560530024346 and parameters: {}. Best is trial 10 with value: 0.1209022497797705.\u001b[0m\n",
            "\u001b[0mLine1\u001b[0m\n",
            "\u001b[0mApplying weights\u001b[0m\n",
            "\u001b[0mAfter applying wieghts\u001b[0m\n",
            "\u001b[0mLine2\u001b[0m\n",
            "\u001b[0mModel fitting\u001b[0m\n",
            "[Epoch 001]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0285,  0.1324,  0.1002,  ...,  0.0776,  0.0713,  0.0747],\n",
            "        [-0.1929,  0.0172,  0.0365,  ...,  0.0581, -0.0700,  0.0262],\n",
            "        [-0.1520, -0.0630,  0.1034,  ..., -0.0509, -0.0073,  0.0742],\n",
            "        ...,\n",
            "        [ 0.0029, -0.0922, -0.0975,  ..., -0.0169,  0.1559,  0.1567],\n",
            "        [ 0.1010, -0.0595,  0.0117,  ..., -0.0413, -0.0308,  0.0674],\n",
            "        [-0.0345,  0.0438, -0.1222,  ...,  0.1181,  0.0274,  0.0566]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 001]: 100% 1/1 [00:00<00:00,  5.42it/s]\u001b[0m\n",
            "[Epoch 002]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0791,  0.0543, -0.1688,  ...,  0.1091, -0.0228,  0.0901],\n",
            "        [ 0.0328,  0.0073,  0.0938,  ..., -0.0605,  0.0873,  0.1099],\n",
            "        [ 0.0531, -0.0373, -0.1013,  ..., -0.0222, -0.0140,  0.0297],\n",
            "        ...,\n",
            "        [ 0.0338,  0.1114,  0.0380,  ..., -0.0985, -0.0625, -0.0204],\n",
            "        [ 0.0140,  0.0866,  0.0788,  ..., -0.1472,  0.0332,  0.0656],\n",
            "        [ 0.0848,  0.1646,  0.0947,  ..., -0.1377, -0.0007, -0.0552]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 002]: 100% 1/1 [00:00<00:00,  5.53it/s]\u001b[0m\n",
            "[Epoch 003]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0801, -0.0182,  0.0943,  ..., -0.0362, -0.0315, -0.0863],\n",
            "        [ 0.0606, -0.0585, -0.0415,  ..., -0.0932,  0.0698,  0.0462],\n",
            "        [ 0.0212,  0.1399,  0.0224,  ..., -0.1643,  0.0057, -0.1542],\n",
            "        ...,\n",
            "        [ 0.2504, -0.1277,  0.1211,  ...,  0.0346, -0.0212,  0.0552],\n",
            "        [-0.0126, -0.0802, -0.0643,  ..., -0.0818, -0.0218,  0.0232],\n",
            "        [-0.1132,  0.1277,  0.0072,  ..., -0.0082, -0.0530,  0.0255]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 003]: 100% 1/1 [00:00<00:00,  5.07it/s]\u001b[0m\n",
            "[Epoch 004]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0424, -0.0775,  0.0226,  ...,  0.0408, -0.1419,  0.0338],\n",
            "        [ 0.0685,  0.0092,  0.0971,  ...,  0.0245, -0.0803, -0.0457],\n",
            "        [-0.0938,  0.0167,  0.0300,  ..., -0.0087, -0.1121, -0.0153],\n",
            "        ...,\n",
            "        [ 0.0485, -0.0598,  0.0637,  ..., -0.0631,  0.0160,  0.0841],\n",
            "        [ 0.0396, -0.0184,  0.0265,  ..., -0.0422,  0.0363,  0.0905],\n",
            "        [ 0.0177, -0.0590, -0.1512,  ..., -0.0326, -0.0482, -0.0543]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 004]: 100% 1/1 [00:00<00:00,  4.85it/s]\u001b[0m\n",
            "[Epoch 005]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 1.7333e-02, -3.6328e-02, -1.2477e-01,  ...,  4.1502e-03,\n",
            "          1.1439e-01,  6.6272e-03],\n",
            "        [ 9.3088e-02, -5.1653e-02,  9.3914e-02,  ..., -3.1337e-02,\n",
            "         -6.3371e-02, -7.0730e-02],\n",
            "        [-2.3537e-04,  8.0534e-05,  2.1799e-05,  ..., -6.9222e-04,\n",
            "          1.8699e-04,  3.0372e-04],\n",
            "        ...,\n",
            "        [-1.5220e-02,  2.8797e-02, -5.4172e-02,  ..., -1.5268e-01,\n",
            "         -1.3909e-01, -1.2621e-01],\n",
            "        [-4.4697e-02, -1.0400e-03, -9.4578e-02,  ...,  1.0038e-01,\n",
            "          4.6818e-02,  6.5636e-02],\n",
            "        [ 1.3381e-01,  5.6576e-02,  6.6446e-02,  ...,  2.0247e-02,\n",
            "         -3.6461e-02, -3.6657e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 005]: 100% 1/1 [00:00<00:00,  4.44it/s]\u001b[0m\n",
            "[Epoch 006]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0271,  0.0233, -0.0636,  ..., -0.0481, -0.1540,  0.0931],\n",
            "        [ 0.0593, -0.0525,  0.0828,  ..., -0.0971,  0.0521, -0.0332],\n",
            "        [-0.0462,  0.0258, -0.1401,  ...,  0.0265,  0.0383,  0.0673],\n",
            "        ...,\n",
            "        [ 0.1986, -0.0708,  0.1234,  ...,  0.0466,  0.1062, -0.1870],\n",
            "        [ 0.0340,  0.1034,  0.0293,  ..., -0.0057,  0.0233,  0.1535],\n",
            "        [ 0.0779,  0.2267,  0.2113,  ...,  0.1452,  0.0598, -0.0212]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 006]: 100% 1/1 [00:00<00:00,  4.78it/s]\u001b[0m\n",
            "[Epoch 007]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-2.9903e-04,  1.0245e-04,  1.1832e-05,  ..., -1.0513e-03,\n",
            "          2.8848e-04,  4.7218e-04],\n",
            "        [-3.4556e-02, -9.5430e-02, -1.9625e-02,  ..., -1.1041e-02,\n",
            "         -1.9810e-02,  7.2738e-02],\n",
            "        [ 1.1450e-01, -1.1724e-02,  1.1087e-02,  ..., -6.6359e-02,\n",
            "          2.3292e-02,  1.2022e-02],\n",
            "        ...,\n",
            "        [-5.0238e-02,  3.8429e-02, -3.1824e-02,  ..., -1.6237e-02,\n",
            "         -3.5689e-03,  1.2712e-01],\n",
            "        [ 3.4190e-02, -2.4593e-02, -3.2959e-02,  ...,  1.1132e-02,\n",
            "          1.4588e-01, -2.0246e-02],\n",
            "        [ 1.3638e-01,  9.7965e-02,  9.4951e-02,  ..., -4.9772e-02,\n",
            "          2.1425e-01, -2.8323e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 007]: 100% 1/1 [00:00<00:00,  5.69it/s]\u001b[0m\n",
            "[Epoch 008]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0359,  0.0214,  0.0324,  ...,  0.0970,  0.0503,  0.0442],\n",
            "        [-0.0624, -0.0447, -0.0363,  ..., -0.1123, -0.0779, -0.0028],\n",
            "        [ 0.0913,  0.0755, -0.0145,  ...,  0.0714, -0.0459, -0.0065],\n",
            "        ...,\n",
            "        [-0.0560, -0.0189, -0.0532,  ..., -0.1019,  0.1848, -0.0250],\n",
            "        [ 0.0218, -0.0137, -0.0535,  ..., -0.0866, -0.1985,  0.0690],\n",
            "        [ 0.0308, -0.0246,  0.0277,  ...,  0.0366, -0.0024, -0.0956]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 008]: 100% 1/1 [00:00<00:00,  4.70it/s]\u001b[0m\n",
            "[Epoch 009]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0119,  0.0713, -0.0603,  ...,  0.0630, -0.0474, -0.1386],\n",
            "        [ 0.0391,  0.0517, -0.0324,  ...,  0.0659, -0.0019, -0.0402],\n",
            "        [ 0.0066,  0.0378,  0.0644,  ..., -0.0550,  0.0223,  0.0368],\n",
            "        ...,\n",
            "        [-0.0649,  0.1428, -0.0024,  ...,  0.2060, -0.0714, -0.1163],\n",
            "        [ 0.1266,  0.0971,  0.0835,  ..., -0.0208,  0.0314,  0.0703],\n",
            "        [-0.1109,  0.0581, -0.0865,  ...,  0.0205, -0.0089,  0.0212]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 009]: 100% 1/1 [00:00<00:00,  5.23it/s]\u001b[0m\n",
            "[Epoch 010]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 4.1632e-02,  3.8937e-02,  2.7607e-01,  ...,  3.8968e-02,\n",
            "         -5.6730e-03, -2.2522e-02],\n",
            "        [ 6.7030e-02, -1.0739e-02, -2.5207e-03,  ..., -3.7434e-02,\n",
            "          5.7598e-02,  7.0506e-03],\n",
            "        [-4.0097e-02,  1.1779e-01,  2.3318e-02,  ..., -9.3943e-03,\n",
            "         -3.6586e-02, -2.5835e-02],\n",
            "        ...,\n",
            "        [-4.1452e-04,  1.1208e-04,  2.2722e-05,  ..., -1.6027e-03,\n",
            "          3.8785e-04,  7.3014e-04],\n",
            "        [ 6.3922e-03, -4.8171e-02,  9.6240e-02,  ...,  4.0726e-02,\n",
            "          1.1636e-02,  3.3532e-02],\n",
            "        [-7.2322e-03,  1.3438e-02, -4.8466e-02,  ..., -1.6318e-01,\n",
            "         -5.5279e-02,  1.8547e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 010]: 100% 1/1 [00:00<00:00,  5.16it/s]\u001b[0m\n",
            "[Epoch 011]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1203,  0.0670,  0.0881,  ..., -0.0472,  0.0026,  0.0348],\n",
            "        [-0.1471,  0.0030,  0.0034,  ...,  0.0462, -0.1265, -0.0898],\n",
            "        [-0.1080,  0.0582,  0.0767,  ..., -0.0632,  0.0114, -0.1049],\n",
            "        ...,\n",
            "        [ 0.0890,  0.0839,  0.1184,  ..., -0.1289, -0.0140,  0.2055],\n",
            "        [ 0.0379,  0.1214,  0.0714,  ...,  0.0407, -0.0781,  0.0341],\n",
            "        [ 0.0908, -0.1306, -0.0846,  ...,  0.0814,  0.0774,  0.1084]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 011]: 100% 1/1 [00:00<00:00,  4.73it/s]\u001b[0m\n",
            "[Epoch 012]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0273,  0.0195,  0.0010,  ...,  0.0740, -0.0353, -0.0238],\n",
            "        [ 0.0605,  0.0414, -0.0474,  ...,  0.0233,  0.0043, -0.1072],\n",
            "        [ 0.0927, -0.0517,  0.0938,  ..., -0.0326, -0.0632, -0.0701],\n",
            "        ...,\n",
            "        [ 0.0223, -0.0309,  0.1599,  ...,  0.0246,  0.0418, -0.0635],\n",
            "        [-0.1062,  0.0156,  0.0203,  ..., -0.0410,  0.0210, -0.1688],\n",
            "        [-0.0885,  0.0615,  0.0085,  ..., -0.0617, -0.0810, -0.0471]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 012]: 100% 1/1 [00:00<00:00,  4.23it/s]\u001b[0m\n",
            "[Epoch 013]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1414, -0.1315, -0.0243,  ..., -0.0180, -0.0207, -0.0058],\n",
            "        [-0.0035, -0.0054,  0.0064,  ..., -0.0359, -0.0715, -0.0803],\n",
            "        [-0.1034,  0.0269, -0.0715,  ..., -0.0513,  0.0031, -0.1528],\n",
            "        ...,\n",
            "        [-0.0050, -0.0445,  0.0337,  ..., -0.1044, -0.0592, -0.0052],\n",
            "        [-0.0055,  0.0011,  0.0776,  ..., -0.0616,  0.0050, -0.0556],\n",
            "        [-0.0408,  0.0684,  0.1572,  ...,  0.0550, -0.0865, -0.1685]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 013]: 100% 1/1 [00:00<00:00,  5.33it/s]\u001b[0m\n",
            "[Epoch 014]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-3.6275e-02,  3.2914e-02,  4.5775e-04,  ...,  7.3234e-02,\n",
            "         -1.6703e-02, -9.3368e-02],\n",
            "        [ 2.5008e-01, -1.2763e-01,  1.2108e-01,  ...,  3.2746e-02,\n",
            "         -2.0730e-02,  5.6209e-02],\n",
            "        [ 2.2751e-02,  6.6200e-02, -1.1186e-01,  ...,  4.5647e-02,\n",
            "          3.5012e-02,  4.0295e-02],\n",
            "        ...,\n",
            "        [-1.7338e-01,  2.3236e-01,  6.0277e-04,  ...,  8.0761e-02,\n",
            "         -1.1141e-01, -2.2601e-02],\n",
            "        [ 6.7682e-02, -2.4072e-04,  3.7246e-02,  ...,  3.4716e-02,\n",
            "         -1.8780e-02, -1.1509e-02],\n",
            "        [-5.4602e-02, -5.7793e-02,  3.1384e-02,  ..., -9.1041e-02,\n",
            "         -9.7499e-02,  8.2430e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 014]: 100% 1/1 [00:00<00:00,  4.49it/s]\u001b[0m\n",
            "[Epoch 015]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 6.6198e-05, -6.2039e-02, -5.9935e-02,  ..., -1.2514e-01,\n",
            "          7.8384e-02, -7.7022e-02],\n",
            "        [ 4.0291e-02, -1.5764e-02, -1.7615e-02,  ...,  4.8219e-02,\n",
            "          5.3274e-02,  1.1245e-02],\n",
            "        [ 6.2368e-02, -1.0921e-01,  4.0768e-02,  ...,  4.5753e-02,\n",
            "         -1.3779e-02,  2.4222e-02],\n",
            "        ...,\n",
            "        [ 7.2050e-03,  6.9746e-03, -5.6395e-04,  ...,  6.6724e-02,\n",
            "          6.0377e-02,  5.9235e-02],\n",
            "        [ 6.0047e-02,  1.5959e-01,  1.5274e-01,  ...,  8.2614e-02,\n",
            "          1.7390e-03,  2.4426e-02],\n",
            "        [-5.4953e-02,  8.0629e-02, -4.3820e-02,  ...,  5.7558e-02,\n",
            "         -8.4768e-02,  3.2157e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 015]: 100% 1/1 [00:00<00:00,  5.05it/s]\u001b[0m\n",
            "[Epoch 016]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0155, -0.0147,  0.0787,  ...,  0.0168, -0.0343, -0.0783],\n",
            "        [-0.0457,  0.0055, -0.0015,  ..., -0.0649, -0.0037,  0.0154],\n",
            "        [-0.0303, -0.0583,  0.0174,  ..., -0.0848, -0.0857, -0.0368],\n",
            "        ...,\n",
            "        [-0.0508, -0.0631, -0.0049,  ..., -0.0907,  0.0072,  0.1294],\n",
            "        [ 0.0522, -0.0796,  0.1251,  ...,  0.0521,  0.1080, -0.1549],\n",
            "        [-0.1334,  0.0832, -0.0651,  ..., -0.0247,  0.0005, -0.0332]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 016]: 100% 1/1 [00:00<00:00,  5.01it/s]\u001b[0m\n",
            "[Epoch 017]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-4.0517e-02,  8.5734e-02,  2.5991e-02,  ...,  2.5563e-02,\n",
            "          4.3906e-02,  1.4205e-01],\n",
            "        [ 1.8047e-02, -1.2378e-02, -2.6981e-02,  ..., -1.0281e-01,\n",
            "         -9.3507e-03, -1.1512e-02],\n",
            "        [ 1.8662e-03,  7.2995e-02, -9.5725e-02,  ...,  7.4269e-02,\n",
            "          3.7574e-02, -3.5129e-02],\n",
            "        ...,\n",
            "        [ 4.8721e-02, -2.0040e-03,  8.0102e-02,  ..., -1.0413e-01,\n",
            "          4.9417e-02, -4.1790e-02],\n",
            "        [-7.1754e-04,  2.2184e-04,  1.3939e-04,  ..., -2.8925e-03,\n",
            "          6.5274e-04,  1.2322e-03],\n",
            "        [ 5.9305e-02,  1.3457e-01,  4.4765e-02,  ..., -1.1375e-01,\n",
            "          9.4852e-03,  9.6955e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 017]: 100% 1/1 [00:00<00:00,  4.75it/s]\u001b[0m\n",
            "[Epoch 018]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 1.8797e-01, -9.7247e-02,  1.5499e-01,  ...,  4.1789e-02,\n",
            "          7.3216e-03,  8.8182e-03],\n",
            "        [-7.8241e-04,  2.0300e-04,  1.8210e-04,  ..., -3.1070e-03,\n",
            "          6.8875e-04,  1.2944e-03],\n",
            "        [-3.3951e-03, -2.6974e-03,  6.7054e-02,  ...,  5.8792e-02,\n",
            "          1.6390e-02,  9.1876e-02],\n",
            "        ...,\n",
            "        [ 5.8852e-02, -5.2365e-02,  8.2900e-02,  ..., -9.9425e-02,\n",
            "          5.2835e-02, -3.2097e-02],\n",
            "        [-6.5622e-02, -1.6755e-02,  1.6119e-01,  ..., -3.5377e-02,\n",
            "          3.9019e-02, -1.0317e-01],\n",
            "        [ 7.4356e-02,  1.2583e-03, -1.0758e-01,  ...,  1.7738e-02,\n",
            "          8.4202e-02, -4.2807e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 018]: 100% 1/1 [00:00<00:00,  4.11it/s]\u001b[0m\n",
            "[Epoch 019]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0606, -0.1101,  0.0447,  ..., -0.0361,  0.0090,  0.1230],\n",
            "        [ 0.1070, -0.1293,  0.1216,  ..., -0.1579,  0.0422, -0.1521],\n",
            "        [-0.0733,  0.0991, -0.1592,  ...,  0.0731,  0.0430, -0.0637],\n",
            "        ...,\n",
            "        [ 0.0696, -0.0144, -0.0342,  ..., -0.0143,  0.0222, -0.0191],\n",
            "        [ 0.0352,  0.0248,  0.0537,  ..., -0.0797,  0.0450, -0.0440],\n",
            "        [ 0.1941, -0.0328,  0.0712,  ...,  0.0425,  0.0657, -0.1318]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 019]: 100% 1/1 [00:00<00:00,  5.27it/s]\u001b[0m\n",
            "[Epoch 020]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0827, -0.0885, -0.1470,  ...,  0.1386,  0.0059, -0.0833],\n",
            "        [ 0.0468, -0.0281,  0.1845,  ...,  0.0191, -0.0363, -0.0454],\n",
            "        [-0.0842, -0.0482, -0.0145,  ..., -0.1519, -0.0958, -0.0214],\n",
            "        ...,\n",
            "        [-0.1881,  0.1256, -0.0037,  ...,  0.0410, -0.0335,  0.1129],\n",
            "        [-0.0564,  0.0449,  0.1225,  ...,  0.0051,  0.0243, -0.0153],\n",
            "        [-0.0009,  0.0003,  0.0002,  ..., -0.0035,  0.0008,  0.0014]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 020]: 100% 1/1 [00:00<00:00,  5.12it/s]\u001b[0m\n",
            "[Epoch 021]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-1.0666e-01,  1.5823e-02,  2.0525e-02,  ..., -4.2720e-02,\n",
            "          2.1324e-02, -1.6821e-01],\n",
            "        [ 5.3022e-02,  2.5270e-02,  2.2418e-01,  ..., -4.4776e-02,\n",
            "          8.6452e-02, -5.0356e-02],\n",
            "        [ 1.1086e-01, -1.7329e-02, -4.9759e-03,  ..., -1.8456e-01,\n",
            "          1.3244e-01,  1.6369e-01],\n",
            "        ...,\n",
            "        [-5.2850e-02, -9.5733e-02, -5.9630e-02,  ..., -3.9040e-04,\n",
            "          9.1732e-02, -5.6009e-02],\n",
            "        [-1.0360e-01, -8.0274e-02,  3.0120e-02,  ..., -1.3621e-01,\n",
            "          1.3996e-04,  5.9238e-02],\n",
            "        [ 7.1538e-02, -3.5739e-02, -8.0478e-02,  ...,  3.3445e-02,\n",
            "          5.5003e-02,  1.5669e-04]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 021]: 100% 1/1 [00:00<00:00,  5.28it/s]\u001b[0m\n",
            "[Epoch 022]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0603,  0.0487, -0.0503,  ...,  0.0755,  0.0622,  0.1281],\n",
            "        [ 0.0572,  0.1912,  0.1130,  ...,  0.0845, -0.0050,  0.1489],\n",
            "        [ 0.0260,  0.0736,  0.0689,  ..., -0.0036,  0.0216, -0.0107],\n",
            "        ...,\n",
            "        [ 0.0329,  0.0262, -0.0252,  ..., -0.1332,  0.0394, -0.2787],\n",
            "        [ 0.0438,  0.1992,  0.0677,  ...,  0.0186, -0.1573,  0.0975],\n",
            "        [ 0.0589, -0.0389,  0.1835,  ...,  0.0418,  0.0022,  0.1206]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 022]: 100% 1/1 [00:00<00:00,  5.85it/s]\u001b[0m\n",
            "[Epoch 023]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0010,  0.0004,  0.0002,  ..., -0.0040,  0.0008,  0.0017],\n",
            "        [-0.0010,  0.0004,  0.0002,  ..., -0.0040,  0.0008,  0.0017],\n",
            "        [-0.0370, -0.0282, -0.0652,  ..., -0.0027, -0.0596, -0.0619],\n",
            "        ...,\n",
            "        [ 0.0173, -0.0021,  0.0367,  ...,  0.0830, -0.0327, -0.0616],\n",
            "        [ 0.0770,  0.0274,  0.0711,  ..., -0.0620, -0.0129, -0.0298],\n",
            "        [ 0.0199, -0.0106,  0.0241,  ..., -0.1237, -0.1326, -0.1116]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 023]: 100% 1/1 [00:00<00:00,  7.01it/s]\u001b[0m\n",
            "[Epoch 024]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0509,  0.0221,  0.0563,  ...,  0.0289, -0.1036,  0.0044],\n",
            "        [-0.0112,  0.0397, -0.0905,  ...,  0.0656,  0.0128,  0.0525],\n",
            "        [ 0.0414,  0.1123, -0.0060,  ...,  0.0498, -0.0608,  0.1308],\n",
            "        ...,\n",
            "        [ 0.1244,  0.1456,  0.0481,  ...,  0.0494, -0.0195, -0.0034],\n",
            "        [ 0.0266, -0.0598,  0.0850,  ..., -0.0765,  0.0176, -0.0784],\n",
            "        [ 0.0166, -0.0539,  0.0967,  ..., -0.0329,  0.0453,  0.0480]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 024]: 100% 1/1 [00:00<00:00,  7.71it/s]\u001b[0m\n",
            "[Epoch 025]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0229,  0.0117,  0.0734,  ..., -0.0791,  0.0635,  0.0225],\n",
            "        [ 0.1355,  0.0982,  0.0951,  ..., -0.0533,  0.2148, -0.0268],\n",
            "        [ 0.0624, -0.1137, -0.0084,  ..., -0.0264,  0.0404, -0.0093],\n",
            "        ...,\n",
            "        [ 0.0198,  0.1062, -0.1280,  ..., -0.1221, -0.0065, -0.0389],\n",
            "        [-0.0011,  0.0004,  0.0002,  ..., -0.0044,  0.0009,  0.0019],\n",
            "        [ 0.0347,  0.0901,  0.0475,  ...,  0.0802, -0.1193, -0.0953]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 025]: 100% 1/1 [00:00<00:00,  8.94it/s]\u001b[0m\n",
            "[Epoch 026]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0476,  0.0085,  0.0140,  ..., -0.0810,  0.0969,  0.0498],\n",
            "        [ 0.0368, -0.0045,  0.0240,  ..., -0.0164,  0.1010, -0.0279],\n",
            "        [ 0.1241,  0.0169, -0.0007,  ..., -0.1818,  0.0849,  0.2031],\n",
            "        ...,\n",
            "        [-0.0626,  0.0222,  0.2205,  ..., -0.1815, -0.0206,  0.2804],\n",
            "        [-0.0482, -0.0179,  0.0504,  ...,  0.0441,  0.0480,  0.1371],\n",
            "        [-0.1432,  0.0141, -0.0858,  ...,  0.0102, -0.0198,  0.0310]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 026]: 100% 1/1 [00:00<00:00,  7.32it/s]\u001b[0m\n",
            "[Epoch 027]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0582, -0.0438,  0.0228,  ..., -0.1150, -0.0873,  0.0057],\n",
            "        [-0.1136,  0.0548, -0.0460,  ...,  0.0560, -0.0172, -0.0710],\n",
            "        [-0.0126,  0.0213, -0.0152,  ...,  0.0033, -0.0160,  0.0131],\n",
            "        ...,\n",
            "        [-0.0012,  0.0004,  0.0003,  ..., -0.0048,  0.0010,  0.0021],\n",
            "        [-0.0013, -0.0672, -0.0290,  ..., -0.0400,  0.0133,  0.0003],\n",
            "        [ 0.0499,  0.0211, -0.0051,  ...,  0.0116, -0.0074, -0.0116]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 027]: 100% 1/1 [00:00<00:00,  8.69it/s]\u001b[0m\n",
            "[Epoch 028]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1051, -0.0131, -0.1047,  ..., -0.0140,  0.0089,  0.0556],\n",
            "        [-0.2310, -0.0829,  0.0363,  ..., -0.1138, -0.0278,  0.0278],\n",
            "        [ 0.0837,  0.0490,  0.0964,  ..., -0.1897, -0.1410, -0.0530],\n",
            "        ...,\n",
            "        [ 0.0380,  0.0279,  0.0457,  ...,  0.0312,  0.1523,  0.1849],\n",
            "        [ 0.0031, -0.0375,  0.0530,  ..., -0.0039,  0.0428, -0.0524],\n",
            "        [-0.0349, -0.0584,  0.1945,  ..., -0.1606, -0.1388,  0.0425]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 028]: 100% 1/1 [00:00<00:00,  6.89it/s]\u001b[0m\n",
            "[Epoch 029]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0034,  0.0109, -0.0552,  ...,  0.0500,  0.0204, -0.0050],\n",
            "        [ 0.0776,  0.0019,  0.0974,  ..., -0.0859,  0.0182, -0.0088],\n",
            "        [-0.0306,  0.0429, -0.1298,  ...,  0.0378,  0.0806,  0.0077],\n",
            "        ...,\n",
            "        [ 0.0681, -0.0027,  0.0219,  ...,  0.0573,  0.1080,  0.0889],\n",
            "        [ 0.0198,  0.1631,  0.0903,  ..., -0.0381, -0.1293,  0.0192],\n",
            "        [ 0.0025, -0.0941,  0.0905,  ...,  0.0038, -0.0560,  0.0892]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 029]: 100% 1/1 [00:00<00:00,  9.08it/s]\u001b[0m\n",
            "[Epoch 030]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0654,  0.0911,  0.1044,  ...,  0.0247,  0.0235,  0.0392],\n",
            "        [-0.0495,  0.0221, -0.0643,  ..., -0.1719,  0.1146, -0.1008],\n",
            "        [ 0.0856,  0.0439,  0.0150,  ...,  0.0438,  0.1505,  0.0456],\n",
            "        ...,\n",
            "        [-0.0857,  0.0316, -0.0907,  ...,  0.0195,  0.0347, -0.0650],\n",
            "        [ 0.0688,  0.0452, -0.0235,  ...,  0.0595,  0.0111, -0.0323],\n",
            "        [-0.0539, -0.0231, -0.0180,  ..., -0.0106,  0.0465, -0.0314]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 030]: 100% 1/1 [00:00<00:00,  9.12it/s]\u001b[0m\n",
            "[Epoch 031]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1159,  0.1470,  0.0028,  ...,  0.0038,  0.0256,  0.0552],\n",
            "        [ 0.0300, -0.0259, -0.0122,  ..., -0.0085,  0.0600,  0.0047],\n",
            "        [-0.1179, -0.0372, -0.0838,  ..., -0.0934, -0.0315, -0.0185],\n",
            "        ...,\n",
            "        [-0.0832, -0.0882, -0.1471,  ...,  0.1366,  0.0063, -0.0823],\n",
            "        [-0.0248,  0.1416,  0.1390,  ...,  0.0122,  0.0249,  0.0308],\n",
            "        [ 0.0179,  0.0890,  0.0818,  ..., -0.0348,  0.0405,  0.1549]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 031]: 100% 1/1 [00:00<00:00,  7.16it/s]\u001b[0m\n",
            "[Epoch 032]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0040, -0.0657,  0.0529,  ..., -0.0330, -0.0235,  0.0192],\n",
            "        [ 0.0556,  0.0122,  0.0719,  ..., -0.1298, -0.0460,  0.0561],\n",
            "        [-0.0637, -0.0265, -0.0659,  ..., -0.0385, -0.0426,  0.0530],\n",
            "        ...,\n",
            "        [-0.0627,  0.1857,  0.0161,  ..., -0.1291,  0.0457, -0.0506],\n",
            "        [-0.0263,  0.0310, -0.0683,  ..., -0.0721,  0.0172, -0.0736],\n",
            "        [-0.0014,  0.0006,  0.0003,  ..., -0.0057,  0.0012,  0.0024]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 032]: 100% 1/1 [00:00<00:00,  6.98it/s]\u001b[0m\n",
            "[Epoch 033]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0914, -0.0515,  0.0939,  ..., -0.0365, -0.0626, -0.0683],\n",
            "        [ 0.1195,  0.0345,  0.0873,  ..., -0.1179,  0.1263,  0.0346],\n",
            "        [ 0.0207,  0.1377, -0.0357,  ..., -0.0444,  0.0257,  0.0526],\n",
            "        ...,\n",
            "        [ 0.1813, -0.1365,  0.0245,  ...,  0.0048,  0.0607,  0.1040],\n",
            "        [ 0.0341,  0.1646, -0.0335,  ..., -0.0584, -0.0058,  0.0323],\n",
            "        [ 0.1167,  0.0666,  0.1439,  ..., -0.1020,  0.0030,  0.0167]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 033]: 100% 1/1 [00:00<00:00,  8.91it/s]\u001b[0m\n",
            "[Epoch 034]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 1.3218e-02, -5.2802e-02,  5.3636e-02,  ..., -8.3909e-02,\n",
            "         -8.9462e-02,  9.9435e-03],\n",
            "        [-1.5593e-03,  5.7542e-04,  2.6324e-04,  ..., -6.0681e-03,\n",
            "          1.3220e-03,  2.5723e-03],\n",
            "        [-6.2826e-02, -4.4556e-02,  2.9306e-02,  ..., -6.6005e-02,\n",
            "         -8.7707e-02, -1.6398e-02],\n",
            "        ...,\n",
            "        [-3.2880e-02, -8.5979e-02,  9.6347e-02,  ..., -2.2792e-02,\n",
            "         -3.1250e-02, -5.3055e-02],\n",
            "        [ 1.6612e-01,  8.5766e-02,  5.8847e-02,  ...,  2.9712e-01,\n",
            "         -2.4854e-02, -4.7809e-02],\n",
            "        [ 7.3851e-02,  5.4446e-02,  1.8221e-02,  ..., -6.8064e-02,\n",
            "         -1.5063e-02,  1.1039e-01]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 034]: 100% 1/1 [00:00<00:00,  7.81it/s]\u001b[0m\n",
            "[Epoch 035]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0726, -0.0565, -0.0609,  ...,  0.0043, -0.0362, -0.0321],\n",
            "        [-0.0701, -0.0503, -0.0600,  ..., -0.0180, -0.0467,  0.1157],\n",
            "        [ 0.0969,  0.0166, -0.0894,  ..., -0.0146,  0.0113, -0.0386],\n",
            "        ...,\n",
            "        [-0.1723,  0.0440, -0.0883,  ..., -0.0622, -0.0292,  0.0512],\n",
            "        [-0.1138,  0.0612,  0.0453,  ..., -0.0102, -0.1130,  0.0485],\n",
            "        [ 0.0038, -0.0389,  0.1609,  ..., -0.1554, -0.0627, -0.0911]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 035]: 100% 1/1 [00:00<00:00,  8.83it/s]\u001b[0m\n",
            "[Epoch 036]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1113,  0.0605, -0.0293,  ..., -0.0924, -0.1182, -0.0708],\n",
            "        [ 0.0852,  0.1824, -0.0168,  ..., -0.0487,  0.0216,  0.0363],\n",
            "        [ 0.1255, -0.1176, -0.0668,  ..., -0.0695, -0.0371,  0.0596],\n",
            "        ...,\n",
            "        [-0.0359,  0.0246,  0.0877,  ...,  0.0376, -0.0011, -0.0131],\n",
            "        [-0.0272,  0.0499, -0.1389,  ..., -0.1209,  0.0757,  0.0343],\n",
            "        [ 0.0336,  0.1270,  0.0312,  ...,  0.0800,  0.1339,  0.1068]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 036]: 100% 1/1 [00:00<00:00,  6.74it/s]\u001b[0m\n",
            "[Epoch 037]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0657, -0.1461,  0.0932,  ...,  0.0434,  0.0292, -0.0282],\n",
            "        [-0.0068, -0.0903,  0.0064,  ...,  0.0661,  0.0846,  0.0300],\n",
            "        [-0.0629, -0.0483,  0.1183,  ..., -0.0883,  0.0552,  0.0254],\n",
            "        ...,\n",
            "        [ 0.0128,  0.0446,  0.0608,  ..., -0.0844, -0.1282, -0.0292],\n",
            "        [-0.0312,  0.0101,  0.0062,  ..., -0.0376, -0.0122,  0.0380],\n",
            "        [ 0.0219, -0.0502, -0.0688,  ..., -0.0057, -0.0623, -0.1168]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 037]: 100% 1/1 [00:00<00:00,  9.40it/s]\u001b[0m\n",
            "[Epoch 038]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 1.4744e-02,  3.6024e-02, -2.7141e-02,  ..., -1.6660e-01,\n",
            "          1.1174e-01,  2.9271e-02],\n",
            "        [ 2.8898e-02,  1.0329e-01,  1.1967e-01,  ...,  5.9507e-02,\n",
            "         -1.2773e-01,  2.1585e-01],\n",
            "        [ 1.5881e-03, -2.6871e-02,  1.0557e-01,  ..., -1.5067e-01,\n",
            "          3.6710e-02,  5.8554e-02],\n",
            "        ...,\n",
            "        [-1.6700e-03,  6.7515e-04,  3.0944e-04,  ..., -6.7780e-03,\n",
            "          1.4618e-03,  2.8798e-03],\n",
            "        [-3.7875e-02,  5.3614e-02,  2.6651e-02,  ..., -1.1840e-02,\n",
            "          4.0790e-02,  3.6146e-02],\n",
            "        [ 1.5685e-02,  1.6309e-04,  3.0691e-02,  ..., -6.8474e-02,\n",
            "         -1.8522e-03,  3.7810e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 038]: 100% 1/1 [00:00<00:00,  9.50it/s]\u001b[0m\n",
            "[Epoch 039]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-1.2680e-02,  7.3117e-02, -8.1597e-02,  ...,  5.9138e-02,\n",
            "          4.9397e-02,  8.5318e-05],\n",
            "        [ 9.0308e-02,  7.5763e-02, -1.4506e-02,  ...,  6.5818e-02,\n",
            "         -4.4505e-02, -3.8268e-03],\n",
            "        [ 6.1505e-02, -7.6840e-02,  9.2084e-02,  ..., -1.3606e-01,\n",
            "         -2.0408e-02, -1.2217e-01],\n",
            "        ...,\n",
            "        [ 6.7226e-02,  1.0780e-02,  9.5860e-02,  ..., -1.2395e-01,\n",
            "          2.8290e-02,  1.4836e-01],\n",
            "        [ 7.9299e-02,  7.9002e-02,  9.4765e-02,  ...,  1.3204e-02,\n",
            "         -1.0208e-02,  6.6008e-03],\n",
            "        [ 9.5581e-02, -7.5187e-02, -1.4860e-01,  ...,  6.9639e-02,\n",
            "         -9.3241e-02, -1.0279e-01]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 039]: 100% 1/1 [00:00<00:00,  7.41it/s]\u001b[0m\n",
            "[Epoch 040]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0873,  0.0034, -0.0389,  ...,  0.0039,  0.0581, -0.0336],\n",
            "        [ 0.0877,  0.0845,  0.1189,  ..., -0.1343, -0.0128,  0.2075],\n",
            "        [ 0.0926, -0.0340,  0.0536,  ...,  0.0520, -0.0170,  0.0236],\n",
            "        ...,\n",
            "        [ 0.0252,  0.0757,  0.1093,  ..., -0.0269, -0.0027, -0.0690],\n",
            "        [ 0.0463,  0.0253,  0.0181,  ...,  0.0805,  0.1266,  0.1927],\n",
            "        [-0.0017,  0.0007,  0.0003,  ..., -0.0071,  0.0015,  0.0030]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 040]: 100% 1/1 [00:00<00:00,  8.71it/s]\u001b[0m\n",
            "[Epoch 041]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0357, -0.0688,  0.1343,  ...,  0.1272,  0.0582, -0.0527],\n",
            "        [-0.0099,  0.1039,  0.0217,  ...,  0.0152, -0.0759,  0.0465],\n",
            "        [ 0.0244, -0.0256,  0.1325,  ..., -0.0775, -0.0718,  0.1130],\n",
            "        ...,\n",
            "        [-0.1134,  0.0632, -0.0369,  ...,  0.1077, -0.0944, -0.0872],\n",
            "        [-0.0470, -0.0262, -0.0342,  ..., -0.0337, -0.0471,  0.0910],\n",
            "        [-0.1183,  0.0871, -0.0470,  ...,  0.0935,  0.0266, -0.0463]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 041]: 100% 1/1 [00:00<00:00,  7.30it/s]\u001b[0m\n",
            "[Epoch 042]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0671,  0.0097,  0.0973,  ...,  0.0177, -0.0787, -0.0425],\n",
            "        [-0.0717, -0.1126,  0.0069,  ..., -0.0630, -0.1110,  0.0215],\n",
            "        [-0.0843,  0.0439, -0.0601,  ..., -0.1876, -0.0268, -0.0933],\n",
            "        ...,\n",
            "        [-0.0055,  0.0454, -0.0836,  ..., -0.0120, -0.1581,  0.0669],\n",
            "        [ 0.0146, -0.0603, -0.0424,  ..., -0.0136, -0.0171,  0.0213],\n",
            "        [-0.0777,  0.0391,  0.0244,  ..., -0.1405, -0.1770,  0.0276]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 042]: 100% 1/1 [00:00<00:00,  9.27it/s]\u001b[0m\n",
            "[Epoch 043]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0586,  0.0387,  0.0725,  ..., -0.0976,  0.0728,  0.0032],\n",
            "        [-0.0837, -0.0879, -0.1471,  ...,  0.1345,  0.0067, -0.0814],\n",
            "        [ 0.0899,  0.0415,  0.0369,  ...,  0.0059, -0.0282, -0.0292],\n",
            "        ...,\n",
            "        [ 0.2156, -0.0035, -0.0775,  ..., -0.0556, -0.0199, -0.0269],\n",
            "        [-0.0019,  0.0008,  0.0003,  ..., -0.0076,  0.0016,  0.0032],\n",
            "        [ 0.0289, -0.0685, -0.0075,  ...,  0.0778,  0.0178,  0.0342]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 043]: 100% 1/1 [00:00<00:00,  7.94it/s]\u001b[0m\n",
            "[Epoch 044]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0019,  0.0008,  0.0004,  ..., -0.0078,  0.0017,  0.0033],\n",
            "        [ 0.0004, -0.0910, -0.0963,  ..., -0.0261,  0.1574,  0.1612],\n",
            "        [-0.0714,  0.0487, -0.0662,  ..., -0.0100,  0.0392,  0.0442],\n",
            "        ...,\n",
            "        [-0.1541, -0.0624,  0.1038,  ..., -0.0586, -0.0055,  0.0775],\n",
            "        [-0.0060,  0.0199, -0.0783,  ..., -0.0765, -0.2550,  0.0997],\n",
            "        [-0.0011,  0.0025,  0.0537,  ..., -0.1006, -0.0042, -0.0438]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 044]: 100% 1/1 [00:00<00:00,  7.51it/s]\u001b[0m\n",
            "[Epoch 045]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0362, -0.0946, -0.0193,  ..., -0.0179, -0.0181,  0.0758],\n",
            "        [ 0.0273,  0.0545, -0.0063,  ...,  0.0881, -0.0763, -0.1023],\n",
            "        [-0.0020,  0.0008,  0.0003,  ..., -0.0079,  0.0018,  0.0034],\n",
            "        ...,\n",
            "        [ 0.0480,  0.1203,  0.1330,  ..., -0.1157, -0.0588,  0.1129],\n",
            "        [-0.0076,  0.0163,  0.1778,  ..., -0.1030, -0.0042,  0.0008],\n",
            "        [-0.0887,  0.0320, -0.0166,  ..., -0.0112, -0.0696,  0.0063]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 045]: 100% 1/1 [00:00<00:00,  8.92it/s]\u001b[0m\n",
            "[Epoch 046]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0835, -0.0251,  0.0717,  ..., -0.0750,  0.0934,  0.0150],\n",
            "        [ 0.0348, -0.0039, -0.0790,  ..., -0.0215,  0.0630, -0.0659],\n",
            "        [-0.0267, -0.1287, -0.1142,  ...,  0.0538, -0.1127, -0.0698],\n",
            "        ...,\n",
            "        [ 0.0577,  0.1253,  0.1257,  ..., -0.0424, -0.0228,  0.1443],\n",
            "        [-0.1542, -0.0624,  0.1038,  ..., -0.0589, -0.0054,  0.0776],\n",
            "        [-0.1290,  0.0304, -0.0645,  ..., -0.0003, -0.0050,  0.1904]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 046]: 100% 1/1 [00:00<00:00,  7.45it/s]\u001b[0m\n",
            "[Epoch 047]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0839, -0.0878, -0.1471,  ...,  0.1338,  0.0069, -0.0810],\n",
            "        [-0.1054,  0.0622, -0.0473,  ...,  0.1285,  0.0517, -0.0047],\n",
            "        [-0.0420,  0.0767,  0.0886,  ..., -0.1277, -0.0152,  0.0635],\n",
            "        ...,\n",
            "        [-0.0301,  0.0233, -0.1075,  ..., -0.0257, -0.0490,  0.0129],\n",
            "        [-0.1029,  0.0444,  0.0034,  ..., -0.0039,  0.0272,  0.1427],\n",
            "        [-0.0148,  0.0486, -0.0702,  ..., -0.1615,  0.0955, -0.0173]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 047]: 100% 1/1 [00:00<00:00,  8.15it/s]\u001b[0m\n",
            "[Epoch 048]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0027,  0.0324, -0.0729,  ..., -0.0979,  0.1083, -0.0072],\n",
            "        [ 0.0906, -0.0515,  0.0939,  ..., -0.0391, -0.0623, -0.0671],\n",
            "        [ 0.0170, -0.0096, -0.0062,  ...,  0.0952, -0.0105, -0.0116],\n",
            "        ...,\n",
            "        [ 0.1188, -0.0634, -0.0630,  ..., -0.1310,  0.0846,  0.0477],\n",
            "        [ 0.0397, -0.0619, -0.0305,  ...,  0.0595, -0.0474,  0.0586],\n",
            "        [-0.0253,  0.0095,  0.1040,  ..., -0.1514,  0.0539,  0.1158]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 048]: 100% 1/1 [00:00<00:00,  7.67it/s]\u001b[0m\n",
            "[Epoch 049]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0142,  0.0989,  0.0589,  ..., -0.0903,  0.0410,  0.0104],\n",
            "        [-0.0873,  0.0343,  0.0367,  ..., -0.1049, -0.0746, -0.0406],\n",
            "        [-0.0157, -0.0018,  0.0558,  ...,  0.1008,  0.0652,  0.0943],\n",
            "        ...,\n",
            "        [ 0.0192,  0.0914, -0.0909,  ...,  0.1283,  0.0785,  0.0187],\n",
            "        [ 0.0124,  0.0556, -0.0457,  ..., -0.0579,  0.0148,  0.0853],\n",
            "        [ 0.0625, -0.0535,  0.1949,  ...,  0.0877,  0.0910, -0.1406]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 049]: 100% 1/1 [00:00<00:00,  9.10it/s]\u001b[0m\n",
            "[Epoch 050]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0765,  0.0022, -0.0523,  ..., -0.0905,  0.0267, -0.1589],\n",
            "        [ 0.0174,  0.0269,  0.1649,  ...,  0.0310, -0.0566, -0.0035],\n",
            "        [-0.0022,  0.0009,  0.0003,  ..., -0.0088,  0.0020,  0.0038],\n",
            "        ...,\n",
            "        [-0.0966, -0.0619, -0.0051,  ...,  0.0154, -0.0449,  0.0650],\n",
            "        [-0.0079, -0.0051, -0.0806,  ..., -0.0519, -0.0677, -0.0860],\n",
            "        [ 0.0079, -0.0219,  0.0712,  ...,  0.0305, -0.0210,  0.0374]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 050]: 100% 1/1 [00:00<00:00,  8.64it/s]\u001b[0m\n",
            "[Epoch 051]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0147, -0.2110, -0.0601,  ..., -0.0668,  0.0018,  0.0228],\n",
            "        [ 0.0242, -0.0041, -0.0147,  ..., -0.0450, -0.0209, -0.0179],\n",
            "        [ 0.0426, -0.1205, -0.0948,  ..., -0.0734,  0.1149,  0.1077],\n",
            "        ...,\n",
            "        [-0.1545, -0.0623,  0.1038,  ..., -0.0597, -0.0051,  0.0780],\n",
            "        [-0.1819,  0.0885, -0.0399,  ...,  0.0587,  0.0589,  0.0172],\n",
            "        [ 0.0602, -0.0930,  0.0265,  ..., -0.1336,  0.0412, -0.0274]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 051]: 100% 1/1 [00:00<00:00,  6.94it/s]\u001b[0m\n",
            "[Epoch 052]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0069, -0.0008, -0.0076,  ..., -0.1260, -0.0629, -0.0570],\n",
            "        [ 0.0331,  0.1083,  0.2137,  ..., -0.0426, -0.0374,  0.0999],\n",
            "        [-0.0175, -0.0059,  0.0461,  ..., -0.1159,  0.0233,  0.0936],\n",
            "        ...,\n",
            "        [ 0.0586,  0.1126,  0.1183,  ...,  0.0381, -0.1547,  0.0016],\n",
            "        [-0.1131,  0.0827,  0.0019,  ..., -0.0012,  0.1541,  0.0815],\n",
            "        [-0.0461, -0.0479, -0.0636,  ...,  0.0091,  0.0089, -0.0357]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 052]: 100% 1/1 [00:00<00:00,  9.05it/s]\u001b[0m\n",
            "[Epoch 053]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0504,  0.1285,  0.0229,  ..., -0.0985,  0.0118, -0.0653],\n",
            "        [-0.0743,  0.0180,  0.0062,  ..., -0.0383, -0.0121,  0.0137],\n",
            "        [ 0.0592, -0.0408,  0.0435,  ..., -0.0010,  0.0747,  0.0058],\n",
            "        ...,\n",
            "        [-0.1082,  0.0164,  0.0207,  ..., -0.0484,  0.0226, -0.1660],\n",
            "        [ 0.0115, -0.0095,  0.0011,  ..., -0.0801, -0.0070, -0.0151],\n",
            "        [ 0.0168,  0.0046, -0.0761,  ..., -0.1081, -0.3293,  0.0490]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 053]: 100% 1/1 [00:00<00:00,  6.41it/s]\u001b[0m\n",
            "[Epoch 054]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0874,  0.0023,  0.0418,  ..., -0.0413,  0.0516,  0.0525],\n",
            "        [-0.0982,  0.2047,  0.0156,  ...,  0.0761, -0.0454, -0.0214],\n",
            "        [ 0.0895, -0.0915,  0.0985,  ..., -0.1940, -0.0073, -0.1348],\n",
            "        ...,\n",
            "        [-0.1701,  0.0633, -0.2242,  ..., -0.1095,  0.0562,  0.0652],\n",
            "        [-0.1299, -0.0494,  0.0173,  ..., -0.0448, -0.0758,  0.0825],\n",
            "        [ 0.0613, -0.0293,  0.0051,  ..., -0.0823, -0.0211, -0.0453]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 054]: 100% 1/1 [00:00<00:00,  8.24it/s]\u001b[0m\n",
            "[Epoch 055]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1652,  0.0862,  0.0591,  ...,  0.2933, -0.0240, -0.0463],\n",
            "        [-0.0381,  0.1669,  0.0176,  ..., -0.0849,  0.0251,  0.0402],\n",
            "        [ 0.0889,  0.0276, -0.0395,  ...,  0.0005,  0.0675,  0.0461],\n",
            "        ...,\n",
            "        [-0.1866, -0.0450, -0.0109,  ..., -0.0095,  0.0726,  0.1724],\n",
            "        [ 0.0209, -0.0105,  0.0694,  ..., -0.1286,  0.1223,  0.0639],\n",
            "        [ 0.0381,  0.0933, -0.0509,  ..., -0.0533,  0.0297, -0.0066]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 055]: 100% 1/1 [00:00<00:00,  6.66it/s]\u001b[0m\n",
            "[Epoch 056]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0025,  0.0010,  0.0005,  ..., -0.0099,  0.0022,  0.0042],\n",
            "        [-0.1124,  0.0995, -0.0240,  ...,  0.0084, -0.0561,  0.0149],\n",
            "        [-0.0549,  0.0198, -0.0097,  ..., -0.0120, -0.0407,  0.0061],\n",
            "        ...,\n",
            "        [-0.0004,  0.0519,  0.1818,  ..., -0.0956, -0.1081, -0.1256],\n",
            "        [ 0.0282, -0.0497,  0.0515,  ...,  0.0217,  0.1382,  0.0835],\n",
            "        [ 0.0183,  0.1067, -0.1276,  ..., -0.1276, -0.0052, -0.0367]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 056]: 100% 1/1 [00:00<00:00,  7.74it/s]\u001b[0m\n",
            "[Epoch 057]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0409,  0.0650,  0.0944,  ..., -0.0044, -0.0223,  0.0601],\n",
            "        [-0.0908,  0.0625,  0.0091,  ..., -0.0695, -0.0793, -0.0438],\n",
            "        [ 0.1086, -0.0330,  0.0029,  ..., -0.0425,  0.0068,  0.0567],\n",
            "        ...,\n",
            "        [ 0.0990, -0.0578,  0.0128,  ..., -0.0516, -0.0288,  0.0718],\n",
            "        [ 0.0869,  0.0847,  0.1191,  ..., -0.1372, -0.0121,  0.2086],\n",
            "        [-0.0026,  0.0010,  0.0005,  ..., -0.0101,  0.0023,  0.0042]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 057]: 100% 1/1 [00:00<00:00,  8.34it/s]\u001b[0m\n",
            "[Epoch 058]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0676,  0.0041,  0.1182,  ..., -0.0841,  0.1881,  0.0858],\n",
            "        [ 0.0078,  0.0454, -0.0584,  ..., -0.1164,  0.0005, -0.0593],\n",
            "        [-0.0497,  0.0550, -0.0669,  ...,  0.0438,  0.0419,  0.0641],\n",
            "        ...,\n",
            "        [-0.0183,  0.0547,  0.0683,  ...,  0.0638, -0.0142,  0.0038],\n",
            "        [-0.0494,  0.0217,  0.1223,  ..., -0.0219, -0.1638, -0.0838],\n",
            "        [-0.1149,  0.0550, -0.0458,  ...,  0.0502, -0.0153, -0.0688]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 058]: 100% 1/1 [00:00<00:00,  7.28it/s]\u001b[0m\n",
            "[Epoch 059]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0381,  0.1370,  0.0204,  ..., -0.0644,  0.1377,  0.1894],\n",
            "        [-0.0047,  0.1684,  0.0538,  ..., -0.0616,  0.0790,  0.0490],\n",
            "        [ 0.0486, -0.0535,  0.0310,  ..., -0.0379,  0.0154, -0.0556],\n",
            "        ...,\n",
            "        [ 0.1337,  0.0989,  0.0953,  ..., -0.0594,  0.2162, -0.0243],\n",
            "        [-0.1252, -0.0506,  0.0164,  ..., -0.0277, -0.0363, -0.0610],\n",
            "        [-0.0040,  0.1176, -0.0771,  ...,  0.1486,  0.1079, -0.0276]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 059]: 100% 1/1 [00:00<00:00,  7.80it/s]\u001b[0m\n",
            "[Epoch 060]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0909,  0.0626,  0.0091,  ..., -0.0700, -0.0792, -0.0436],\n",
            "        [ 0.1186,  0.0111,  0.0813,  ..., -0.0349,  0.0674,  0.0544],\n",
            "        [-0.0200, -0.0920, -0.0746,  ..., -0.1055, -0.0384, -0.1454],\n",
            "        ...,\n",
            "        [-0.1091, -0.0134,  0.0540,  ...,  0.0507,  0.0036,  0.0283],\n",
            "        [ 0.0663, -0.0008,  0.1631,  ..., -0.0419,  0.0014,  0.0525],\n",
            "        [ 0.0513,  0.0408,  0.0845,  ...,  0.0552, -0.0982, -0.0994]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 060]: 100% 1/1 [00:00<00:00,  8.18it/s]\u001b[0m\n",
            "[Epoch 061]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1026,  0.1330,  0.0037,  ..., -0.0035, -0.0877,  0.0405],\n",
            "        [ 0.1381, -0.0782,  0.0782,  ...,  0.0557,  0.0860, -0.0342],\n",
            "        [ 0.0648,  0.0427,  0.0497,  ..., -0.0694,  0.0262,  0.0316],\n",
            "        ...,\n",
            "        [-0.0568,  0.0216, -0.0501,  ...,  0.0016,  0.0100,  0.1428],\n",
            "        [ 0.0086, -0.0203,  0.0112,  ..., -0.0759, -0.0326,  0.0943],\n",
            "        [-0.0006, -0.0990,  0.1210,  ..., -0.0086, -0.0148,  0.0450]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 061]: 100% 1/1 [00:00<00:00,  9.21it/s]\u001b[0m\n",
            "[Epoch 062]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0305, -0.0218,  0.0904,  ..., -0.1054,  0.0640,  0.1255],\n",
            "        [-0.0374,  0.0521, -0.0384,  ..., -0.1013, -0.1258, -0.0280],\n",
            "        [ 0.0201,  0.0342,  0.1974,  ...,  0.0722, -0.0364,  0.0464],\n",
            "        ...,\n",
            "        [ 0.1128,  0.0978, -0.0918,  ..., -0.0801,  0.0191,  0.0168],\n",
            "        [-0.0635, -0.0593,  0.1020,  ..., -0.0692,  0.0147, -0.0805],\n",
            "        [ 0.0782,  0.1131,  0.2296,  ..., -0.2666, -0.0216, -0.1094]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 062]: 100% 1/1 [00:00<00:00,  7.97it/s]\u001b[0m\n",
            "[Epoch 063]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0711, -0.0590, -0.0623,  ..., -0.1094, -0.0188,  0.0069],\n",
            "        [ 0.0124, -0.0463, -0.0548,  ..., -0.0382,  0.0168,  0.0227],\n",
            "        [ 0.0397, -0.0006, -0.0040,  ..., -0.1481, -0.1273, -0.0732],\n",
            "        ...,\n",
            "        [ 0.0897, -0.0513,  0.0939,  ..., -0.0417, -0.0619, -0.0659],\n",
            "        [-0.1129,  0.0906, -0.1193,  ...,  0.0932, -0.0090,  0.0882],\n",
            "        [ 0.2943, -0.1051, -0.0038,  ..., -0.0401, -0.0496,  0.0075]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 063]: 100% 1/1 [00:00<00:00,  9.46it/s]\u001b[0m\n",
            "[Epoch 064]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1368,  0.0745, -0.0695,  ...,  0.0161,  0.0231, -0.0096],\n",
            "        [ 0.0605, -0.0424, -0.2141,  ...,  0.0522,  0.1050,  0.1414],\n",
            "        [-0.0029,  0.0013,  0.0005,  ..., -0.0113,  0.0026,  0.0048],\n",
            "        ...,\n",
            "        [ 0.1271, -0.0655, -0.0793,  ...,  0.0509,  0.1148, -0.0430],\n",
            "        [ 0.0095, -0.0218,  0.0615,  ..., -0.1132, -0.0322, -0.0605],\n",
            "        [ 0.0731, -0.0328,  0.0562,  ...,  0.0484,  0.0641, -0.0298]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 064]: 100% 1/1 [00:00<00:00,  7.38it/s]\u001b[0m\n",
            "[Epoch 065]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0532, -0.0438,  0.0119,  ...,  0.0261, -0.0086, -0.0461],\n",
            "        [-0.0848, -0.0874, -0.1471,  ...,  0.1307,  0.0076, -0.0796],\n",
            "        [ 0.0774, -0.0456,  0.0723,  ..., -0.0824,  0.0385,  0.0419],\n",
            "        ...,\n",
            "        [ 0.0489, -0.1185,  0.0272,  ..., -0.1125, -0.0112,  0.1182],\n",
            "        [ 0.0834, -0.0518,  0.0452,  ..., -0.0205,  0.0808,  0.0134],\n",
            "        [-0.0193, -0.0004,  0.0067,  ..., -0.0649,  0.0002,  0.0100]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 065]: 100% 1/1 [00:00<00:00,  8.93it/s]\u001b[0m\n",
            "[Epoch 066]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-8.6675e-02, -3.1381e-02,  2.3236e-03,  ..., -3.6995e-02,\n",
            "         -4.6815e-02,  7.8776e-02],\n",
            "        [ 2.4143e-02, -2.8578e-02, -1.2943e-02,  ...,  8.0127e-02,\n",
            "         -2.2685e-02,  4.9173e-02],\n",
            "        [-4.4839e-02,  1.3952e-02,  4.9397e-02,  ...,  7.3988e-02,\n",
            "          2.7940e-02,  2.4199e-02],\n",
            "        ...,\n",
            "        [ 8.0408e-03, -1.2818e-04,  3.0020e-02,  ..., -7.7910e-02,\n",
            "          3.7494e-03,  8.5672e-02],\n",
            "        [-5.2515e-02, -3.7774e-02, -1.1025e-01,  ..., -1.2175e-01,\n",
            "         -3.1582e-01,  1.2852e-01],\n",
            "        [ 7.6011e-02, -1.1279e-01,  1.1586e-01,  ..., -1.1129e-01,\n",
            "          3.3165e-02, -1.3438e-01]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 066]: 100% 1/1 [00:00<00:00,  9.27it/s]\u001b[0m\n",
            "[Epoch 067]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0336,  0.0343, -0.0145,  ..., -0.0887,  0.0375,  0.0005],\n",
            "        [ 0.1702, -0.0465,  0.1163,  ...,  0.1061,  0.0704, -0.0787],\n",
            "        [-0.1160,  0.0865, -0.0397,  ...,  0.0305, -0.0450, -0.0158],\n",
            "        ...,\n",
            "        [ 0.0721, -0.0663,  0.0052,  ..., -0.1064, -0.1483, -0.0460],\n",
            "        [-0.0271,  0.0574, -0.0152,  ..., -0.1029,  0.0390,  0.0697],\n",
            "        [ 0.1714, -0.0328,  0.0463,  ...,  0.0212, -0.0153,  0.1495]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 067]: 100% 1/1 [00:00<00:00,  7.49it/s]\u001b[0m\n",
            "[Epoch 068]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0031,  0.0013,  0.0005,  ..., -0.0120,  0.0027,  0.0051],\n",
            "        [-0.0189, -0.0848, -0.0210,  ..., -0.0544,  0.0260,  0.0647],\n",
            "        [-0.0136, -0.0128,  0.0808,  ..., -0.0990, -0.0347,  0.0502],\n",
            "        ...,\n",
            "        [ 0.0588, -0.0384, -0.0853,  ..., -0.0408,  0.0609, -0.0261],\n",
            "        [-0.0856,  0.0466,  0.0144,  ...,  0.0227, -0.0067,  0.0366],\n",
            "        [ 0.0910,  0.0356,  0.0794,  ..., -0.0503, -0.0702, -0.0145]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 068]: 100% 1/1 [00:00<00:00,  8.03it/s]\u001b[0m\n",
            "[Epoch 069]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0849, -0.0873, -0.1471,  ...,  0.1299,  0.0078, -0.0793],\n",
            "        [ 0.1203, -0.0601, -0.0370,  ..., -0.0639,  0.1069,  0.0146],\n",
            "        [ 0.2394, -0.0239,  0.1423,  ...,  0.0451, -0.0951,  0.1032],\n",
            "        ...,\n",
            "        [ 0.0125, -0.1325,  0.0601,  ..., -0.0915,  0.0329,  0.0666],\n",
            "        [ 0.0203, -0.0497, -0.0687,  ..., -0.0113, -0.0612, -0.1145],\n",
            "        [-0.0324,  0.0021, -0.0896,  ..., -0.2135,  0.1346, -0.0316]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 069]: 100% 1/1 [00:00<00:00,  7.01it/s]\u001b[0m\n",
            "[Epoch 070]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0119,  0.0178,  0.1165,  ..., -0.0939, -0.0426, -0.0419],\n",
            "        [-0.1175, -0.0430, -0.1036,  ..., -0.0843, -0.0025,  0.0603],\n",
            "        [-0.0448, -0.0138, -0.0560,  ..., -0.1594, -0.0340, -0.0419],\n",
            "        ...,\n",
            "        [-0.1095, -0.0132,  0.0540,  ...,  0.0490,  0.0040,  0.0291],\n",
            "        [-0.1064,  0.0622, -0.0473,  ...,  0.1239,  0.0535, -0.0030],\n",
            "        [-0.0539, -0.0373, -0.0668,  ..., -0.0168,  0.0823,  0.0839]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 070]: 100% 1/1 [00:00<00:00,  9.08it/s]\u001b[0m\n",
            "[Epoch 071]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0875,  0.0501,  0.2069,  ...,  0.0703, -0.0066, -0.0856],\n",
            "        [-0.0032,  0.0014,  0.0005,  ..., -0.0126,  0.0028,  0.0053],\n",
            "        [ 0.0230, -0.0213, -0.0936,  ..., -0.2560,  0.1464, -0.0494],\n",
            "        ...,\n",
            "        [-0.0845,  0.1358, -0.0378,  ...,  0.0070, -0.0509,  0.0568],\n",
            "        [ 0.0163,  0.0899,  0.0821,  ..., -0.0423,  0.0420,  0.1577],\n",
            "        [-0.0032,  0.0014,  0.0005,  ..., -0.0126,  0.0028,  0.0053]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 071]: 100% 1/1 [00:00<00:00,  8.24it/s]\u001b[0m\n",
            "[Epoch 072]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0601, -0.1153,  0.0463,  ..., -0.0451, -0.1234,  0.0587],\n",
            "        [ 0.0365,  0.0663,  0.0475,  ..., -0.0276, -0.0124,  0.0306],\n",
            "        [ 0.0230, -0.0552, -0.0196,  ..., -0.0564,  0.1469,  0.0444],\n",
            "        ...,\n",
            "        [ 0.0659,  0.0101,  0.0973,  ...,  0.0124, -0.0773, -0.0400],\n",
            "        [-0.1165, -0.0117,  0.1365,  ..., -0.1348, -0.1186,  0.0444],\n",
            "        [ 0.0375,  0.0399, -0.0327,  ..., -0.0400,  0.0560,  0.0635]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 072]: 100% 1/1 [00:00<00:00,  8.26it/s]\u001b[0m\n",
            "[Epoch 073]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0459, -0.0303, -0.0468,  ...,  0.0147,  0.1487, -0.0972],\n",
            "        [ 0.0415, -0.0511,  0.1203,  ...,  0.0160,  0.1134,  0.0096],\n",
            "        [-0.0584,  0.0067,  0.0667,  ..., -0.0076,  0.0125, -0.0742],\n",
            "        ...,\n",
            "        [-0.0634,  0.0461, -0.0143,  ..., -0.0189, -0.0791, -0.0258],\n",
            "        [-0.0851, -0.0872, -0.1471,  ...,  0.1292,  0.0079, -0.0788],\n",
            "        [-0.0204,  0.0371, -0.1562,  ...,  0.1166,  0.0545, -0.0013]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 073]: 100% 1/1 [00:00<00:00,  8.32it/s]\u001b[0m\n",
            "[Epoch 074]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0438, -0.0200,  0.0029,  ...,  0.0844,  0.0222,  0.1089],\n",
            "        [ 0.0419,  0.1159,  0.1088,  ..., -0.0462, -0.0186,  0.0892],\n",
            "        [ 0.0026, -0.0413,  0.0870,  ...,  0.0239,  0.0126,  0.0356],\n",
            "        ...,\n",
            "        [ 0.0563, -0.0510,  0.0833,  ..., -0.1102,  0.0562, -0.0270],\n",
            "        [ 0.1363,  0.0446,  0.1096,  ..., -0.0921,  0.0317,  0.0764],\n",
            "        [ 0.0414, -0.1080, -0.1464,  ...,  0.0674,  0.1193, -0.0254]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 074]: 100% 1/1 [00:00<00:00,  7.59it/s]\u001b[0m\n",
            "[Epoch 075]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.2392, -0.0239,  0.1423,  ...,  0.0441, -0.0949,  0.1040],\n",
            "        [ 0.0193,  0.1169,  0.0703,  ..., -0.1174,  0.0304,  0.1521],\n",
            "        [ 0.1250,  0.0581,  0.0731,  ...,  0.0182,  0.0094, -0.0421],\n",
            "        ...,\n",
            "        [ 0.1329,  0.0992,  0.0954,  ..., -0.0625,  0.2167, -0.0230],\n",
            "        [-0.0726,  0.0565,  0.0277,  ..., -0.0549,  0.0294, -0.1018],\n",
            "        [ 0.0744,  0.0408,  0.1049,  ..., -0.0801, -0.0235,  0.0617]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 075]: 100% 1/1 [00:00<00:00,  9.25it/s]\u001b[0m\n",
            "[Epoch 076]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1367,  0.0599,  0.0417,  ..., -0.0844, -0.1053, -0.0890],\n",
            "        [-0.0796, -0.0356,  0.1128,  ..., -0.1183, -0.0318, -0.0680],\n",
            "        [ 0.0030,  0.1495,  0.0395,  ..., -0.1261, -0.0168,  0.1322],\n",
            "        ...,\n",
            "        [ 0.0930, -0.0362,  0.0590,  ..., -0.1446, -0.1604, -0.0165],\n",
            "        [ 0.0715, -0.0158,  0.0352,  ..., -0.1330,  0.0715,  0.1229],\n",
            "        [-0.0603,  0.0056, -0.1383,  ..., -0.1348,  0.0656,  0.0459]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 076]: 100% 1/1 [00:00<00:00,  8.31it/s]\u001b[0m\n",
            "[Epoch 077]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0756, -0.0432,  0.0766,  ...,  0.0057,  0.1322, -0.0444],\n",
            "        [ 0.1253,  0.1655,  0.1371,  ...,  0.0892, -0.1098, -0.0899],\n",
            "        [-0.0106,  0.0146, -0.0474,  ..., -0.1755, -0.0527,  0.0234],\n",
            "        ...,\n",
            "        [-0.0311, -0.0321,  0.1159,  ..., -0.0054,  0.1614, -0.0282],\n",
            "        [-0.0235, -0.0298,  0.0536,  ..., -0.0211, -0.0745, -0.0914],\n",
            "        [-0.0326, -0.0048,  0.0128,  ..., -0.0310, -0.0289, -0.0458]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 077]: 100% 1/1 [00:00<00:00,  7.04it/s]\u001b[0m\n",
            "[Epoch 078]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0158,  0.1694,  0.0037,  ...,  0.0522, -0.0699,  0.2227],\n",
            "        [ 0.0025, -0.0567,  0.1315,  ...,  0.0348,  0.0260, -0.0165],\n",
            "        [ 0.0030, -0.1104, -0.0280,  ..., -0.0463,  0.0944,  0.0041],\n",
            "        ...,\n",
            "        [ 0.0396,  0.1036, -0.0123,  ..., -0.2139,  0.0492, -0.0945],\n",
            "        [-0.0812,  0.1610,  0.0008,  ...,  0.0660, -0.0411, -0.0800],\n",
            "        [-0.0417,  0.0601, -0.0202,  ..., -0.1567,  0.0410,  0.0034]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 078]: 100% 1/1 [00:00<00:00,  6.85it/s]\u001b[0m\n",
            "[Epoch 079]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0238,  0.0254,  0.0610,  ...,  0.0326,  0.0790,  0.0434],\n",
            "        [-0.0411,  0.1216, -0.0657,  ..., -0.0609, -0.0332, -0.0015],\n",
            "        [ 0.0342, -0.0033,  0.0245,  ..., -0.0267,  0.1030, -0.0238],\n",
            "        ...,\n",
            "        [ 0.0785,  0.0007,  0.0835,  ...,  0.0091,  0.0987,  0.1357],\n",
            "        [-0.1423, -0.0488, -0.0803,  ..., -0.0200,  0.0825,  0.1306],\n",
            "        [-0.0023,  0.1030,  0.1848,  ..., -0.0239,  0.0746, -0.0351]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 079]: 100% 1/1 [00:00<00:00,  7.55it/s]\u001b[0m\n",
            "[Epoch 080]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0360,  0.0924,  0.0629,  ...,  0.0253, -0.0259, -0.0703],\n",
            "        [ 0.0022, -0.0411,  0.0870,  ...,  0.0227,  0.0129,  0.0361],\n",
            "        [-0.0595, -0.0087,  0.1598,  ...,  0.0293,  0.1095, -0.0337],\n",
            "        ...,\n",
            "        [-0.1325,  0.0535,  0.1732,  ..., -0.1687,  0.0236,  0.2266],\n",
            "        [ 0.0410, -0.0179, -0.0008,  ..., -0.1878, -0.0996, -0.0996],\n",
            "        [ 0.1380, -0.0340, -0.0396,  ..., -0.0338, -0.0714,  0.0069]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 080]: 100% 1/1 [00:00<00:00,  8.74it/s]\u001b[0m\n",
            "[Epoch 081]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0572,  0.0236,  0.0246,  ..., -0.0074,  0.0683,  0.0550],\n",
            "        [-0.0406,  0.1703,  0.1954,  ..., -0.0619, -0.0381,  0.1602],\n",
            "        [-0.0038,  0.0016,  0.0006,  ..., -0.0144,  0.0032,  0.0061],\n",
            "        ...,\n",
            "        [ 0.0105, -0.0313,  0.0199,  ...,  0.0358,  0.0430,  0.0976],\n",
            "        [ 0.0353, -0.0156,  0.2291,  ...,  0.0515, -0.0258,  0.1575],\n",
            "        [ 0.0742,  0.1444,  0.1430,  ...,  0.0725, -0.1002, -0.0760]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 081]: 100% 1/1 [00:00<00:00,  8.90it/s]\u001b[0m\n",
            "[Epoch 082]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0595, -0.1121, -0.0081,  ..., -0.0365,  0.0437, -0.0043],\n",
            "        [ 0.0449, -0.0639,  0.2047,  ...,  0.0868,  0.0023, -0.1638],\n",
            "        [-0.1148,  0.0835,  0.0022,  ..., -0.0067,  0.1553,  0.0838],\n",
            "        ...,\n",
            "        [-0.0027, -0.0721, -0.0115,  ...,  0.0597, -0.0641, -0.0218],\n",
            "        [-0.1676, -0.0583,  0.0732,  ...,  0.0533,  0.0764, -0.1501],\n",
            "        [-0.0637,  0.0890, -0.0658,  ..., -0.1894, -0.0821, -0.0527]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 082]: 100% 1/1 [00:00<00:00,  7.51it/s]\u001b[0m\n",
            "[Epoch 083]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0156,  0.0902,  0.0823,  ..., -0.0447,  0.0425,  0.1586],\n",
            "        [ 0.0180,  0.0895,  0.0502,  ..., -0.0741, -0.0180,  0.1109],\n",
            "        [ 0.0097,  0.0362,  0.2180,  ..., -0.0116, -0.0786, -0.0598],\n",
            "        ...,\n",
            "        [-0.1024, -0.1019, -0.0554,  ..., -0.0650,  0.0068,  0.0410],\n",
            "        [-0.1373,  0.1091, -0.0209,  ..., -0.0072, -0.0827,  0.0058],\n",
            "        [-0.0890, -0.0925,  0.1529,  ..., -0.0891, -0.0457,  0.1391]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 083]: 100% 1/1 [00:00<00:00,  9.35it/s]\u001b[0m\n",
            "[Epoch 084]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0751, -0.1123,  0.1161,  ..., -0.1146,  0.0342, -0.1328],\n",
            "        [-0.0155,  0.0222, -0.0152,  ..., -0.0074, -0.0123,  0.0174],\n",
            "        [-0.0745, -0.0687,  0.1305,  ..., -0.0937, -0.0419,  0.0838],\n",
            "        ...,\n",
            "        [ 0.0218,  0.0570, -0.0014,  ..., -0.1183,  0.0795,  0.0844],\n",
            "        [ 0.0654,  0.0104,  0.0974,  ...,  0.0102, -0.0768, -0.0389],\n",
            "        [-0.1677, -0.0582,  0.0732,  ...,  0.0529,  0.0765, -0.1500]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 084]: 100% 1/1 [00:00<00:00,  7.63it/s]\u001b[0m\n",
            "[Epoch 085]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-7.6605e-03,  5.6951e-02, -3.2988e-03,  ..., -1.1004e-01,\n",
            "          1.2372e-01,  1.5222e-01],\n",
            "        [-4.5674e-02, -5.8568e-02, -3.1160e-03,  ..., -7.8740e-02,\n",
            "         -5.9999e-02, -1.6320e-02],\n",
            "        [ 5.0083e-03,  9.4429e-02,  7.2039e-02,  ..., -1.5896e-01,\n",
            "          7.7110e-03, -7.0149e-02],\n",
            "        ...,\n",
            "        [ 7.1361e-02, -8.4883e-02, -4.9861e-02,  ..., -1.4632e-02,\n",
            "          9.7925e-02,  2.3930e-05],\n",
            "        [ 4.8762e-04, -3.7149e-02, -8.6278e-02,  ..., -6.6050e-02,\n",
            "         -5.1169e-02, -5.3603e-03],\n",
            "        [ 3.9430e-03,  2.5066e-02,  7.4614e-02,  ...,  5.2685e-03,\n",
            "          1.1823e-01,  1.0034e-01]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 085]: 100% 1/1 [00:00<00:00,  6.75it/s]\u001b[0m\n",
            "[Epoch 086]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0923, -0.1760,  0.1016,  ..., -0.1438, -0.1136, -0.0691],\n",
            "        [ 0.1124,  0.0425,  0.0353,  ..., -0.0557,  0.0543,  0.0547],\n",
            "        [-0.0040,  0.0017,  0.0007,  ..., -0.0154,  0.0035,  0.0066],\n",
            "        ...,\n",
            "        [-0.0260,  0.0748,  0.0214,  ...,  0.0201,  0.0048, -0.0920],\n",
            "        [-0.0250, -0.0173,  0.1978,  ..., -0.0989, -0.1174,  0.0423],\n",
            "        [ 0.1054,  0.0158,  0.0887,  ..., -0.1047,  0.0592,  0.0735]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 086]: 100% 1/1 [00:00<00:00,  8.62it/s]\u001b[0m\n",
            "[Epoch 087]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-1.4603e-01,  1.5230e-02, -8.5161e-02,  ..., -9.1143e-04,\n",
            "         -1.7064e-02,  3.5782e-02],\n",
            "        [-7.6245e-02, -3.3682e-02, -2.2196e-02,  ..., -5.8001e-02,\n",
            "         -1.2372e-02, -1.1673e-01],\n",
            "        [ 7.3825e-02,  7.8072e-03, -3.2105e-02,  ..., -1.4976e-01,\n",
            "         -4.6906e-02, -5.3848e-02],\n",
            "        ...,\n",
            "        [ 1.0493e-04, -1.1812e-03,  1.6088e-01,  ...,  9.9356e-03,\n",
            "          5.4409e-02, -1.1231e-01],\n",
            "        [-9.7334e-04, -1.2717e-02,  4.1351e-03,  ..., -3.2414e-02,\n",
            "          3.7719e-02, -1.2985e-02],\n",
            "        [ 8.9706e-02,  5.4099e-02, -5.5162e-02,  ..., -1.5469e-01,\n",
            "          3.4464e-02, -1.8522e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 087]: 100% 1/1 [00:00<00:00,  7.49it/s]\u001b[0m\n",
            "[Epoch 088]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1893,  0.1162, -0.0361,  ...,  0.0511,  0.0063,  0.0012],\n",
            "        [-0.0226, -0.0612, -0.0433,  ..., -0.0829,  0.0914, -0.0091],\n",
            "        [-0.0140,  0.2027,  0.0186,  ...,  0.1068, -0.0587, -0.0038],\n",
            "        ...,\n",
            "        [ 0.1321,  0.0994,  0.0955,  ..., -0.0650,  0.2172, -0.0220],\n",
            "        [ 0.1333,  0.0142,  0.0227,  ..., -0.0370,  0.0672, -0.0049],\n",
            "        [-0.0438,  0.0319,  0.0488,  ...,  0.0080,  0.1600, -0.0886]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 088]: 100% 1/1 [00:00<00:00,  7.91it/s]\u001b[0m\n",
            "[Epoch 089]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0041,  0.0018,  0.0007,  ..., -0.0159,  0.0035,  0.0067],\n",
            "        [-0.1532,  0.0497,  0.1312,  ..., -0.0140, -0.1669, -0.0867],\n",
            "        [ 0.0770,  0.0445, -0.0664,  ..., -0.0097, -0.0633, -0.0298],\n",
            "        ...,\n",
            "        [ 0.1964, -0.0333, -0.0246,  ..., -0.1120,  0.0511,  0.0622],\n",
            "        [-0.0214,  0.0389, -0.0691,  ..., -0.0141,  0.0805, -0.0114],\n",
            "        [-0.0567, -0.0326, -0.0062,  ..., -0.0481,  0.0169, -0.0323]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 089]: 100% 1/1 [00:00<00:00,  7.65it/s]\u001b[0m\n",
            "[Epoch 090]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0042,  0.0019,  0.0007,  ..., -0.0161,  0.0036,  0.0068],\n",
            "        [ 0.1081, -0.0325,  0.0567,  ..., -0.0737, -0.0861,  0.0207],\n",
            "        [-0.0927,  0.0173,  0.0842,  ..., -0.0995,  0.0586, -0.0976],\n",
            "        ...,\n",
            "        [ 0.0477,  0.1060,  0.1381,  ..., -0.0819, -0.0317,  0.0597],\n",
            "        [-0.0544, -0.0433,  0.0122,  ...,  0.0214, -0.0076, -0.0437],\n",
            "        [ 0.0658,  0.0052,  0.1188,  ..., -0.0910,  0.1891,  0.0892]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 090]: 100% 1/1 [00:00<00:00,  8.51it/s]\u001b[0m\n",
            "[Epoch 091]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0574,  0.0027, -0.0109,  ...,  0.0384, -0.0217, -0.0332],\n",
            "        [-0.0306,  0.0503, -0.0185,  ..., -0.0959,  0.0008, -0.0259],\n",
            "        [-0.0609,  0.0059, -0.1381,  ..., -0.1374,  0.0663,  0.0470],\n",
            "        ...,\n",
            "        [ 0.0175, -0.1003,  0.0457,  ...,  0.0127,  0.0360,  0.0803],\n",
            "        [ 0.0761, -0.0848, -0.0145,  ..., -0.1917, -0.1213, -0.0394],\n",
            "        [-0.2179,  0.1405,  0.0514,  ...,  0.1079, -0.1342, -0.0027]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 091]: 100% 1/1 [00:00<00:00,  7.45it/s]\u001b[0m\n",
            "[Epoch 092]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0923,  0.0952,  0.0088,  ...,  0.0551,  0.0707,  0.0214],\n",
            "        [-0.0292,  0.0379, -0.0133,  ...,  0.0448,  0.0214, -0.0076],\n",
            "        [-0.0043,  0.0019,  0.0007,  ..., -0.0164,  0.0037,  0.0070],\n",
            "        ...,\n",
            "        [-0.0665, -0.0208, -0.0150,  ..., -0.1511, -0.1972,  0.0845],\n",
            "        [-0.0522,  0.0093,  0.1952,  ..., -0.1688, -0.0511, -0.0557],\n",
            "        [-0.0043,  0.0019,  0.0007,  ..., -0.0164,  0.0037,  0.0070]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 092]: 100% 1/1 [00:00<00:00,  8.01it/s]\u001b[0m\n",
            "[Epoch 093]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0043,  0.0019,  0.0007,  ..., -0.0166,  0.0037,  0.0071],\n",
            "        [-0.0297,  0.0511, -0.1384,  ..., -0.1307,  0.0781,  0.0387],\n",
            "        [-0.0043,  0.0019,  0.0007,  ..., -0.0166,  0.0037,  0.0071],\n",
            "        ...,\n",
            "        [ 0.0469,  0.0228, -0.0306,  ...,  0.0017,  0.0407, -0.0636],\n",
            "        [ 0.0173, -0.0312,  0.0351,  ...,  0.0086,  0.1017,  0.0837],\n",
            "        [-0.1445,  0.1136, -0.0176,  ..., -0.2027,  0.1511, -0.0110]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 093]: 100% 1/1 [00:00<00:00,  8.04it/s]\u001b[0m\n",
            "[Epoch 094]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0122,  0.0959,  0.0204,  ...,  0.1393, -0.0451, -0.1143],\n",
            "        [-0.0019, -0.0014, -0.1043,  ..., -0.0453,  0.0573, -0.0099],\n",
            "        [-0.0195, -0.0386,  0.0200,  ..., -0.0554,  0.0571, -0.0141],\n",
            "        ...,\n",
            "        [ 0.0741,  0.0514, -0.0630,  ..., -0.1348, -0.1605, -0.0802],\n",
            "        [-0.0241,  0.0317,  0.0434,  ...,  0.0946,  0.0205,  0.0659],\n",
            "        [-0.0567, -0.0965,  0.1831,  ..., -0.0275, -0.0269, -0.0138]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 094]: 100% 1/1 [00:00<00:00,  7.82it/s]\u001b[0m\n",
            "[Epoch 095]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0030,  0.0714,  0.1309,  ..., -0.0163,  0.0435,  0.0970],\n",
            "        [-0.0396,  0.0470,  0.0509,  ..., -0.1270, -0.0499,  0.0771],\n",
            "        [-0.0538,  0.0555, -0.0612,  ..., -0.0379, -0.0653,  0.0194],\n",
            "        ...,\n",
            "        [-0.0044,  0.0020,  0.0007,  ..., -0.0170,  0.0038,  0.0073],\n",
            "        [-0.1500,  0.0725, -0.0075,  ..., -0.0616, -0.0685, -0.0225],\n",
            "        [ 0.0156, -0.0140, -0.0194,  ..., -0.0426, -0.0226,  0.0662]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 095]: 100% 1/1 [00:00<00:00,  9.14it/s]\u001b[0m\n",
            "[Epoch 096]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-2.0716e-02,  2.3497e-04,  1.7430e-02,  ...,  1.9209e-02,\n",
            "          1.2661e-01, -8.9863e-02],\n",
            "        [-3.1374e-02,  2.4961e-01,  1.4227e-01,  ..., -2.5431e-02,\n",
            "         -1.3527e-02,  1.5344e-01],\n",
            "        [-4.4382e-03,  1.9819e-03,  7.4805e-04,  ..., -1.7231e-02,\n",
            "          3.8601e-03,  7.3299e-03],\n",
            "        ...,\n",
            "        [-4.4382e-03,  1.9819e-03,  7.4805e-04,  ..., -1.7231e-02,\n",
            "          3.8601e-03,  7.3299e-03],\n",
            "        [ 3.1290e-02, -1.5851e-02,  7.4118e-03,  ..., -7.4272e-02,\n",
            "         -3.4611e-02, -3.8165e-02],\n",
            "        [ 8.8214e-02, -1.2334e-01,  2.9178e-02,  ..., -1.1308e-01,\n",
            "         -4.0164e-03,  1.1527e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 096]: 100% 1/1 [00:00<00:00,  7.44it/s]\u001b[0m\n",
            "[Epoch 097]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0809,  0.0662, -0.0049,  ..., -0.0871, -0.0025,  0.1054],\n",
            "        [-0.0045,  0.0020,  0.0007,  ..., -0.0174,  0.0039,  0.0074],\n",
            "        [-0.0058, -0.0010,  0.1734,  ..., -0.1312,  0.0431,  0.0119],\n",
            "        ...,\n",
            "        [-0.0297, -0.0422, -0.0845,  ..., -0.2316,  0.1290, -0.0557],\n",
            "        [-0.1388, -0.0091, -0.0686,  ..., -0.0708,  0.0668,  0.0112],\n",
            "        [ 0.1199,  0.0019, -0.0273,  ...,  0.0029,  0.1067, -0.0378]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 097]: 100% 1/1 [00:00<00:00,  9.30it/s]\u001b[0m\n",
            "[Epoch 098]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1575, -0.0358,  0.0215,  ..., -0.0958,  0.0509, -0.0351],\n",
            "        [ 0.1008, -0.1775, -0.0260,  ..., -0.0735,  0.0324,  0.0308],\n",
            "        [-0.1477, -0.0267, -0.0925,  ...,  0.0023,  0.0149,  0.0790],\n",
            "        ...,\n",
            "        [-0.1224,  0.0133,  0.0590,  ..., -0.1377,  0.0985,  0.0310],\n",
            "        [-0.0859,  0.1366, -0.0375,  ...,  0.0019, -0.0498,  0.0589],\n",
            "        [ 0.0035, -0.0212, -0.0164,  ..., -0.1222, -0.2171,  0.0065]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 098]: 100% 1/1 [00:00<00:00,  8.65it/s]\u001b[0m\n",
            "[Epoch 099]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0392,  0.0480,  0.0430,  ..., -0.0510,  0.0341,  0.0399],\n",
            "        [ 0.0249,  0.0351,  0.1013,  ...,  0.0148, -0.0453, -0.0135],\n",
            "        [-0.0743,  0.0364,  0.0310,  ..., -0.0609, -0.0704, -0.0410],\n",
            "        ...,\n",
            "        [ 0.0142, -0.0397,  0.0383,  ...,  0.0346,  0.0769,  0.0499],\n",
            "        [ 0.0648,  0.0106,  0.0974,  ...,  0.0074, -0.0761, -0.0376],\n",
            "        [ 0.0659,  0.0728,  0.0389,  ...,  0.0005,  0.0498,  0.0028]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 099]: 100% 1/1 [00:00<00:00,  7.76it/s]\u001b[0m\n",
            "[Epoch 100]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.2470, -0.1263,  0.1215,  ...,  0.0177, -0.0169,  0.0642],\n",
            "        [-0.0236,  0.0547, -0.0062,  ..., -0.1246, -0.2678,  0.0338],\n",
            "        [-0.0277,  0.0144,  0.0205,  ..., -0.1003,  0.0147, -0.0330],\n",
            "        ...,\n",
            "        [-0.0947, -0.0029, -0.0356,  ..., -0.0742, -0.0456,  0.0648],\n",
            "        [-0.0182, -0.0547, -0.0055,  ...,  0.0093,  0.1532,  0.0994],\n",
            "        [ 0.2014,  0.0095, -0.0528,  ..., -0.0347, -0.0988,  0.0435]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 100]: 100% 1/1 [00:00<00:00,  8.36it/s]\u001b[0m\n",
            "\u001b[0m14 Apr 00:14 INFO - Finish 1 train-validation experiment(s)...\u001b[0m\n",
            "\u001b[0m14 Apr 00:14 INFO - Start Calculating Metrics...\u001b[0m\n",
            "\u001b[0m14 Apr 00:14 INFO - ==========================\u001b[0m\n",
            "\u001b[0m14 Apr 00:14 INFO - Generate recommend list...\u001b[0m\n",
            "\u001b[0m14 Apr 00:14 INFO - ==========================\u001b[0m\n",
            "\u001b[0m\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0795,  0.0448,  0.0302,  ...,  0.1339, -0.0092, -0.0174],\n",
            "        [ 0.0388,  0.0655,  0.1494,  ...,  0.0012,  0.0012, -0.0567],\n",
            "        [ 0.0159,  0.0274, -0.0164,  ...,  0.0157,  0.0040, -0.0120],\n",
            "        ...,\n",
            "        [-0.0047,  0.0021,  0.0008,  ..., -0.0182,  0.0040,  0.0077],\n",
            "        [-0.1044,  0.0572, -0.0187,  ..., -0.0540, -0.0242,  0.0384],\n",
            "        [-0.0216, -0.0930, -0.0016,  ..., -0.0305, -0.0491,  0.0180]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "\u001b[0mPREDS\u001b[0m \u001b[0m[[ 30.  30. 316. ... 152.   5. 154.]\n",
            " [ 29.  29.  29. ... 113. 268. 268.]\n",
            " [338. 338. 338. ... 337. 337.  85.]\n",
            " ...\n",
            " [291. 184. 203. ... 336. 336. 214.]\n",
            " [116. 116. 116. ... 142. 257. 257.]\n",
            " [ 29.  29.  29. ...  79.  79. 386.]]\u001b[0m\n",
            "14 Apr 00:14 INFO - Finish 39 trial...\u001b[0m\n",
            "\u001b[0m\u001b[32m[I 2023-04-14 00:14:27,331]\u001b[0m Trial 38 finished with value: 0.04015966250127232 and parameters: {}. Best is trial 10 with value: 0.1209022497797705.\u001b[0m\n",
            "\u001b[0mLine1\u001b[0m\n",
            "\u001b[0mApplying weights\u001b[0m\n",
            "\u001b[0mAfter applying wieghts\u001b[0m\n",
            "\u001b[0mLine2\u001b[0m\n",
            "\u001b[0mModel fitting\u001b[0m\n",
            "[Epoch 001]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0641, -0.0606, -0.0640,  ...,  0.1553,  0.0405,  0.1455],\n",
            "        [-0.1308, -0.0039,  0.1014,  ...,  0.0073,  0.0020,  0.1140],\n",
            "        [-0.0150, -0.0606, -0.0686,  ..., -0.0196,  0.0826, -0.0386],\n",
            "        ...,\n",
            "        [ 0.0947, -0.0004, -0.0481,  ...,  0.0862, -0.0812, -0.0486],\n",
            "        [-0.0683, -0.0078, -0.0529,  ...,  0.0228, -0.0721, -0.0128],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 001]: 100% 1/1 [00:00<00:00,  5.63it/s]\u001b[0m\n",
            "[Epoch 002]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0173, -0.0725,  0.0330,  ...,  0.0045, -0.0199,  0.0787],\n",
            "        [ 0.0896, -0.0310,  0.0038,  ...,  0.1711, -0.0406,  0.0376],\n",
            "        [ 0.0213, -0.0885,  0.1020,  ...,  0.0497, -0.0978, -0.0649],\n",
            "        ...,\n",
            "        [-0.0655, -0.2259, -0.0403,  ...,  0.0009, -0.0242, -0.0083],\n",
            "        [-0.0110, -0.0311,  0.0965,  ...,  0.0166,  0.0923,  0.0087],\n",
            "        [-0.0278, -0.0289, -0.0324,  ...,  0.0065,  0.0443, -0.0389]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 002]: 100% 1/1 [00:00<00:00,  4.79it/s]\u001b[0m\n",
            "[Epoch 003]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0835, -0.0844, -0.0133,  ...,  0.0591,  0.0976,  0.0894],\n",
            "        [-0.0293,  0.0234, -0.1945,  ..., -0.0810,  0.0348, -0.0432],\n",
            "        [-0.0245, -0.0592,  0.0046,  ..., -0.0217, -0.0235,  0.0449],\n",
            "        ...,\n",
            "        [ 0.0725, -0.0315, -0.1257,  ..., -0.0223,  0.0567, -0.0454],\n",
            "        [ 0.0436,  0.0434,  0.0656,  ..., -0.0098,  0.1512, -0.0590],\n",
            "        [ 0.0345,  0.0093,  0.0292,  ..., -0.0162, -0.0884, -0.0341]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 003]: 100% 1/1 [00:00<00:00,  6.81it/s]\u001b[0m\n",
            "[Epoch 004]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1056, -0.1411,  0.0010,  ...,  0.0355, -0.1642,  0.1730],\n",
            "        [ 0.1383,  0.0653, -0.0023,  ...,  0.0424,  0.0653,  0.0988],\n",
            "        [ 0.0041, -0.0966, -0.1267,  ...,  0.0492,  0.0437, -0.0390],\n",
            "        ...,\n",
            "        [ 0.1005, -0.0498, -0.0644,  ...,  0.0523, -0.0552,  0.0213],\n",
            "        [-0.0602,  0.0969, -0.2675,  ...,  0.0041, -0.0142, -0.0012],\n",
            "        [-0.0144, -0.0736, -0.0157,  ...,  0.1104,  0.0577, -0.0335]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 004]: 100% 1/1 [00:00<00:00,  4.64it/s]\u001b[0m\n",
            "[Epoch 005]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0591, -0.0067,  0.1117,  ...,  0.0897,  0.0429, -0.1075],\n",
            "        [ 0.0719, -0.0587, -0.0349,  ..., -0.0726,  0.0151,  0.0378],\n",
            "        [ 0.0245, -0.0103,  0.0135,  ..., -0.0600, -0.0198,  0.0078],\n",
            "        ...,\n",
            "        [ 0.0173, -0.0226,  0.0074,  ...,  0.0076, -0.0206, -0.0040],\n",
            "        [ 0.1377, -0.0109, -0.0495,  ...,  0.0478,  0.0048, -0.0323],\n",
            "        [ 0.0141,  0.0299, -0.0613,  ..., -0.0430, -0.0954,  0.0706]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 005]: 100% 1/1 [00:00<00:00,  5.00it/s]\u001b[0m\n",
            "[Epoch 006]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0593,  0.0147, -0.0577,  ...,  0.0053,  0.0809, -0.1114],\n",
            "        [-0.0763,  0.0394,  0.0264,  ...,  0.0523,  0.0256,  0.0734],\n",
            "        [-0.0722, -0.0426,  0.0258,  ...,  0.1006, -0.1069, -0.0505],\n",
            "        ...,\n",
            "        [-0.0303,  0.0155, -0.0576,  ..., -0.0918, -0.0227,  0.0508],\n",
            "        [ 0.0379,  0.0400, -0.0120,  ..., -0.0155,  0.0814, -0.1820],\n",
            "        [-0.0177, -0.1696, -0.0203,  ...,  0.0080,  0.0840, -0.0815]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 006]: 100% 1/1 [00:00<00:00,  4.38it/s]\u001b[0m\n",
            "[Epoch 007]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 4.0986e-02,  5.3429e-02,  1.1825e-01,  ...,  5.8091e-02,\n",
            "          4.7586e-02, -5.0237e-02],\n",
            "        [ 5.7474e-03, -9.5703e-02,  8.6578e-02,  ...,  5.1839e-02,\n",
            "         -1.8807e-02,  8.2289e-02],\n",
            "        [ 7.9021e-02,  2.9219e-02,  4.4892e-02,  ...,  2.3941e-02,\n",
            "          1.4089e-01, -1.2161e-01],\n",
            "        ...,\n",
            "        [ 9.6153e-02, -1.6785e-01, -1.0250e-01,  ...,  4.3855e-02,\n",
            "         -3.6385e-02, -3.8133e-02],\n",
            "        [ 3.7068e-04,  1.4003e-04, -7.4589e-04,  ...,  3.4107e-04,\n",
            "         -7.7846e-05,  2.1296e-04],\n",
            "        [-1.2852e-02, -1.3251e-01, -2.0991e-02,  ...,  1.9061e-02,\n",
            "         -2.3654e-02, -4.4240e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 007]: 100% 1/1 [00:00<00:00,  5.14it/s]\u001b[0m\n",
            "[Epoch 008]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0670,  0.0349, -0.0003,  ...,  0.0604,  0.0483, -0.0920],\n",
            "        [ 0.0329, -0.0950,  0.0287,  ...,  0.0352, -0.0543,  0.0955],\n",
            "        [-0.0396,  0.0082, -0.0274,  ...,  0.0191, -0.0863,  0.0207],\n",
            "        ...,\n",
            "        [-0.0186,  0.0679, -0.0645,  ...,  0.0394, -0.0179,  0.0128],\n",
            "        [-0.0554, -0.0861, -0.0215,  ..., -0.1009,  0.1023, -0.0151],\n",
            "        [ 0.0025,  0.1013,  0.0314,  ..., -0.2176,  0.1368, -0.0259]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 008]: 100% 1/1 [00:00<00:00,  5.48it/s]\u001b[0m\n",
            "[Epoch 009]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 1.6115e-01,  5.3970e-02,  1.4140e-01,  ..., -1.2775e-01,\n",
            "         -3.7264e-02,  7.2173e-02],\n",
            "        [ 2.7783e-02, -4.4790e-02, -6.7808e-02,  ...,  1.8408e-02,\n",
            "          7.1520e-03, -1.7184e-02],\n",
            "        [-1.7537e-01,  8.3248e-03,  5.9790e-02,  ..., -1.4009e-01,\n",
            "         -3.4722e-02, -6.7775e-02],\n",
            "        ...,\n",
            "        [ 1.2864e-02,  1.1933e-01,  1.1124e-02,  ..., -2.4652e-01,\n",
            "          9.9424e-02, -1.3271e-02],\n",
            "        [ 5.3208e-04,  1.7614e-04, -9.7211e-04,  ...,  4.1298e-04,\n",
            "         -7.8618e-05,  3.1538e-04],\n",
            "        [ 8.7751e-02,  2.7726e-02,  5.8253e-02,  ...,  3.1611e-02,\n",
            "          1.9869e-01, -6.8822e-03]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 009]: 100% 1/1 [00:00<00:00,  5.43it/s]\u001b[0m\n",
            "[Epoch 010]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0700,  0.0406,  0.0097,  ..., -0.0906,  0.0467,  0.0581],\n",
            "        [-0.0874, -0.1828, -0.1183,  ...,  0.1502,  0.0010,  0.0250],\n",
            "        [ 0.0468, -0.0403,  0.0337,  ..., -0.0958,  0.0470,  0.0384],\n",
            "        ...,\n",
            "        [-0.2081,  0.1313,  0.0844,  ...,  0.0431,  0.1263, -0.0086],\n",
            "        [-0.1507, -0.0316, -0.0354,  ...,  0.1737, -0.0806, -0.0202],\n",
            "        [-0.0817, -0.0755, -0.0808,  ..., -0.0403,  0.0519,  0.0180]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 010]: 100% 1/1 [00:00<00:00,  4.99it/s]\u001b[0m\n",
            "[Epoch 011]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1431, -0.0973,  0.0473,  ...,  0.0018,  0.0022,  0.0454],\n",
            "        [ 0.0377,  0.1037,  0.0079,  ...,  0.1079, -0.0186,  0.0679],\n",
            "        [ 0.1358,  0.0845,  0.0146,  ...,  0.0062,  0.0686, -0.1371],\n",
            "        ...,\n",
            "        [-0.0466,  0.0246, -0.0762,  ..., -0.0414, -0.1082,  0.1573],\n",
            "        [ 0.1232, -0.0214, -0.0085,  ..., -0.0834,  0.0573,  0.0078],\n",
            "        [-0.1752,  0.0083,  0.0595,  ..., -0.1400, -0.0348, -0.0677]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 011]: 100% 1/1 [00:00<00:00,  5.34it/s]\u001b[0m\n",
            "[Epoch 012]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0301, -0.0557, -0.1368,  ...,  0.0448,  0.1255,  0.0124],\n",
            "        [-0.1649, -0.0030, -0.0115,  ..., -0.0084, -0.2660,  0.1844],\n",
            "        [ 0.1614,  0.0540,  0.1410,  ..., -0.1276, -0.0373,  0.0723],\n",
            "        ...,\n",
            "        [-0.1124, -0.0018,  0.0156,  ..., -0.0093,  0.1094, -0.0967],\n",
            "        [ 0.0086,  0.0350, -0.0524,  ..., -0.0169, -0.0175,  0.0441],\n",
            "        [-0.0299,  0.0156, -0.0583,  ..., -0.0915, -0.0228,  0.0511]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 012]: 100% 1/1 [00:00<00:00,  4.99it/s]\u001b[0m\n",
            "[Epoch 013]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0026,  0.0286,  0.0624,  ..., -0.0750, -0.0373, -0.0064],\n",
            "        [-0.0351, -0.0405, -0.0653,  ..., -0.1357,  0.1191, -0.0253],\n",
            "        [-0.0460,  0.0184, -0.0055,  ...,  0.0417,  0.0291, -0.0338],\n",
            "        ...,\n",
            "        [-0.0234,  0.0101, -0.0769,  ...,  0.0652,  0.0645, -0.0521],\n",
            "        [-0.0008, -0.0846,  0.0080,  ...,  0.0657, -0.0131, -0.0365],\n",
            "        [-0.0800, -0.1193, -0.0374,  ...,  0.0215, -0.0205, -0.0387]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 013]: 100% 1/1 [00:00<00:00,  4.91it/s]\u001b[0m\n",
            "[Epoch 014]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0883,  0.0282, -0.0449,  ...,  0.0249, -0.0032, -0.0719],\n",
            "        [ 0.0946,  0.0549, -0.0290,  ...,  0.0838,  0.0356, -0.2399],\n",
            "        [-0.0065, -0.1760, -0.0210,  ...,  0.1577, -0.0944,  0.0358],\n",
            "        ...,\n",
            "        [-0.0682, -0.0643, -0.0960,  ...,  0.0360,  0.1271,  0.0319],\n",
            "        [-0.0225,  0.0275,  0.1251,  ...,  0.1561, -0.0832, -0.0409],\n",
            "        [-0.1576, -0.0460, -0.0059,  ..., -0.0117, -0.0524, -0.0094]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 014]: 100% 1/1 [00:00<00:00,  4.86it/s]\u001b[0m\n",
            "[Epoch 015]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0912,  0.1107, -0.1129,  ...,  0.0247,  0.0017, -0.0718],\n",
            "        [ 0.0602, -0.0302,  0.0477,  ..., -0.1123,  0.1385, -0.0061],\n",
            "        [-0.0224, -0.1349,  0.0018,  ..., -0.0190, -0.1137,  0.0021],\n",
            "        ...,\n",
            "        [ 0.0009,  0.0002, -0.0018,  ...,  0.0008, -0.0001,  0.0006],\n",
            "        [-0.1097,  0.0387, -0.1151,  ...,  0.0209,  0.0550,  0.0269],\n",
            "        [-0.1395, -0.0299, -0.0475,  ...,  0.1367,  0.1086, -0.0031]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 015]: 100% 1/1 [00:00<00:00,  4.93it/s]\u001b[0m\n",
            "[Epoch 016]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0304, -0.0305, -0.0360,  ...,  0.0255, -0.0334,  0.0071],\n",
            "        [ 0.1541, -0.1498,  0.0213,  ...,  0.2066, -0.0759,  0.1300],\n",
            "        [-0.0479, -0.1159,  0.0646,  ..., -0.0770, -0.1318,  0.0068],\n",
            "        ...,\n",
            "        [ 0.0423, -0.0413, -0.0437,  ...,  0.0550,  0.0926, -0.0126],\n",
            "        [-0.0105,  0.1009, -0.0781,  ...,  0.0385, -0.0945,  0.0476],\n",
            "        [ 0.1085, -0.0526, -0.0964,  ...,  0.2650, -0.0157,  0.1972]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 016]: 100% 1/1 [00:00<00:00,  4.54it/s]\u001b[0m\n",
            "[Epoch 017]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0198, -0.1207,  0.0012,  ..., -0.0168, -0.1018,  0.0021],\n",
            "        [ 0.0440, -0.1186,  0.0128,  ..., -0.0012,  0.0698,  0.0465],\n",
            "        [ 0.0752,  0.0637, -0.0796,  ..., -0.0282, -0.0048,  0.0369],\n",
            "        ...,\n",
            "        [-0.0182,  0.0220,  0.0385,  ..., -0.1744,  0.1253,  0.0056],\n",
            "        [-0.0357,  0.0956, -0.0702,  ..., -0.0374,  0.1188, -0.0073],\n",
            "        [-0.0058,  0.0565, -0.0440,  ..., -0.0226,  0.0231, -0.0603]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 017]: 100% 1/1 [00:00<00:00,  4.53it/s]\u001b[0m\n",
            "[Epoch 018]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-9.7600e-02, -7.2650e-02,  3.0188e-03,  ..., -3.4974e-02,\n",
            "         -6.7973e-02,  1.1316e-01],\n",
            "        [ 6.5998e-03, -7.3327e-02, -4.0731e-02,  ...,  8.8591e-02,\n",
            "          1.2417e-01,  3.9726e-02],\n",
            "        [-1.5703e-02, -3.1731e-02,  8.5680e-02,  ..., -3.3368e-03,\n",
            "          1.7265e-01,  9.2164e-02],\n",
            "        ...,\n",
            "        [-1.0156e-01, -2.6681e-02,  9.9486e-02,  ..., -2.8377e-03,\n",
            "          3.4152e-02, -1.0234e-01],\n",
            "        [ 1.0988e-03,  2.6713e-04, -2.1800e-03,  ...,  9.8000e-04,\n",
            "         -1.3566e-04,  7.7111e-04],\n",
            "        [-1.0421e-01, -1.2194e-03, -5.4579e-02,  ..., -3.6941e-02,\n",
            "         -1.7927e-02, -1.1871e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 018]: 100% 1/1 [00:00<00:00,  4.69it/s]\u001b[0m\n",
            "[Epoch 019]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0012,  0.0003, -0.0023,  ...,  0.0011, -0.0002,  0.0008],\n",
            "        [ 0.0152,  0.0007,  0.0069,  ..., -0.0591,  0.0569, -0.0105],\n",
            "        [-0.0235,  0.0831, -0.0840,  ..., -0.0171,  0.0742, -0.0140],\n",
            "        ...,\n",
            "        [-0.1215, -0.1089,  0.0020,  ...,  0.1051, -0.0096,  0.0184],\n",
            "        [ 0.1238, -0.0213, -0.0096,  ..., -0.0830,  0.0573,  0.0083],\n",
            "        [ 0.0012,  0.0003, -0.0023,  ...,  0.0011, -0.0002,  0.0008]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 019]: 100% 1/1 [00:00<00:00,  5.09it/s]\u001b[0m\n",
            "[Epoch 020]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1428,  0.0451,  0.0649,  ...,  0.1171,  0.1464,  0.1632],\n",
            "        [-0.1259, -0.1074,  0.0955,  ...,  0.0625, -0.0603,  0.0884],\n",
            "        [-0.0103,  0.1009, -0.0787,  ...,  0.0388, -0.0945,  0.0478],\n",
            "        ...,\n",
            "        [-0.0025,  0.0359,  0.0702,  ...,  0.0652,  0.0293, -0.0704],\n",
            "        [ 0.0647,  0.0253, -0.1206,  ..., -0.0033, -0.0265,  0.0422],\n",
            "        [-0.1145, -0.0192, -0.1018,  ..., -0.0202, -0.0240,  0.0141]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 020]: 100% 1/1 [00:00<00:00,  4.29it/s]\u001b[0m\n",
            "[Epoch 021]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0313, -0.0788, -0.1373,  ...,  0.0465, -0.1129, -0.0919],\n",
            "        [ 0.1895, -0.1385, -0.0266,  ...,  0.0282, -0.0321, -0.0190],\n",
            "        [ 0.0151,  0.0756,  0.0608,  ...,  0.0161,  0.0135,  0.0251],\n",
            "        ...,\n",
            "        [-0.0742, -0.1289, -0.0522,  ...,  0.0413,  0.0210,  0.1385],\n",
            "        [ 0.0620, -0.1726,  0.0494,  ..., -0.0169, -0.0213,  0.0324],\n",
            "        [-0.1186,  0.0536, -0.1139,  ...,  0.1226,  0.0864, -0.1076]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 021]: 100% 1/1 [00:00<00:00,  5.26it/s]\u001b[0m\n",
            "[Epoch 022]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-1.1776e-01, -1.3527e-02,  1.2987e-01,  ...,  7.5026e-02,\n",
            "         -6.1576e-03,  1.9533e-03],\n",
            "        [ 9.3549e-02, -1.5129e-01, -4.9569e-02,  ..., -7.8556e-02,\n",
            "         -1.7877e-02,  7.8664e-02],\n",
            "        [-8.7953e-02,  2.1566e-02, -1.4626e-02,  ...,  6.0659e-02,\n",
            "          2.0366e-03, -8.3497e-02],\n",
            "        ...,\n",
            "        [-1.9854e-05,  1.8158e-01, -3.5499e-02,  ...,  9.0938e-02,\n",
            "          9.6273e-02, -1.0827e-02],\n",
            "        [-4.3138e-03, -1.0602e-01,  6.2752e-02,  ..., -6.4887e-02,\n",
            "          7.2609e-02, -1.6029e-02],\n",
            "        [ 5.8592e-02, -1.2931e-01,  5.0120e-02,  ..., -2.3402e-03,\n",
            "         -2.1236e-02,  4.7597e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 022]: 100% 1/1 [00:00<00:00,  5.18it/s]\u001b[0m\n",
            "[Epoch 023]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1067, -0.1096,  0.0692,  ..., -0.0023,  0.0008,  0.0517],\n",
            "        [-0.0197, -0.0553, -0.0156,  ..., -0.1754, -0.0012, -0.0222],\n",
            "        [-0.0374, -0.0995,  0.1132,  ...,  0.0066, -0.0892, -0.0320],\n",
            "        ...,\n",
            "        [-0.0411,  0.0405, -0.0012,  ...,  0.1147, -0.0480,  0.0495],\n",
            "        [-0.0122,  0.0086,  0.0561,  ...,  0.0370, -0.0975, -0.0574],\n",
            "        [ 0.0741, -0.0105, -0.1263,  ...,  0.2523, -0.0190,  0.1674]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 023]: 100% 1/1 [00:00<00:00,  5.11it/s]\u001b[0m\n",
            "[Epoch 024]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.1027, -0.1207,  0.0713,  ...,  0.0608, -0.0612, -0.0618],\n",
            "        [-0.0741,  0.0199, -0.0219,  ...,  0.0345, -0.1144,  0.0819],\n",
            "        [ 0.0576, -0.0727, -0.1059,  ...,  0.2091, -0.0178,  0.1554],\n",
            "        ...,\n",
            "        [-0.0649,  0.0546, -0.0942,  ...,  0.0271, -0.0168, -0.0654],\n",
            "        [ 0.1777, -0.0780, -0.0978,  ...,  0.1593, -0.0122, -0.0055],\n",
            "        [ 0.0533, -0.2111, -0.0497,  ...,  0.1416,  0.1103, -0.0257]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 024]: 100% 1/1 [00:00<00:00,  5.82it/s]\u001b[0m\n",
            "[Epoch 025]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0845, -0.1013, -0.0128,  ...,  0.0053,  0.0255,  0.0433],\n",
            "        [-0.0410, -0.0267,  0.0530,  ...,  0.0351, -0.0352,  0.0969],\n",
            "        [ 0.0116, -0.0049, -0.0306,  ...,  0.0101,  0.0017, -0.0401],\n",
            "        ...,\n",
            "        [-0.0297, -0.0493, -0.0242,  ...,  0.0993, -0.0337,  0.0465],\n",
            "        [ 0.0413, -0.1032, -0.0976,  ...,  0.0084,  0.1026,  0.0919],\n",
            "        [-0.0082, -0.0275, -0.0269,  ...,  0.1341,  0.1550,  0.0240]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 025]: 100% 1/1 [00:00<00:00,  4.25it/s]\u001b[0m\n",
            "[Epoch 026]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0344,  0.0740,  0.0603,  ...,  0.0484,  0.0163, -0.0745],\n",
            "        [ 0.0290,  0.0446, -0.0966,  ...,  0.0092,  0.0787,  0.0313],\n",
            "        [-0.1983, -0.0473,  0.0142,  ...,  0.1697,  0.0423,  0.2238],\n",
            "        ...,\n",
            "        [ 0.0271, -0.0974, -0.0239,  ..., -0.0112, -0.0112,  0.0177],\n",
            "        [-0.0255,  0.0220, -0.1090,  ..., -0.0528,  0.0746, -0.0613],\n",
            "        [ 0.1462, -0.1521,  0.0093,  ...,  0.0732, -0.0780,  0.0065]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 026]: 100% 1/1 [00:00<00:00,  6.56it/s]\u001b[0m\n",
            "[Epoch 027]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 1.1375e-01,  9.4048e-02,  4.7068e-02,  ...,  1.4390e-01,\n",
            "         -1.0667e-01, -4.0968e-02],\n",
            "        [ 5.5117e-02,  1.2175e-02, -3.6361e-02,  ..., -4.8888e-02,\n",
            "          5.8797e-02, -3.2505e-02],\n",
            "        [ 1.6779e-03,  3.3262e-04, -3.4315e-03,  ...,  1.5193e-03,\n",
            "         -1.6063e-04,  1.2379e-03],\n",
            "        ...,\n",
            "        [ 1.1004e-02, -6.3354e-02,  2.2754e-02,  ..., -5.9275e-02,\n",
            "          2.8491e-02,  5.9777e-02],\n",
            "        [-6.4842e-03,  6.9523e-03,  2.5218e-02,  ..., -6.8888e-02,\n",
            "         -1.4051e-04,  4.5536e-02],\n",
            "        [ 1.6251e-01,  5.4098e-02,  1.3892e-01,  ..., -1.2679e-01,\n",
            "         -3.7122e-02,  7.3250e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 027]: 100% 1/1 [00:00<00:00,  6.17it/s]\u001b[0m\n",
            "[Epoch 028]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0242, -0.0126,  0.0005,  ..., -0.0311, -0.0125,  0.0050],\n",
            "        [-0.0299,  0.1064, -0.0099,  ...,  0.0890, -0.0668, -0.2219],\n",
            "        [ 0.0753,  0.0479,  0.0579,  ...,  0.1635, -0.0926,  0.0604],\n",
            "        ...,\n",
            "        [ 0.1625,  0.0302,  0.0258,  ..., -0.0437,  0.0057,  0.0095],\n",
            "        [-0.0098,  0.1009, -0.0798,  ...,  0.0393, -0.0944,  0.0483],\n",
            "        [-0.0391, -0.0667, -0.0327,  ...,  0.0130,  0.2328, -0.1168]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 028]: 100% 1/1 [00:00<00:00,  7.93it/s]\u001b[0m\n",
            "[Epoch 029]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-2.3973e-02, -3.4400e-02, -9.2734e-03,  ..., -5.5868e-02,\n",
            "          1.6567e-01, -9.1791e-02],\n",
            "        [ 2.3465e-02, -7.9001e-03, -6.0771e-02,  ...,  6.4211e-02,\n",
            "          2.3520e-02, -9.6587e-02],\n",
            "        [-2.0344e-02, -2.9117e-02, -7.4285e-02,  ...,  1.2004e-01,\n",
            "          5.1390e-02,  6.9023e-02],\n",
            "        ...,\n",
            "        [ 8.5684e-02,  8.4159e-03, -1.0968e-02,  ...,  9.5826e-03,\n",
            "          1.5067e-01,  1.0519e-01],\n",
            "        [ 1.7941e-03,  3.4763e-04, -3.7339e-03,  ...,  1.6211e-03,\n",
            "         -1.6275e-04,  1.3453e-03],\n",
            "        [-2.7179e-02, -1.9634e-02,  9.1304e-02,  ..., -2.6355e-02,\n",
            "          3.7461e-02, -1.6479e-01]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 029]: 100% 1/1 [00:00<00:00,  9.18it/s]\u001b[0m\n",
            "[Epoch 030]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1284, -0.1242, -0.0341,  ..., -0.0762, -0.0330,  0.0243],\n",
            "        [-0.0215,  0.0276,  0.1228,  ...,  0.1570, -0.0834, -0.0398],\n",
            "        [-0.0664, -0.0074, -0.0567,  ...,  0.0244, -0.0723, -0.0114],\n",
            "        ...,\n",
            "        [-0.1103, -0.0435,  0.1333,  ...,  0.0024, -0.0073, -0.0793],\n",
            "        [ 0.0055, -0.0250,  0.0002,  ...,  0.0180,  0.1215, -0.0383],\n",
            "        [-0.0172,  0.0126, -0.0102,  ...,  0.1166, -0.0553, -0.0085]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 030]: 100% 1/1 [00:00<00:00,  8.73it/s]\u001b[0m\n",
            "[Epoch 031]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0256,  0.0264,  0.0794,  ...,  0.1294, -0.0758, -0.1512],\n",
            "        [-0.0616,  0.0073, -0.0088,  ...,  0.0193, -0.0115, -0.0516],\n",
            "        [-0.0392,  0.0060, -0.0067,  ...,  0.0291,  0.0122, -0.0405],\n",
            "        ...,\n",
            "        [ 0.0061,  0.0407,  0.0598,  ...,  0.0513, -0.0028,  0.0287],\n",
            "        [ 0.1980,  0.0023,  0.2021,  ...,  0.0941,  0.1261,  0.1436],\n",
            "        [-0.1456, -0.0251, -0.1104,  ..., -0.0220,  0.0802, -0.0567]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 031]: 100% 1/1 [00:00<00:00,  7.14it/s]\u001b[0m\n",
            "[Epoch 032]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0337, -0.0707, -0.0102,  ...,  0.0253, -0.0314, -0.1257],\n",
            "        [ 0.0477, -0.0114,  0.0039,  ...,  0.0660, -0.0424, -0.0388],\n",
            "        [ 0.0004, -0.0580,  0.0197,  ...,  0.0044,  0.0427,  0.0458],\n",
            "        ...,\n",
            "        [-0.0095,  0.1009, -0.0804,  ...,  0.0396, -0.0943,  0.0484],\n",
            "        [ 0.0595, -0.0374, -0.0236,  ...,  0.0641, -0.0269, -0.0974],\n",
            "        [ 0.0020,  0.0004, -0.0041,  ...,  0.0018, -0.0001,  0.0015]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 032]: 100% 1/1 [00:00<00:00,  7.63it/s]\u001b[0m\n",
            "[Epoch 033]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0018, -0.0553, -0.0111,  ...,  0.0120,  0.0977,  0.0465],\n",
            "        [-0.0522, -0.0222, -0.1366,  ...,  0.1345,  0.1012,  0.0881],\n",
            "        [ 0.0172, -0.0263, -0.1055,  ..., -0.0337, -0.0122,  0.0517],\n",
            "        ...,\n",
            "        [-0.0163, -0.0780,  0.0828,  ...,  0.0225,  0.0021, -0.0907],\n",
            "        [ 0.0144,  0.0266,  0.0121,  ...,  0.0439,  0.1210, -0.3010],\n",
            "        [-0.1269,  0.1165, -0.1057,  ..., -0.0051, -0.0424, -0.0509]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 033]: 100% 1/1 [00:00<00:00,  7.42it/s]\u001b[0m\n",
            "[Epoch 034]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 1.2871e-01, -1.2427e-01, -3.4647e-02,  ..., -7.5928e-02,\n",
            "         -3.2854e-02,  2.4521e-02],\n",
            "        [-2.6821e-02, -7.5654e-02, -7.0382e-02,  ...,  7.4835e-02,\n",
            "          2.5249e-02, -1.4009e-05],\n",
            "        [-1.1364e-01, -1.9295e-02, -1.0372e-01,  ..., -1.9320e-02,\n",
            "         -2.3823e-02,  1.4668e-02],\n",
            "        ...,\n",
            "        [ 1.1595e-01, -1.0853e-01,  2.0350e-01,  ...,  4.5754e-02,\n",
            "          2.8746e-02,  2.1701e-01],\n",
            "        [ 3.8919e-02, -5.2558e-03, -1.4584e-02,  ...,  3.3477e-02,\n",
            "          4.4100e-02, -1.8398e-02],\n",
            "        [ 4.2045e-02,  8.6353e-02, -1.0553e-01,  ...,  4.1914e-03,\n",
            "         -1.2420e-02, -3.5068e-03]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 034]: 100% 1/1 [00:00<00:00,  8.56it/s]\u001b[0m\n",
            "[Epoch 035]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 2.2003e-03,  4.1424e-04, -4.5126e-03,  ...,  2.0109e-03,\n",
            "         -1.2860e-04,  1.6033e-03],\n",
            "        [-3.0037e-02, -8.1049e-02,  2.0514e-02,  ...,  7.1071e-02,\n",
            "         -7.0539e-02, -8.0196e-02],\n",
            "        [ 6.6679e-02,  2.6461e-02,  1.0085e-01,  ..., -4.3863e-02,\n",
            "         -9.4302e-03,  6.8992e-02],\n",
            "        ...,\n",
            "        [-4.7184e-02,  3.6645e-02,  1.3602e-02,  ..., -1.3224e-01,\n",
            "         -5.8649e-02,  1.4086e-01],\n",
            "        [-7.2140e-02,  1.0467e-01,  9.2953e-02,  ..., -5.0894e-03,\n",
            "         -2.7388e-02,  9.2756e-02],\n",
            "        [-1.3481e-02,  3.3064e-02, -9.5482e-02,  ..., -4.8427e-02,\n",
            "          6.1719e-02, -6.4045e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 035]: 100% 1/1 [00:00<00:00,  7.86it/s]\u001b[0m\n",
            "[Epoch 036]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0381,  0.0141,  0.0410,  ..., -0.0409,  0.0160, -0.0147],\n",
            "        [ 0.0382, -0.0725,  0.0435,  ...,  0.0448,  0.0641,  0.0707],\n",
            "        [ 0.0740, -0.0433,  0.0496,  ..., -0.0498,  0.0564, -0.0010],\n",
            "        ...,\n",
            "        [-0.0528, -0.0472, -0.1028,  ..., -0.0525,  0.1433,  0.0562],\n",
            "        [-0.0306, -0.0049,  0.0844,  ..., -0.0967,  0.2067,  0.0370],\n",
            "        [ 0.0342,  0.0496, -0.0762,  ..., -0.0549, -0.0234,  0.0524]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 036]: 100% 1/1 [00:00<00:00,  7.07it/s]\u001b[0m\n",
            "[Epoch 037]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1280, -0.0886, -0.0434,  ...,  0.0477, -0.0072,  0.0066],\n",
            "        [ 0.0178,  0.0497, -0.0308,  ...,  0.0144,  0.1640, -0.0312],\n",
            "        [ 0.0407,  0.0749,  0.1460,  ..., -0.0426, -0.0947,  0.0663],\n",
            "        ...,\n",
            "        [ 0.0561, -0.0611, -0.0798,  ...,  0.0026,  0.0505,  0.0055],\n",
            "        [ 0.1027, -0.0494, -0.0689,  ...,  0.0546, -0.0553,  0.0231],\n",
            "        [-0.0856,  0.0087,  0.0691,  ...,  0.0953, -0.1100, -0.0080]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 037]: 100% 1/1 [00:00<00:00,  8.21it/s]\u001b[0m\n",
            "[Epoch 038]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-7.6887e-03, -9.1802e-02, -2.5297e-02,  ..., -7.7584e-02,\n",
            "          7.3463e-02, -3.2511e-02],\n",
            "        [ 2.3374e-03, -7.7387e-02, -2.2803e-02,  ...,  7.0010e-02,\n",
            "         -2.0293e-02, -4.6051e-02],\n",
            "        [-4.4617e-02, -5.7284e-02,  9.2993e-03,  ...,  3.3874e-02,\n",
            "          1.1374e-02, -2.6565e-02],\n",
            "        ...,\n",
            "        [ 1.9916e-02, -9.2696e-02, -1.0012e-03,  ..., -1.9139e-02,\n",
            "         -7.6990e-02,  4.0539e-02],\n",
            "        [ 2.4161e-03,  4.3121e-04, -4.9042e-03,  ...,  2.1984e-03,\n",
            "         -1.3685e-04,  1.7154e-03],\n",
            "        [ 1.4907e-01, -1.4669e-01,  5.1254e-02,  ...,  1.5964e-01,\n",
            "         -2.9119e-02, -1.2258e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 038]: 100% 1/1 [00:00<00:00,  8.11it/s]\u001b[0m\n",
            "[Epoch 039]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0091,  0.1009, -0.0813,  ...,  0.0400, -0.0943,  0.0488],\n",
            "        [-0.0728, -0.0151, -0.0515,  ...,  0.0118,  0.0191, -0.0042],\n",
            "        [ 0.0121,  0.0583,  0.0355,  ...,  0.0374,  0.0872,  0.0113],\n",
            "        ...,\n",
            "        [ 0.1956,  0.0743,  0.0168,  ...,  0.0900, -0.0418, -0.0366],\n",
            "        [-0.0658, -0.0073, -0.0578,  ...,  0.0249, -0.0723, -0.0109],\n",
            "        [-0.0263,  0.0270,  0.0672,  ...,  0.0595, -0.0736,  0.0299]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 039]: 100% 1/1 [00:00<00:00,  8.43it/s]\u001b[0m\n",
            "[Epoch 040]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0304, -0.0415, -0.1152,  ..., -0.0116, -0.1202, -0.0507],\n",
            "        [ 0.0703, -0.0903, -0.1554,  ...,  0.2181, -0.1083,  0.0813],\n",
            "        [ 0.0329, -0.1469, -0.0709,  ...,  0.1107,  0.0732,  0.1475],\n",
            "        ...,\n",
            "        [ 0.0365, -0.1178,  0.0467,  ...,  0.0290,  0.0003,  0.0337],\n",
            "        [ 0.0148, -0.1734, -0.1400,  ...,  0.0552,  0.1758,  0.0421],\n",
            "        [-0.0474,  0.0578,  0.0862,  ..., -0.0684,  0.0383, -0.0367]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 040]: 100% 1/1 [00:00<00:00,  6.95it/s]\u001b[0m\n",
            "[Epoch 041]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0580, -0.1170, -0.0145,  ...,  0.1045, -0.0128, -0.0655],\n",
            "        [-0.0371,  0.0188,  0.0607,  ...,  0.0218, -0.0342, -0.0014],\n",
            "        [ 0.0112, -0.0593, -0.0489,  ...,  0.0483, -0.0198, -0.0201],\n",
            "        ...,\n",
            "        [ 0.0295,  0.0914,  0.1100,  ..., -0.0121, -0.0111,  0.0096],\n",
            "        [-0.1373, -0.0638,  0.1973,  ..., -0.0476,  0.0439, -0.0664],\n",
            "        [ 0.0438,  0.1256, -0.0515,  ..., -0.0111,  0.0202, -0.0921]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 041]: 100% 1/1 [00:00<00:00,  8.85it/s]\u001b[0m\n",
            "[Epoch 042]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1693, -0.1550, -0.0050,  ...,  0.1503, -0.0605,  0.0513],\n",
            "        [-0.0412, -0.0368,  0.0120,  ...,  0.0375, -0.0310,  0.1176],\n",
            "        [ 0.0027,  0.0005, -0.0055,  ...,  0.0024, -0.0002,  0.0019],\n",
            "        ...,\n",
            "        [ 0.0470, -0.0434, -0.0905,  ...,  0.0083,  0.0917, -0.0134],\n",
            "        [ 0.0654,  0.0434,  0.0092,  ..., -0.0236, -0.0501,  0.0053],\n",
            "        [-0.0845,  0.0390, -0.0213,  ...,  0.0603, -0.0063,  0.0057]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 042]: 100% 1/1 [00:00<00:00,  8.12it/s]\u001b[0m\n",
            "[Epoch 043]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0050, -0.0924, -0.0633,  ...,  0.0421,  0.0927,  0.1175],\n",
            "        [ 0.0027,  0.0005, -0.0056,  ...,  0.0024, -0.0002,  0.0020],\n",
            "        [ 0.0878,  0.0130,  0.1686,  ...,  0.1196,  0.0689, -0.0915],\n",
            "        ...,\n",
            "        [ 0.0210, -0.1043, -0.0946,  ...,  0.0275,  0.0017,  0.0336],\n",
            "        [-0.1926,  0.0082, -0.0805,  ...,  0.1016, -0.0457,  0.0202],\n",
            "        [ 0.1793, -0.1003, -0.0259,  ...,  0.1485, -0.0757,  0.0026]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 043]: 100% 1/1 [00:00<00:00,  8.41it/s]\u001b[0m\n",
            "[Epoch 044]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0850,  0.0099, -0.0888,  ...,  0.0158,  0.0775,  0.0544],\n",
            "        [ 0.0028,  0.0005, -0.0057,  ...,  0.0025, -0.0002,  0.0020],\n",
            "        [-0.0321, -0.0074,  0.0028,  ...,  0.0808, -0.2093,  0.1137],\n",
            "        ...,\n",
            "        [-0.0520,  0.0421,  0.0559,  ..., -0.0236, -0.0240,  0.1522],\n",
            "        [ 0.0562, -0.0486, -0.0512,  ...,  0.0665,  0.0405, -0.0104],\n",
            "        [-0.1079, -0.1582,  0.0458,  ..., -0.0502, -0.0822,  0.0061]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 044]: 100% 1/1 [00:00<00:00,  7.86it/s]\u001b[0m\n",
            "[Epoch 045]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1204, -0.0635, -0.0751,  ...,  0.0325,  0.0845,  0.0210],\n",
            "        [-0.1116,  0.0505, -0.0206,  ..., -0.0906, -0.0169, -0.1379],\n",
            "        [ 0.0310,  0.0202, -0.0252,  ...,  0.0501, -0.0278, -0.3171],\n",
            "        ...,\n",
            "        [-0.0931,  0.0035,  0.0634,  ...,  0.1115, -0.0796,  0.0646],\n",
            "        [ 0.0111, -0.0035,  0.0545,  ..., -0.0730,  0.1270,  0.0679],\n",
            "        [ 0.0057, -0.0319, -0.1308,  ..., -0.1217,  0.1633,  0.0100]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 045]: 100% 1/1 [00:00<00:00,  7.22it/s]\u001b[0m\n",
            "[Epoch 046]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0267, -0.0511,  0.0165,  ..., -0.0207,  0.2088,  0.0982],\n",
            "        [ 0.0233, -0.0201, -0.0113,  ..., -0.0505, -0.0189,  0.0299],\n",
            "        [ 0.0757, -0.0103, -0.1296,  ...,  0.2539, -0.0185,  0.1683],\n",
            "        ...,\n",
            "        [-0.0695, -0.0039,  0.0425,  ...,  0.0450,  0.0032, -0.1326],\n",
            "        [-0.0279,  0.0159, -0.0630,  ..., -0.0896, -0.0229,  0.0528],\n",
            "        [ 0.0610, -0.0645,  0.0130,  ...,  0.1223, -0.0408,  0.0170]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 046]: 100% 1/1 [00:00<00:00,  7.93it/s]\u001b[0m\n",
            "[Epoch 047]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 5.8035e-02, -3.7333e-02, -1.5295e-01,  ...,  2.4143e-03,\n",
            "          6.5156e-02,  2.2731e-03],\n",
            "        [ 1.9597e-02,  5.0705e-02, -3.1330e-03,  ...,  1.7578e-01,\n",
            "          1.3184e-01, -2.3132e-01],\n",
            "        [ 8.7642e-02,  1.9477e-04, -4.9547e-02,  ...,  8.0099e-02,\n",
            "         -7.2245e-02, -4.1613e-02],\n",
            "        ...,\n",
            "        [-4.0822e-02,  7.8594e-03, -7.5583e-02,  ...,  1.1061e-01,\n",
            "          7.4197e-02,  4.6244e-02],\n",
            "        [ 1.6408e-01,  5.4216e-02,  1.3623e-01,  ..., -1.2587e-01,\n",
            "         -3.6895e-02,  7.4421e-02],\n",
            "        [ 6.2031e-02, -6.7453e-02, -5.8179e-02,  ...,  3.3050e-02,\n",
            "          4.8560e-02,  4.3138e-03]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 047]: 100% 1/1 [00:00<00:00,  7.83it/s]\u001b[0m\n",
            "[Epoch 048]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0069, -0.0962, -0.1334,  ...,  0.0523,  0.0441, -0.0373],\n",
            "        [ 0.0181, -0.0315,  0.1575,  ...,  0.0953, -0.0304, -0.0977],\n",
            "        [ 0.0118, -0.1379, -0.0634,  ...,  0.0731,  0.0593,  0.0091],\n",
            "        ...,\n",
            "        [-0.0924,  0.0061,  0.1067,  ..., -0.0095,  0.0209, -0.0722],\n",
            "        [ 0.0302,  0.0521,  0.0030,  ..., -0.0933,  0.0696,  0.0866],\n",
            "        [ 0.0031,  0.0005, -0.0063,  ...,  0.0027, -0.0002,  0.0022]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 048]: 100% 1/1 [00:00<00:00,  8.39it/s]\u001b[0m\n",
            "[Epoch 049]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0876,  0.1042,  0.0099,  ...,  0.0974, -0.0710, -0.0047],\n",
            "        [-0.1155, -0.0034,  0.0185,  ...,  0.1093,  0.1897,  0.0962],\n",
            "        [ 0.0446, -0.0120, -0.0564,  ...,  0.0274, -0.0708, -0.0231],\n",
            "        ...,\n",
            "        [ 0.1046, -0.1350,  0.0420,  ...,  0.0963,  0.0134,  0.0290],\n",
            "        [ 0.0034, -0.1071,  0.0188,  ...,  0.1044, -0.0497,  0.0485],\n",
            "        [ 0.1471,  0.1716, -0.0241,  ...,  0.0322,  0.0004, -0.0181]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 049]: 100% 1/1 [00:00<00:00,  7.84it/s]\u001b[0m\n",
            "[Epoch 050]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0567, -0.0539, -0.0931,  ...,  0.0242, -0.0986,  0.0649],\n",
            "        [-0.0740, -0.0765,  0.1139,  ...,  0.1050, -0.0806,  0.0791],\n",
            "        [ 0.0769,  0.0481,  0.0549,  ...,  0.1650, -0.0927,  0.0617],\n",
            "        ...,\n",
            "        [ 0.0453, -0.0774,  0.0115,  ..., -0.0411, -0.1518,  0.0073],\n",
            "        [-0.0229,  0.1498, -0.2578,  ..., -0.0876, -0.0357, -0.0164],\n",
            "        [ 0.1267,  0.0563, -0.1950,  ..., -0.0981,  0.0630,  0.0194]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 050]: 100% 1/1 [00:00<00:00,  8.42it/s]\u001b[0m\n",
            "[Epoch 051]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0279,  0.0101,  0.0034,  ...,  0.0279,  0.0617,  0.0397],\n",
            "        [-0.0701,  0.0025, -0.0569,  ...,  0.0111,  0.0111,  0.0842],\n",
            "        [-0.0473, -0.1725, -0.0291,  ...,  0.0870, -0.0487,  0.0083],\n",
            "        ...,\n",
            "        [ 0.0623,  0.0149, -0.0638,  ...,  0.0077,  0.0804, -0.1092],\n",
            "        [-0.0177,  0.0550,  0.0461,  ..., -0.0901,  0.1368, -0.0482],\n",
            "        [ 0.0546,  0.1616,  0.0049,  ..., -0.0007, -0.0581,  0.0560]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 051]: 100% 1/1 [00:00<00:00,  6.95it/s]\u001b[0m\n",
            "[Epoch 052]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0624,  0.0149, -0.0640,  ...,  0.0077,  0.0804, -0.1091],\n",
            "        [ 0.0995,  0.2088,  0.0206,  ...,  0.0667, -0.0279, -0.0444],\n",
            "        [ 0.1101,  0.0350,  0.0045,  ...,  0.0096,  0.0332, -0.0057],\n",
            "        ...,\n",
            "        [-0.0550, -0.0671,  0.1100,  ...,  0.0345,  0.0427, -0.0101],\n",
            "        [ 0.0408,  0.0248, -0.0624,  ...,  0.0471,  0.0813, -0.1160],\n",
            "        [-0.1024, -0.0431, -0.1276,  ..., -0.0336,  0.1027, -0.0024]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 052]: 100% 1/1 [00:00<00:00,  8.05it/s]\u001b[0m\n",
            "[Epoch 053]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0808, -0.0867, -0.0101,  ..., -0.0910,  0.0199,  0.0976],\n",
            "        [ 0.0407, -0.0434,  0.0600,  ...,  0.1525, -0.0814, -0.0341],\n",
            "        [ 0.0558, -0.0916, -0.0413,  ...,  0.0499,  0.0958,  0.0759],\n",
            "        ...,\n",
            "        [-0.0036,  0.0560, -0.0293,  ...,  0.2170,  0.0325, -0.1028],\n",
            "        [ 0.0625,  0.0149, -0.0641,  ...,  0.0078,  0.0804, -0.1091],\n",
            "        [ 0.1264, -0.0211, -0.0141,  ..., -0.0813,  0.0576,  0.0103]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 053]: 100% 1/1 [00:00<00:00,  8.23it/s]\u001b[0m\n",
            "[Epoch 054]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-1.1536e-01, -4.6977e-02,  9.3883e-02,  ..., -4.2015e-02,\n",
            "         -1.9160e-02, -5.7120e-02],\n",
            "        [-1.7188e-01,  8.2716e-03,  5.3016e-02,  ..., -1.3767e-01,\n",
            "         -3.5851e-02, -6.5412e-02],\n",
            "        [ 6.9803e-02, -4.4910e-02, -1.4375e-01,  ...,  5.7631e-02,\n",
            "         -3.2128e-02, -1.4870e-01],\n",
            "        ...,\n",
            "        [ 5.0843e-02,  4.7197e-02, -3.3714e-02,  ...,  6.0923e-02,\n",
            "          2.5753e-02, -2.0550e-02],\n",
            "        [-2.2217e-02,  4.7911e-02,  4.0176e-03,  ..., -9.6357e-02,\n",
            "          1.2278e-01, -5.3848e-02],\n",
            "        [-8.2468e-02, -1.4930e-01, -1.6168e-04,  ...,  6.6060e-02,\n",
            "         -1.8062e-01, -4.1181e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 054]: 100% 1/1 [00:00<00:00,  8.16it/s]\u001b[0m\n",
            "[Epoch 055]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0548,  0.1616,  0.0043,  ..., -0.0004, -0.0581,  0.0562],\n",
            "        [ 0.0420,  0.0749,  0.1437,  ..., -0.0416, -0.0948,  0.0672],\n",
            "        [ 0.0174,  0.0346,  0.0678,  ..., -0.0483,  0.0838,  0.0310],\n",
            "        ...,\n",
            "        [-0.0731,  0.0471, -0.0290,  ...,  0.0144, -0.0534,  0.0392],\n",
            "        [-0.0294, -0.1131,  0.0201,  ...,  0.0460, -0.0441,  0.0377],\n",
            "        [-0.0062,  0.0197,  0.0608,  ...,  0.1245,  0.0133,  0.0198]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 055]: 100% 1/1 [00:00<00:00,  9.14it/s]\u001b[0m\n",
            "[Epoch 056]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0075,  0.0930, -0.0138,  ..., -0.0863,  0.0817,  0.0424],\n",
            "        [-0.0224,  0.0319, -0.0190,  ..., -0.0658, -0.0367, -0.0365],\n",
            "        [ 0.0036,  0.0005, -0.0073,  ...,  0.0032, -0.0003,  0.0026],\n",
            "        ...,\n",
            "        [ 0.0477, -0.0496, -0.0220,  ..., -0.0179, -0.0226,  0.1377],\n",
            "        [ 0.0628,  0.0149, -0.0646,  ...,  0.0079,  0.0803, -0.1089],\n",
            "        [ 0.1133, -0.0315, -0.0420,  ..., -0.0535,  0.0442, -0.0131]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 056]: 100% 1/1 [00:00<00:00,  6.85it/s]\u001b[0m\n",
            "[Epoch 057]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-4.6893e-02,  5.7119e-03,  2.7815e-02,  ..., -3.1187e-02,\n",
            "          3.3129e-02,  7.3996e-02],\n",
            "        [ 5.2381e-03,  5.7486e-02, -5.0192e-02,  ...,  4.9509e-02,\n",
            "          2.6193e-02, -1.2739e-01],\n",
            "        [-2.5477e-02,  1.1077e-02, -1.2093e-01,  ...,  5.8649e-02,\n",
            "          4.0912e-02,  3.0338e-02],\n",
            "        ...,\n",
            "        [ 1.3560e-01,  8.4339e-02, -1.6928e-02,  ...,  6.8024e-03,\n",
            "          1.5769e-01,  1.1019e-01],\n",
            "        [ 3.6982e-03,  5.5015e-04, -7.3960e-03,  ...,  3.2703e-03,\n",
            "         -2.6032e-04,  2.6690e-03],\n",
            "        [-7.7104e-02,  4.5907e-02,  5.9266e-02,  ...,  9.1459e-02,\n",
            "          1.4411e-01, -1.5671e-04]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 057]: 100% 1/1 [00:00<00:00,  8.68it/s]\u001b[0m\n",
            "[Epoch 058]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0392,  0.0573, -0.0443,  ..., -0.0200, -0.0506,  0.0627],\n",
            "        [-0.0387, -0.0037,  0.0249,  ...,  0.1200,  0.0039, -0.0860],\n",
            "        [-0.0438, -0.1316,  0.0039,  ...,  0.0595,  0.0411, -0.1629],\n",
            "        ...,\n",
            "        [-0.0515,  0.0177,  0.0344,  ..., -0.0581,  0.0857,  0.0688],\n",
            "        [ 0.0403, -0.0110,  0.0104,  ...,  0.0899, -0.0902, -0.0135],\n",
            "        [ 0.0101,  0.0389,  0.0534,  ..., -0.0460, -0.0412, -0.1183]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 058]: 100% 1/1 [00:00<00:00,  7.12it/s]\u001b[0m\n",
            "[Epoch 059]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0091, -0.0126,  0.0045,  ...,  0.0164, -0.0703, -0.2296],\n",
            "        [-0.0841, -0.0552, -0.0180,  ..., -0.0036,  0.0363,  0.0037],\n",
            "        [-0.0283,  0.0073, -0.0700,  ...,  0.0175,  0.0499,  0.0222],\n",
            "        ...,\n",
            "        [-0.1618, -0.0031, -0.0176,  ..., -0.0060, -0.2659,  0.1865],\n",
            "        [ 0.0703, -0.0100,  0.0266,  ...,  0.1426,  0.0040, -0.2132],\n",
            "        [ 0.0806, -0.0814, -0.1159,  ...,  0.0723,  0.1058,  0.0765]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 059]: 100% 1/1 [00:00<00:00,  8.76it/s]\u001b[0m\n",
            "[Epoch 060]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0666, -0.1613, -0.2032,  ...,  0.0628, -0.0413, -0.0090],\n",
            "        [ 0.0468, -0.0366,  0.0320,  ..., -0.0803, -0.0108, -0.0366],\n",
            "        [-0.1132, -0.0747,  0.0679,  ...,  0.1574, -0.0018,  0.0861],\n",
            "        ...,\n",
            "        [-0.0562,  0.0250, -0.0424,  ...,  0.0357, -0.0024, -0.1781],\n",
            "        [-0.0202, -0.0017, -0.1401,  ...,  0.0032,  0.0817,  0.0659],\n",
            "        [ 0.0207,  0.0864,  0.0909,  ..., -0.0015,  0.0409, -0.1179]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 060]: 100% 1/1 [00:00<00:00,  6.82it/s]\u001b[0m\n",
            "[Epoch 061]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0711,  0.0592,  0.0142,  ..., -0.0975,  0.0460,  0.0298],\n",
            "        [-0.0489, -0.0222,  0.0547,  ...,  0.0353,  0.0599,  0.0827],\n",
            "        [ 0.0185,  0.0256,  0.1063,  ...,  0.1114,  0.1509,  0.0362],\n",
            "        ...,\n",
            "        [ 0.0450, -0.0384, -0.0458,  ...,  0.1778,  0.0831,  0.0707],\n",
            "        [ 0.0432, -0.0724, -0.0522,  ...,  0.0851, -0.0428, -0.0525],\n",
            "        [-0.0259,  0.0219, -0.0648,  ..., -0.0831,  0.0190,  0.0241]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 061]: 100% 1/1 [00:00<00:00,  8.79it/s]\u001b[0m\n",
            "[Epoch 062]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0920, -0.1188, -0.1147,  ..., -0.0038, -0.0327,  0.0400],\n",
            "        [-0.0288, -0.0044,  0.0804,  ..., -0.0950,  0.2062,  0.0380],\n",
            "        [ 0.0877,  0.0297, -0.0151,  ...,  0.0457, -0.1071,  0.0450],\n",
            "        ...,\n",
            "        [ 0.0742, -0.1234,  0.0174,  ...,  0.0420, -0.0151,  0.0705],\n",
            "        [-0.0596, -0.0344,  0.0702,  ..., -0.0497,  0.1285,  0.0478],\n",
            "        [-0.0507, -0.0973, -0.0580,  ...,  0.0729,  0.0190,  0.1540]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 062]: 100% 1/1 [00:00<00:00,  7.73it/s]\u001b[0m\n",
            "[Epoch 063]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0213, -0.0783, -0.0659,  ...,  0.0151,  0.0517, -0.0182],\n",
            "        [ 0.0483, -0.0586,  0.0009,  ...,  0.1454,  0.0112,  0.0028],\n",
            "        [ 0.0823, -0.1248, -0.0579,  ...,  0.0323,  0.0111,  0.0527],\n",
            "        ...,\n",
            "        [ 0.1353, -0.1285, -0.0722,  ...,  0.1922, -0.0953,  0.0261],\n",
            "        [-0.0190,  0.0335, -0.0202,  ..., -0.0052, -0.0047,  0.0295],\n",
            "        [ 0.0581,  0.0562, -0.1149,  ..., -0.0631, -0.0968,  0.0197]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 063]: 100% 1/1 [00:00<00:00,  8.28it/s]\u001b[0m\n",
            "[Epoch 064]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1287, -0.0590, -0.0590,  ...,  0.0267,  0.0484,  0.0845],\n",
            "        [-0.0366, -0.0348, -0.0154,  ...,  0.0811, -0.0456,  0.1922],\n",
            "        [ 0.0106, -0.0304, -0.2022,  ..., -0.0647,  0.1012,  0.0289],\n",
            "        ...,\n",
            "        [-0.0073,  0.1009, -0.0847,  ...,  0.0415, -0.0942,  0.0501],\n",
            "        [ 0.1327, -0.0377, -0.0436,  ..., -0.0298,  0.0092, -0.0236],\n",
            "        [-0.0291, -0.0556,  0.0489,  ..., -0.0918, -0.0279,  0.1561]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 064]: 100% 1/1 [00:00<00:00,  8.12it/s]\u001b[0m\n",
            "[Epoch 065]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0505, -0.1272, -0.0671,  ..., -0.0023, -0.0636,  0.0244],\n",
            "        [-0.0219,  0.0048, -0.0062,  ..., -0.0283,  0.0470,  0.0433],\n",
            "        [ 0.0179,  0.0301, -0.0691,  ..., -0.0397, -0.0956,  0.0734],\n",
            "        ...,\n",
            "        [ 0.0403, -0.1383, -0.0561,  ...,  0.0166,  0.0456,  0.0308],\n",
            "        [-0.2047,  0.1325,  0.0768,  ...,  0.0460,  0.1266, -0.0060],\n",
            "        [ 0.0457, -0.0119, -0.0586,  ...,  0.0283, -0.0708, -0.0223]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 065]: 100% 1/1 [00:00<00:00,  7.20it/s]\u001b[0m\n",
            "[Epoch 066]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0287, -0.0319,  0.0241,  ...,  0.0502,  0.0822,  0.1054],\n",
            "        [ 0.0044,  0.0006, -0.0086,  ...,  0.0038, -0.0002,  0.0032],\n",
            "        [ 0.0563, -0.0537, -0.0846,  ..., -0.0484,  0.0989,  0.0232],\n",
            "        ...,\n",
            "        [ 0.0044,  0.0006, -0.0086,  ...,  0.0038, -0.0002,  0.0032],\n",
            "        [ 0.0624, -0.0990, -0.0814,  ...,  0.0390, -0.0563, -0.0155],\n",
            "        [ 0.0202, -0.0558,  0.0443,  ...,  0.0214, -0.0380,  0.0171]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 066]: 100% 1/1 [00:00<00:00,  8.62it/s]\u001b[0m\n",
            "[Epoch 067]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0780,  0.0670,  0.0259,  ...,  0.0735, -0.0081,  0.0149],\n",
            "        [-0.0394, -0.0163, -0.0291,  ..., -0.0338,  0.0426, -0.0143],\n",
            "        [ 0.0301,  0.0553, -0.1303,  ...,  0.0181,  0.0359, -0.0226],\n",
            "        ...,\n",
            "        [ 0.1927, -0.1386, -0.0334,  ...,  0.0316, -0.0307, -0.0171],\n",
            "        [ 0.0044,  0.0007, -0.0088,  ...,  0.0039, -0.0003,  0.0032],\n",
            "        [-0.0364, -0.0511,  0.0379,  ...,  0.0980, -0.1315,  0.0034]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 067]: 100% 1/1 [00:00<00:00,  6.35it/s]\u001b[0m\n",
            "[Epoch 068]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0534,  0.0186,  0.0885,  ...,  0.1765,  0.0049, -0.0039],\n",
            "        [-0.0136, -0.0931, -0.0995,  ..., -0.0393, -0.0283,  0.0328],\n",
            "        [ 0.0474, -0.0366,  0.0310,  ..., -0.0798, -0.0107, -0.0362],\n",
            "        ...,\n",
            "        [ 0.0309,  0.0013,  0.0227,  ...,  0.0544, -0.0808, -0.0529],\n",
            "        [-0.2045,  0.1326,  0.0764,  ...,  0.0463,  0.1266, -0.0059],\n",
            "        [ 0.0203,  0.1045, -0.1923,  ...,  0.0763,  0.0172, -0.0521]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 068]: 100% 1/1 [00:00<00:00,  8.03it/s]\u001b[0m\n",
            "[Epoch 069]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0720, -0.0680, -0.0722,  ...,  0.1424, -0.0708, -0.1376],\n",
            "        [ 0.0878,  0.0240,  0.0085,  ...,  0.0998,  0.0401, -0.1987],\n",
            "        [ 0.0354,  0.0029, -0.0391,  ...,  0.0597,  0.1449,  0.0931],\n",
            "        ...,\n",
            "        [ 0.0295,  0.0291,  0.0883,  ...,  0.1083, -0.0754, -0.0129],\n",
            "        [ 0.0992,  0.0004, -0.0577,  ...,  0.0908, -0.0804, -0.0458],\n",
            "        [-0.0207, -0.0293,  0.0015,  ..., -0.0454,  0.0576,  0.0060]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 069]: 100% 1/1 [00:00<00:00,  6.54it/s]\u001b[0m\n",
            "[Epoch 070]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0072, -0.0457, -0.0088,  ...,  0.0146, -0.0120,  0.0453],\n",
            "        [-0.1536, -0.0450, -0.0131,  ..., -0.0086, -0.0530, -0.0065],\n",
            "        [-0.0808, -0.0397, -0.0260,  ...,  0.0358,  0.0322, -0.0102],\n",
            "        ...,\n",
            "        [-0.1150, -0.0168, -0.0067,  ...,  0.1039,  0.1269,  0.0399],\n",
            "        [-0.0249,  0.0811, -0.0671,  ...,  0.0060,  0.0455,  0.0452],\n",
            "        [-0.0050,  0.0163,  0.0515,  ..., -0.0558, -0.0042, -0.0028]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 070]: 100% 1/1 [00:00<00:00,  8.33it/s]\u001b[0m\n",
            "[Epoch 071]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-2.9026e-02, -7.1036e-02,  1.0315e-01,  ..., -1.1155e-02,\n",
            "          1.7286e-01,  1.0763e-04],\n",
            "        [ 6.3085e-02, -7.0756e-02, -5.1278e-02,  ...,  5.2873e-02,\n",
            "          1.9763e-02,  4.2684e-02],\n",
            "        [-1.8437e-02,  2.5035e-02,  2.9306e-02,  ..., -4.3898e-02,\n",
            "          5.6853e-03,  8.5882e-03],\n",
            "        ...,\n",
            "        [ 1.2618e-01, -2.0960e-02, -1.2542e-01,  ...,  1.1712e-01,\n",
            "         -1.1655e-03, -6.5769e-02],\n",
            "        [ 4.4946e-02, -3.5814e-02,  5.0962e-02,  ..., -2.5143e-02,\n",
            "         -9.7559e-02,  3.9055e-02],\n",
            "        [-1.1269e-01,  1.2685e-01, -9.9378e-02,  ...,  4.5041e-02,\n",
            "          4.1209e-03, -6.5296e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 071]: 100% 1/1 [00:00<00:00,  7.36it/s]\u001b[0m\n",
            "[Epoch 072]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 1.0714e-02,  1.5964e-01, -2.9815e-03,  ..., -2.4490e-01,\n",
            "          1.0994e-01, -7.5822e-02],\n",
            "        [ 1.1802e-02, -5.8794e-02,  1.2294e-04,  ...,  1.3646e-01,\n",
            "          6.5105e-02, -5.7321e-04],\n",
            "        [ 9.0684e-02, -5.4773e-02, -6.3374e-02,  ...,  1.8618e-02,\n",
            "          1.4589e-01,  4.3614e-02],\n",
            "        ...,\n",
            "        [ 1.6798e-01,  5.7245e-02, -3.3999e-02,  ...,  4.7216e-02,\n",
            "          8.7674e-02, -1.0960e-02],\n",
            "        [-6.2208e-02, -2.8974e-02, -6.2139e-02,  ..., -1.1421e-01,\n",
            "          1.4180e-01, -2.0682e-02],\n",
            "        [ 6.9887e-02, -2.8634e-03,  5.5736e-03,  ..., -1.1427e-02,\n",
            "         -6.2051e-02,  4.8806e-02]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 072]: 100% 1/1 [00:00<00:00,  8.39it/s]\u001b[0m\n",
            "[Epoch 073]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0048,  0.0008, -0.0096,  ...,  0.0043, -0.0003,  0.0035],\n",
            "        [ 0.0860,  0.0338,  0.0004,  ...,  0.1401, -0.0119, -0.0342],\n",
            "        [ 0.0048,  0.0008, -0.0096,  ...,  0.0043, -0.0003,  0.0035],\n",
            "        ...,\n",
            "        [-0.0184,  0.0336, -0.0216,  ..., -0.0045, -0.0047,  0.0299],\n",
            "        [ 0.0336, -0.0899,  0.0651,  ...,  0.1731,  0.0957,  0.1333],\n",
            "        [-0.0178, -0.1342, -0.0059,  ..., -0.0160, -0.1139,  0.0054]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 073]: 100% 1/1 [00:00<00:00,  8.51it/s]\u001b[0m\n",
            "[Epoch 074]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0050,  0.0583,  0.0422,  ...,  0.0587, -0.0100, -0.0296],\n",
            "        [-0.0048,  0.0200,  0.0582,  ...,  0.1257,  0.0133,  0.0208],\n",
            "        [-0.0021,  0.0652,  0.0378,  ..., -0.0257, -0.0544,  0.0847],\n",
            "        ...,\n",
            "        [ 0.0811, -0.1476, -0.0581,  ...,  0.0128, -0.0964, -0.0254],\n",
            "        [-0.0887,  0.0434,  0.0909,  ...,  0.1117,  0.0306,  0.0638],\n",
            "        [ 0.0050, -0.0872,  0.0741,  ...,  0.1107,  0.0816,  0.1781]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 074]: 100% 1/1 [00:00<00:00,  6.75it/s]\u001b[0m\n",
            "[Epoch 075]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-5.4296e-05,  2.6056e-02, -1.0172e-01,  ..., -6.5237e-02,\n",
            "          4.6461e-02, -2.0992e-02],\n",
            "        [ 6.5784e-02, -1.0859e-01,  1.1677e-02,  ...,  8.8386e-02,\n",
            "          7.0596e-03,  6.8204e-02],\n",
            "        [ 1.5179e-01, -1.4587e-01,  4.5786e-02,  ...,  1.6216e-01,\n",
            "         -2.9034e-02, -1.0557e-02],\n",
            "        ...,\n",
            "        [-3.9814e-02, -1.2852e-02,  6.5370e-02,  ...,  9.8102e-02,\n",
            "          6.3533e-02,  1.5724e-02],\n",
            "        [ 2.9885e-02,  2.9146e-02,  8.7503e-02,  ...,  1.0863e-01,\n",
            "         -7.5473e-02, -1.2551e-02],\n",
            "        [-3.1151e-02, -5.4221e-02,  6.0943e-02,  ..., -8.5537e-02,\n",
            "          1.5554e-01, -7.2400e-03]], grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 075]: 100% 1/1 [00:00<00:00,  8.88it/s]\u001b[0m\n",
            "[Epoch 076]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0819, -0.0448,  0.0100,  ..., -0.0336,  0.1262, -0.0063],\n",
            "        [-0.0514, -0.0647,  0.0584,  ...,  0.0321, -0.0023, -0.0684],\n",
            "        [ 0.0050,  0.0008, -0.0100,  ...,  0.0044, -0.0002,  0.0036],\n",
            "        ...,\n",
            "        [ 0.0642,  0.0151, -0.0674,  ...,  0.0090,  0.0802, -0.1079],\n",
            "        [ 0.0812, -0.0502,  0.0659,  ...,  0.1960,  0.0747,  0.0267],\n",
            "        [-0.0034,  0.0109,  0.0219,  ...,  0.0187,  0.2008,  0.0976]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 076]: 100% 1/1 [00:00<00:00,  6.77it/s]\u001b[0m\n",
            "[Epoch 077]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0595, -0.0315,  0.0040,  ..., -0.0224,  0.0893, -0.0034],\n",
            "        [ 0.0436,  0.0752,  0.1407,  ..., -0.0403, -0.0948,  0.0682],\n",
            "        [-0.0314, -0.0316,  0.0103,  ...,  0.0801,  0.0401, -0.0408],\n",
            "        ...,\n",
            "        [ 0.0083, -0.0092, -0.1605,  ...,  0.0054,  0.0099,  0.0280],\n",
            "        [ 0.0348,  0.0535, -0.0268,  ..., -0.1970,  0.0068, -0.0722],\n",
            "        [-0.0102, -0.0674,  0.0332,  ..., -0.0791, -0.0125,  0.0027]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 077]: 100% 1/1 [00:00<00:00,  8.67it/s]\u001b[0m\n",
            "[Epoch 078]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0230, -0.1616,  0.0070,  ..., -0.0657,  0.0365,  0.0126],\n",
            "        [-0.0500,  0.0586, -0.1645,  ..., -0.0321, -0.0770, -0.0692],\n",
            "        [ 0.0371, -0.0041, -0.0493,  ..., -0.0219,  0.0525,  0.0183],\n",
            "        ...,\n",
            "        [-0.0905,  0.0845, -0.0495,  ...,  0.0008,  0.0293, -0.0265],\n",
            "        [-0.0239, -0.0188,  0.0848,  ..., -0.0236,  0.0371, -0.1627],\n",
            "        [ 0.0924, -0.1517, -0.0090,  ..., -0.0284,  0.1140,  0.0813]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 078]: 100% 1/1 [00:00<00:00,  8.27it/s]\u001b[0m\n",
            "[Epoch 079]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0237,  0.0459,  0.1219,  ...,  0.0701,  0.0153,  0.0719],\n",
            "        [-0.0629,  0.0273, -0.0312,  ..., -0.0385, -0.0138, -0.0884],\n",
            "        [-0.0990,  0.1004, -0.1370,  ...,  0.0260,  0.0143, -0.0652],\n",
            "        ...,\n",
            "        [ 0.0381, -0.1247, -0.0368,  ...,  0.1658, -0.0202, -0.1972],\n",
            "        [ 0.0996, -0.1382,  0.0135,  ..., -0.0544,  0.0499,  0.0325],\n",
            "        [-0.0542, -0.0222, -0.0360,  ...,  0.0119,  0.0772,  0.1201]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 079]: 100% 1/1 [00:00<00:00,  7.91it/s]\u001b[0m\n",
            "[Epoch 080]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0130,  0.0022,  0.0079,  ...,  0.0774,  0.1148,  0.0246],\n",
            "        [-0.1059, -0.0532,  0.0436,  ..., -0.0571, -0.1143, -0.0313],\n",
            "        [-0.0447,  0.0272, -0.0102,  ...,  0.0686,  0.0453,  0.1393],\n",
            "        ...,\n",
            "        [ 0.0230,  0.0487,  0.0303,  ..., -0.1055, -0.0046,  0.1074],\n",
            "        [ 0.0101, -0.0150,  0.0241,  ...,  0.0635, -0.1237,  0.0958],\n",
            "        [-0.0008, -0.1133, -0.0311,  ..., -0.0974,  0.0522,  0.0006]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 080]: 100% 1/1 [00:00<00:00,  8.07it/s]\u001b[0m\n",
            "[Epoch 081]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0645,  0.0151, -0.0680,  ...,  0.0093,  0.0801, -0.1078],\n",
            "        [ 0.0283, -0.1125, -0.1189,  ..., -0.0299, -0.0188,  0.0397],\n",
            "        [ 0.1349,  0.1319, -0.0435,  ...,  0.1360, -0.0192, -0.0136],\n",
            "        ...,\n",
            "        [ 0.0371,  0.0357, -0.1145,  ...,  0.1275,  0.0443,  0.0813],\n",
            "        [-0.0051, -0.0760,  0.0782,  ...,  0.0079,  0.0237,  0.2033],\n",
            "        [-0.0430, -0.0813,  0.1300,  ..., -0.0099, -0.0307, -0.0517]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 081]: 100% 1/1 [00:00<00:00,  7.06it/s]\u001b[0m\n",
            "[Epoch 082]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0184,  0.0283,  0.0358,  ...,  0.0231, -0.0144, -0.0201],\n",
            "        [-0.0452, -0.0665, -0.0702,  ..., -0.0189,  0.0629, -0.0300],\n",
            "        [ 0.0645,  0.0151, -0.0681,  ...,  0.0094,  0.0801, -0.1077],\n",
            "        ...,\n",
            "        [-0.1444, -0.0070,  0.0084,  ..., -0.0676,  0.0618, -0.1812],\n",
            "        [ 0.0532,  0.0169, -0.0414,  ..., -0.0140,  0.0768, -0.0049],\n",
            "        [-0.0245, -0.0230, -0.0298,  ..., -0.0539,  0.0609,  0.0098]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 082]: 100% 1/1 [00:00<00:00,  9.18it/s]\u001b[0m\n",
            "[Epoch 083]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0009, -0.1205,  0.1227,  ...,  0.0021, -0.0646,  0.0962],\n",
            "        [ 0.0118,  0.0392,  0.0501,  ..., -0.0446, -0.0413, -0.1171],\n",
            "        [ 0.1634,  0.0014,  0.2201,  ...,  0.0983,  0.1972,  0.1348],\n",
            "        ...,\n",
            "        [-0.0075, -0.0867,  0.0263,  ...,  0.1336,  0.1065, -0.0879],\n",
            "        [-0.0080,  0.0090,  0.0481,  ...,  0.0403, -0.0979, -0.0539],\n",
            "        [ 0.0803,  0.0881, -0.1006,  ...,  0.0491,  0.0183, -0.0755]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 083]: 100% 1/1 [00:00<00:00,  7.33it/s]\u001b[0m\n",
            "[Epoch 084]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.1112, -0.1095,  0.0599,  ...,  0.0008,  0.0012,  0.0549],\n",
            "        [ 0.1272, -0.0685,  0.0335,  ...,  0.0265,  0.0094, -0.0422],\n",
            "        [ 0.1481,  0.0308,  0.1521,  ..., -0.0183,  0.0550,  0.1343],\n",
            "        ...,\n",
            "        [ 0.0594,  0.0721, -0.0129,  ..., -0.0224, -0.0241,  0.0319],\n",
            "        [-0.0187, -0.0156, -0.0184,  ...,  0.1036,  0.0358,  0.0407],\n",
            "        [ 0.0088, -0.0855,  0.0184,  ..., -0.0120, -0.0019, -0.0104]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 084]: 100% 1/1 [00:00<00:00,  7.83it/s]\u001b[0m\n",
            "[Epoch 085]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0451,  0.0282, -0.0225,  ..., -0.0194, -0.0251, -0.2689],\n",
            "        [-0.2035,  0.1332,  0.0741,  ...,  0.0471,  0.1267, -0.0052],\n",
            "        [-0.0827, -0.0731,  0.0417,  ..., -0.0442, -0.0184, -0.0251],\n",
            "        ...,\n",
            "        [ 0.0430, -0.0944, -0.0095,  ...,  0.1118, -0.0476,  0.0446],\n",
            "        [-0.2166,  0.0492,  0.0156,  ..., -0.0401, -0.0830, -0.1027],\n",
            "        [-0.0041,  0.0201,  0.0567,  ...,  0.1263,  0.0132,  0.0214]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 085]: 100% 1/1 [00:00<00:00,  9.01it/s]\u001b[0m\n",
            "[Epoch 086]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0963, -0.0463, -0.0503,  ...,  0.0806, -0.0287,  0.1247],\n",
            "        [-0.0060, -0.1093, -0.0094,  ..., -0.0133, -0.0131,  0.0265],\n",
            "        [ 0.1337,  0.0651,  0.0589,  ...,  0.0116, -0.0310, -0.0693],\n",
            "        ...,\n",
            "        [-0.0425,  0.0407, -0.0020,  ...,  0.0164,  0.1061,  0.0377],\n",
            "        [ 0.0571,  0.0978,  0.1643,  ...,  0.0094,  0.0986, -0.0569],\n",
            "        [ 0.0576, -0.1036, -0.0335,  ...,  0.0105,  0.0831, -0.0081]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 086]: 100% 1/1 [00:00<00:00,  7.26it/s]\u001b[0m\n",
            "[Epoch 087]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0814, -0.0333, -0.0053,  ..., -0.0676,  0.0896, -0.0623],\n",
            "        [ 0.0341,  0.0907,  0.0544,  ...,  0.1604, -0.0023, -0.1201],\n",
            "        [ 0.0764,  0.0992, -0.0476,  ..., -0.0750,  0.0698, -0.0280],\n",
            "        ...,\n",
            "        [ 0.1456, -0.1317,  0.0114,  ...,  0.0974, -0.0578,  0.0407],\n",
            "        [ 0.0626, -0.0762, -0.0398,  ..., -0.0282,  0.0871, -0.0326],\n",
            "        [-0.0152,  0.0558,  0.0409,  ..., -0.0878,  0.1364, -0.0467]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 087]: 100% 1/1 [00:00<00:00,  8.94it/s]\u001b[0m\n",
            "[Epoch 088]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0199, -0.1186, -0.1501,  ...,  0.0766, -0.0635, -0.0900],\n",
            "        [ 0.0058,  0.0010, -0.0115,  ...,  0.0051, -0.0003,  0.0041],\n",
            "        [-0.0399, -0.0631,  0.0198,  ...,  0.1508, -0.0790, -0.0849],\n",
            "        ...,\n",
            "        [ 0.0956, -0.1614, -0.0549,  ...,  0.1514,  0.0478,  0.0032],\n",
            "        [ 0.0298, -0.0256, -0.0529,  ..., -0.0715,  0.0922, -0.0274],\n",
            "        [-0.0217,  0.0555, -0.0045,  ..., -0.0373, -0.0255,  0.0808]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 088]: 100% 1/1 [00:00<00:00,  7.62it/s]\u001b[0m\n",
            "[Epoch 089]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0059,  0.0010, -0.0116,  ...,  0.0052, -0.0003,  0.0042],\n",
            "        [ 0.0260, -0.0158, -0.0383,  ..., -0.0245, -0.0273,  0.1652],\n",
            "        [ 0.0651,  0.0152, -0.0691,  ...,  0.0097,  0.0800, -0.1074],\n",
            "        ...,\n",
            "        [ 0.0172,  0.0454, -0.1190,  ...,  0.1909,  0.0278,  0.1586],\n",
            "        [-0.1262, -0.1387, -0.0373,  ...,  0.2097, -0.0521,  0.0352],\n",
            "        [-0.0554, -0.0095, -0.0469,  ...,  0.0751,  0.0101,  0.1305]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 089]: 100% 1/1 [00:00<00:00,  8.89it/s]\u001b[0m\n",
            "[Epoch 090]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0433, -0.0525, -0.0389,  ...,  0.0495,  0.0273,  0.0272],\n",
            "        [ 0.0213, -0.0160, -0.0192,  ..., -0.0137, -0.0547,  0.0887],\n",
            "        [-0.1324, -0.1519, -0.1078,  ...,  0.1116,  0.0354,  0.0234],\n",
            "        ...,\n",
            "        [-0.0820,  0.1601, -0.1847,  ..., -0.0376,  0.0533, -0.0290],\n",
            "        [ 0.0523, -0.0398,  0.0217,  ..., -0.0913,  0.0459,  0.0425],\n",
            "        [ 0.0892,  0.0108,  0.0265,  ...,  0.0224, -0.0753, -0.0113]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 090]: 100% 1/1 [00:00<00:00,  9.08it/s]\u001b[0m\n",
            "[Epoch 091]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0259,  0.0077, -0.0743,  ...,  0.0193,  0.0499,  0.0239],\n",
            "        [ 0.0060,  0.0010, -0.0119,  ...,  0.0053, -0.0004,  0.0043],\n",
            "        [-0.0984, -0.0056,  0.0272,  ...,  0.1478, -0.0709,  0.0764],\n",
            "        ...,\n",
            "        [ 0.0156, -0.0888,  0.0538,  ...,  0.0587, -0.0924, -0.0597],\n",
            "        [-0.2031,  0.1333,  0.0733,  ...,  0.0474,  0.1267, -0.0049],\n",
            "        [ 0.0598, -0.1432, -0.1101,  ...,  0.0448,  0.0445,  0.0377]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 091]: 100% 1/1 [00:00<00:00,  8.16it/s]\u001b[0m\n",
            "[Epoch 092]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0555, -0.0625, -0.0255,  ...,  0.0778,  0.0658,  0.1059],\n",
            "        [ 0.0582, -0.0587, -0.0404,  ...,  0.0260,  0.0502, -0.0074],\n",
            "        [ 0.0508, -0.0121,  0.0792,  ..., -0.0514,  0.0103,  0.0850],\n",
            "        ...,\n",
            "        [-0.0249,  0.0054,  0.0545,  ..., -0.0114,  0.0791,  0.0824],\n",
            "        [ 0.0016,  0.0419,  0.0071,  ..., -0.0288,  0.0828,  0.0556],\n",
            "        [ 0.0802, -0.0729, -0.0610,  ..., -0.0530,  0.1858,  0.0372]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 092]: 100% 1/1 [00:00<00:00,  7.90it/s]\u001b[0m\n",
            "[Epoch 093]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0163, -0.0195, -0.0184,  ...,  0.0290, -0.0700,  0.1451],\n",
            "        [ 0.0236, -0.1570, -0.0920,  ...,  0.0513, -0.0265,  0.0141],\n",
            "        [ 0.0822,  0.0344, -0.0278,  ...,  0.0693, -0.0277, -0.2562],\n",
            "        ...,\n",
            "        [-0.1204, -0.0310,  0.0148,  ...,  0.1407,  0.0237,  0.0563],\n",
            "        [-0.0589, -0.0299,  0.0953,  ..., -0.0668,  0.0444, -0.0232],\n",
            "        [ 0.0250,  0.0645,  0.0331,  ...,  0.0340,  0.1017,  0.1335]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 093]: 100% 1/1 [00:00<00:00,  6.91it/s]\u001b[0m\n",
            "[Epoch 094]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0564, -0.1515, -0.0314,  ...,  0.0494,  0.0540, -0.1781],\n",
            "        [ 0.0654,  0.0152, -0.0698,  ...,  0.0100,  0.0799, -0.1072],\n",
            "        [-0.0884,  0.0488, -0.0347,  ...,  0.0682, -0.0290,  0.0076],\n",
            "        ...,\n",
            "        [-0.0886, -0.0949, -0.0967,  ...,  0.1274, -0.0223,  0.0493],\n",
            "        [ 0.0381,  0.0359, -0.1163,  ...,  0.1282,  0.0442,  0.0819],\n",
            "        [-0.0645,  0.0465,  0.0625,  ...,  0.0805,  0.0586,  0.1057]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 094]: 100% 1/1 [00:00<00:00,  8.54it/s]\u001b[0m\n",
            "[Epoch 095]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0654,  0.0317, -0.0144,  ...,  0.0053,  0.0014, -0.0340],\n",
            "        [ 0.0607, -0.0313,  0.0017,  ..., -0.0214,  0.0893, -0.0025],\n",
            "        [-0.0832,  0.0739,  0.0230,  ...,  0.1927, -0.1752, -0.0050],\n",
            "        ...,\n",
            "        [ 0.0403,  0.0313, -0.0328,  ...,  0.0074,  0.0480, -0.0257],\n",
            "        [ 0.0063,  0.0010, -0.0124,  ...,  0.0055, -0.0004,  0.0045],\n",
            "        [-0.0463, -0.0120,  0.0092,  ..., -0.0628,  0.0617,  0.0408]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 095]: 100% 1/1 [00:00<00:00,  6.23it/s]\u001b[0m\n",
            "[Epoch 096]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0265,  0.0207, -0.0700,  ...,  0.0832,  0.0183, -0.0007],\n",
            "        [-0.0471,  0.0029,  0.0579,  ..., -0.1310,  0.0519, -0.0047],\n",
            "        [-0.0559,  0.0660, -0.0299,  ..., -0.2518,  0.1996, -0.0144],\n",
            "        ...,\n",
            "        [-0.0363,  0.0022,  0.0065,  ...,  0.0010,  0.0569, -0.0214],\n",
            "        [-0.0690, -0.1371, -0.0716,  ...,  0.1502, -0.0431,  0.0154],\n",
            "        [ 0.1606, -0.0188,  0.0403,  ...,  0.1000,  0.0118, -0.1002]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 096]: 100% 1/1 [00:00<00:00,  8.66it/s]\u001b[0m\n",
            "[Epoch 097]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0428, -0.0063, -0.1892,  ..., -0.0040,  0.0401,  0.0248],\n",
            "        [-0.0255,  0.0077, -0.0750,  ...,  0.0196,  0.0499,  0.0242],\n",
            "        [ 0.0083, -0.0965, -0.1286,  ...,  0.1435, -0.0055, -0.0077],\n",
            "        ...,\n",
            "        [ 0.1333, -0.1246, -0.0432,  ..., -0.0717, -0.0314,  0.0277],\n",
            "        [-0.0235, -0.0308, -0.0073,  ...,  0.0346,  0.0428,  0.0019],\n",
            "        [-0.0422,  0.0282, -0.1314,  ...,  0.1339, -0.0024,  0.1214]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 097]: 100% 1/1 [00:00<00:00,  8.40it/s]\u001b[0m\n",
            "[Epoch 098]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0984, -0.0773, -0.0643,  ...,  0.0866,  0.0592,  0.0411],\n",
            "        [ 0.0883, -0.0934, -0.0200,  ...,  0.0563,  0.0452,  0.0047],\n",
            "        [ 0.0376, -0.0297, -0.1077,  ...,  0.0766,  0.0211, -0.0214],\n",
            "        ...,\n",
            "        [-0.1116,  0.1112, -0.0595,  ...,  0.1430, -0.0376,  0.1550],\n",
            "        [-0.0331, -0.0696,  0.0114,  ...,  0.0585,  0.0293,  0.0103],\n",
            "        [ 0.0806,  0.1295,  0.0109,  ...,  0.0108, -0.0539,  0.0320]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 098]: 100% 1/1 [00:00<00:00,  7.55it/s]\u001b[0m\n",
            "[Epoch 099]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0657,  0.0317, -0.0148,  ...,  0.0055,  0.0014, -0.0338],\n",
            "        [-0.0494, -0.0327,  0.0572,  ...,  0.0416,  0.0801,  0.0151],\n",
            "        [-0.0590, -0.0981, -0.1569,  ..., -0.0655,  0.0676,  0.0370],\n",
            "        ...,\n",
            "        [-0.0980, -0.0134, -0.0022,  ..., -0.0494, -0.0356,  0.0886],\n",
            "        [ 0.0065,  0.0010, -0.0129,  ...,  0.0057, -0.0004,  0.0046],\n",
            "        [ 0.0459,  0.0748, -0.1201,  ...,  0.0400,  0.0228, -0.0482]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 099]: 100% 1/1 [00:00<00:00,  8.38it/s]\u001b[0m\n",
            "[Epoch 100]:   0% 0/1 [00:00<?, ?it/s]\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[ 0.0937, -0.0497, -0.0815,  ...,  0.0170,  0.0136, -0.0377],\n",
            "        [-0.0914, -0.2097, -0.1778,  ...,  0.0486,  0.0800,  0.1289],\n",
            "        [ 0.0145,  0.0285,  0.0061,  ..., -0.1526,  0.0169, -0.0494],\n",
            "        ...,\n",
            "        [ 0.0091, -0.0778,  0.0032,  ...,  0.0328,  0.0297,  0.0059],\n",
            "        [ 0.0447, -0.0579,  0.0299,  ..., -0.1346,  0.0211,  0.0496],\n",
            "        [ 0.1340,  0.0140, -0.1169,  ...,  0.0743, -0.1611, -0.0504]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "[Epoch 100]: 100% 1/1 [00:00<00:00,  6.52it/s]\u001b[0m\n",
            "\u001b[0m14 Apr 00:14 INFO - Finish 1 train-validation experiment(s)...\u001b[0m\n",
            "\u001b[0m14 Apr 00:14 INFO - Start Calculating Metrics...\u001b[0m\n",
            "\u001b[0m14 Apr 00:14 INFO - ==========================\u001b[0m\n",
            "\u001b[0m14 Apr 00:14 INFO - Generate recommend list...\u001b[0m\n",
            "\u001b[0m14 Apr 00:14 INFO - ==========================\u001b[0m\n",
            "\u001b[0m\u001b[0mForward algorithm matrix after encoding\u001b[0m\n",
            "\u001b[0mForward algorithm mean\u001b[0m \u001b[0mtensor([[-0.0984,  0.0678,  0.0296,  ...,  0.0272,  0.0640,  0.0005],\n",
            "        [-0.0835,  0.0039,  0.0183,  ...,  0.0357,  0.0366,  0.0137],\n",
            "        [ 0.0522, -0.0144, -0.0118,  ...,  0.0933, -0.0210,  0.0242],\n",
            "        ...,\n",
            "        [ 0.0066,  0.0011, -0.0131,  ...,  0.0058, -0.0003,  0.0047],\n",
            "        [-0.0351, -0.0842, -0.0037,  ...,  0.0267,  0.0098, -0.0675],\n",
            "        [ 0.0024, -0.0086, -0.0119,  ..., -0.0062,  0.0645, -0.0032]],\n",
            "       grad_fn=<SliceBackward0>)\u001b[0m\n",
            "\u001b[0mForward algorithm reparameterise\u001b[0m\n",
            "\u001b[0mForward algorithm decoder\u001b[0m\n",
            "\u001b[0mPREDS\u001b[0m \u001b[0m[[345. 345. 345. ... 243. 243. 112.]\n",
            " [325. 290. 290. ... 140. 454.   1.]\n",
            " [151. 291. 291. ...  98. 307. 173.]\n",
            " ...\n",
            " [291. 291. 291. ... 331. 247. 213.]\n",
            " [300. 300. 300. ...  24.  24.  24.]\n",
            " [ 86.  86. 134. ... 240. 240.  29.]]\u001b[0m\n",
            "14 Apr 00:14 INFO - Finish 40 trial...\u001b[0m\n",
            "\u001b[0m\u001b[32m[I 2023-04-14 00:14:42,134]\u001b[0m Trial 39 finished with value: 0.06121550366242308 and parameters: {}. Best is trial 10 with value: 0.1209022497797705.\u001b[0m\n",
            "14 Apr 00:14 INFO - Trial 10 get the best ndcg(0.1209022497797705) with params: {}\u001b[0m\n",
            "\u001b[0m\u001b[0m\u001b[0m"
          ]
        }
      ],
      "source": [
        "!python3 tune.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmQeEzVpxb-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea0a9843-a1f9-4c58-c632-9a2a15623120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Project/daisyRec/tune_res\n"
          ]
        }
      ],
      "source": [
        "cd tune_res"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Et-mULaSM1ml",
        "outputId": "779474ad-4a06-4aff-c000-8fecfeb201d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_params_BPR_ease_ml-100k_10filter_tsbr.csv\n",
            "best_params_BPR_mf_ml-100k_10filter_tsbr.csv\n",
            "best_params_BPR_multi-vae_amazon-electronic_10filter_tsbr.csv\n",
            "best_params_BPR_multi-vae_ml-100k_10filter_tsbr.csv\n",
            "best_params_LD_BPR_multi-vae_amazon-electronic_10filter_tsbr.csv\n",
            "best_params_LD_BPR_multi-vae_ml-100k_10filter_tsbr.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Zy8yPaMgNbf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amaLD=pd.read_csv(\"best_params_BPR_multi-vae_amazon-electronic_10filter_tsbr.csv\")"
      ],
      "metadata": {
        "id": "JvSP0pBTNMe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amaLD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "hdqGg6qGOCVk",
        "outputId": "8acf7696-94e8-4bbd-cb74-ea233980fb7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   latent_dim  dropout  batch_size     lr  anneal_cap    ndcg\n",
              "0          32      0.5         256  0.001         0.2  0.1323\n",
              "1  latent_dim  dropout  batch_size     lr  anneal_cap    ndcg\n",
              "2          64      0.5         256  0.001         0.2  0.1400\n",
              "3  latent_dim  dropout  batch_size     lr  anneal_cap    ndcg\n",
              "4         128      0.5         256  0.001         0.2  0.1209\n",
              "5  latent_dim  dropout  batch_size     lr  anneal_cap    ndcg\n",
              "6         128      0.5         256   0.01         0.2  0.1736\n",
              "7  latent_dim  dropout  batch_size     lr  anneal_cap    ndcg\n",
              "8          64      0.5         256   0.01         0.2  0.1761"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-53eb309d-ae00-4dbb-a3cc-560e883c93a0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>latent_dim</th>\n",
              "      <th>dropout</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>lr</th>\n",
              "      <th>anneal_cap</th>\n",
              "      <th>ndcg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>latent_dim</td>\n",
              "      <td>dropout</td>\n",
              "      <td>batch_size</td>\n",
              "      <td>lr</td>\n",
              "      <td>anneal_cap</td>\n",
              "      <td>ndcg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>64</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>latent_dim</td>\n",
              "      <td>dropout</td>\n",
              "      <td>batch_size</td>\n",
              "      <td>lr</td>\n",
              "      <td>anneal_cap</td>\n",
              "      <td>ndcg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>128</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>latent_dim</td>\n",
              "      <td>dropout</td>\n",
              "      <td>batch_size</td>\n",
              "      <td>lr</td>\n",
              "      <td>anneal_cap</td>\n",
              "      <td>ndcg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>128</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>latent_dim</td>\n",
              "      <td>dropout</td>\n",
              "      <td>batch_size</td>\n",
              "      <td>lr</td>\n",
              "      <td>anneal_cap</td>\n",
              "      <td>ndcg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>64</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1761</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53eb309d-ae00-4dbb-a3cc-560e883c93a0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-53eb309d-ae00-4dbb-a3cc-560e883c93a0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-53eb309d-ae00-4dbb-a3cc-560e883c93a0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "amaLD.latent_dim.unique"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr8_lyRrOHng",
        "outputId": "491c9fc0-ac8e-4032-b493-de879d72c60e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Series.unique of 0            32\n",
              "1    latent_dim\n",
              "2            64\n",
              "3    latent_dim\n",
              "4           128\n",
              "5    latent_dim\n",
              "6           128\n",
              "7    latent_dim\n",
              "8            64\n",
              "Name: latent_dim, dtype: object>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "amaLD=amaLD[amaLD.latent_dim !='latent_dim']"
      ],
      "metadata": {
        "id": "olmAy_zHNMhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amaLD=amaLD.drop_duplicates()"
      ],
      "metadata": {
        "id": "Mds0pX31PFPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amaLD2=amaLD[amaLD.lr!='0.01']"
      ],
      "metadata": {
        "id": "zQVx3-n9PTXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amaLD2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "eVt0chh9P0Ci",
        "outputId": "346d8a79-afab-4521-966b-b8ea0a4cfd38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  latent_dim dropout batch_size     lr anneal_cap    ndcg\n",
              "0         32     0.5        256  0.001        0.2  0.1323\n",
              "2         64     0.5        256  0.001        0.2  0.1400\n",
              "4        128     0.5        256  0.001        0.2  0.1209"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6e6b414-ef16-476e-b955-3edcbdf15f41\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>latent_dim</th>\n",
              "      <th>dropout</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>lr</th>\n",
              "      <th>anneal_cap</th>\n",
              "      <th>ndcg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>64</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>128</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1209</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6e6b414-ef16-476e-b955-3edcbdf15f41')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b6e6b414-ef16-476e-b955-3edcbdf15f41 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b6e6b414-ef16-476e-b955-3edcbdf15f41');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "R9BFh1C5M2Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "amaLD2.ndcg=amaLD2.ndcg.astype(float)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUijcHBAQe7l",
        "outputId": "8a5ea508-5406-4244-b10b-d4aa7165252c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-c88db1ad98dc>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  amaLD2.ndcg=amaLD2.ndcg.astype(float)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(amaLD2['latent_dim'], amaLD2['ndcg'])\n",
        "ax.set_title('Latent dimension vs NDCG')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "9ipkQJKCNARQ",
        "outputId": "7e263c4a-bd75-417e-bd40-7df82b1fcf11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "amaLR=pd.read_csv(\"best_params_LD_BPR_multi-vae_amazon-electronic_10filter_tsbr.csv\")"
      ],
      "metadata": {
        "id": "WEGeItT1QCFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amaLR=amaLR[amaLR.latent_dim !='latent_dim']"
      ],
      "metadata": {
        "id": "XNo28-fvSAJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amaLR=amaLR.astype(float)"
      ],
      "metadata": {
        "id": "re66EIDVSDQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amaLR=amaLR.drop_duplicates()"
      ],
      "metadata": {
        "id": "ndWS7G5hSJx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amaLR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "dzPAICEQSf9Z",
        "outputId": "167ab70b-fbf1-45bb-ff4c-4c8f27c012aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    latent_dim  dropout  batch_size            lr  anneal_cap    ndcg\n",
              "0        128.0      0.5       256.0  1.000000e-02         0.2  0.1736\n",
              "2        128.0      0.5       256.0  1.000000e-03         0.2  0.1209\n",
              "6        128.0      0.5       256.0  1.000000e-04         0.2  0.1172\n",
              "9        128.0      0.5       256.0  1.000000e-05         0.2  0.1176\n",
              "11       128.0      0.5       256.0  1.000000e-06         0.2  0.1176\n",
              "13       128.0      0.5       256.0  1.000000e-07         0.2  0.1176"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3382ed5e-16b0-468f-a3fe-3e3ee2e9cd94\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>latent_dim</th>\n",
              "      <th>dropout</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>lr</th>\n",
              "      <th>anneal_cap</th>\n",
              "      <th>ndcg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>128.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256.0</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>128.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256.0</td>\n",
              "      <td>1.000000e-03</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>128.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256.0</td>\n",
              "      <td>1.000000e-04</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>128.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256.0</td>\n",
              "      <td>1.000000e-05</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>128.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256.0</td>\n",
              "      <td>1.000000e-06</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>128.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>256.0</td>\n",
              "      <td>1.000000e-07</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1176</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3382ed5e-16b0-468f-a3fe-3e3ee2e9cd94')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3382ed5e-16b0-468f-a3fe-3e3ee2e9cd94 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3382ed5e-16b0-468f-a3fe-3e3ee2e9cd94');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.semilogx(amaLR['lr'], amaLR['ndcg'])\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.ylabel('NDCG')\n",
        "plt.title('Learning Rate vs NDCG (Log Scale)')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "2M2Xm_w0SlOn",
        "outputId": "b52994b3-bc1f-49a5-d46a-87210e378186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#If your NGCD (normalized gradient coordinate descent) value remains the same for different dropout rates, it may indicate that the dropout regularization technique is not having a significant impact on the training process.\n",
        "\n"
      ],
      "metadata": {
        "id": "nq_yZTPxVmDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EXcTX86WKskl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}